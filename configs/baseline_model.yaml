baseline_model:
  # XGBoost Parameters
  xgboost_params:
    objective: "binary:logistic"
    eval_metric: "auc"
    n_estimators: 100
    max_depth: 6
    learning_rate: 0.1
    subsample: 0.8
    colsample_bytree: 0.8
    min_child_weight: 1
    gamma: 0
    reg_alpha: 0
    reg_lambda: 1
    random_state: 42
    n_jobs: -1
    verbosity: 1
    
  # Training Parameters
  training:
    early_stopping_rounds: 10
    validation_split: 0.2
    class_weight: "balanced"
    
  # Cross-Validation
  cross_validation:
    cv_folds: 5
    stratify: true
    scoring: ["roc_auc", "average_precision", "f1"]
    
  # Hyperparameter Search
  hyperparameter_search:
    method: "grid"  # grid, random, bayesian
    cv_folds: 3
    n_jobs: -1
    param_grids:
      coarse:
        n_estimators: [50, 100, 200]
        max_depth: [3, 6, 9]
        learning_rate: [0.05, 0.1, 0.2]
        subsample: [0.8, 1.0]
        colsample_bytree: [0.8, 1.0]
      fine:
        n_estimators: [80, 100, 120]
        max_depth: [5, 6, 7]
        learning_rate: [0.08, 0.1, 0.12]
        subsample: [0.7, 0.8, 0.9]
        colsample_bytree: [0.7, 0.8, 0.9]
        min_child_weight: [1, 3, 5]
        gamma: [0, 0.1, 0.2]
      extensive:
        n_estimators: [50, 100, 150, 200, 300]
        max_depth: [3, 4, 5, 6, 7, 8, 9]
        learning_rate: [0.01, 0.05, 0.1, 0.15, 0.2]
        subsample: [0.6, 0.7, 0.8, 0.9, 1.0]
        colsample_bytree: [0.6, 0.7, 0.8, 0.9, 1.0]
        min_child_weight: [1, 3, 5, 7]
        gamma: [0, 0.1, 0.2, 0.3]
        reg_alpha: [0, 0.1, 0.5, 1.0]
        reg_lambda: [0.5, 1.0, 1.5, 2.0]
        
  # Feature Selection
  feature_selection:
    method: "importance"  # importance, permutation, recursive
    n_features: 50
    importance_threshold: 0.001
    
  # Model Persistence
  persistence:
    model_dir: "models/artifacts"
    compress: true
    include_metadata: true
    versioning: true
    
  # Logging
  logging:
    level: "INFO"
    log_file: "logs/baseline_model.log"
    track_metrics: true
    plot_curves: true

# Performance Targets
performance_targets:
  auc_roc: 0.85
  auc_pr: 0.70
  f1_score: 0.75
  precision: 0.80
  recall: 0.70
  training_time_max_minutes: 5
  inference_time_max_ms: 100
  memory_usage_max_gb: 2
  model_size_max_mb: 50

# Evaluation Configuration
evaluation:
  metrics:
    - "auc_roc"
    - "auc_pr"
    - "f1_score"
    - "precision"
    - "recall"
    - "accuracy"
  
  cost_sensitive_defaults:
    false_positive_cost: 1.0
    false_negative_cost: 10.0
  
  test_size: 0.2
  stratify: true
  random_state: 42
  
  # Threshold optimization
  threshold_optimization:
    method: "f1"  # f1, precision, recall, youden
    search_range: [0.1, 0.9]
    search_steps: 81

# Data Configuration
data:
  # Preprocessing
  preprocessing:
    handle_missing: "drop"  # drop, impute, flag
    scaling: "none"  # none, standard, minmax, robust
    feature_selection: true
    
  # Class imbalance handling
  class_imbalance:
    strategy: "class_weight"  # class_weight, smote, undersampling, oversampling
    ratio: "auto"
    
  # Validation strategy
  validation:
    strategy: "stratified_kfold"  # stratified_kfold, time_series, group_kfold
    n_splits: 5
    shuffle: true
    random_state: 42