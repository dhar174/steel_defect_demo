baseline_model:
  algorithm: "xgboost"
  parameters:
    n_estimators: 100
    max_depth: 6
    learning_rate: 0.1
    subsample: 0.8
    colsample_bytree: 0.8
    random_state: 42
  
  feature_engineering:
    statistical_features: true
    stability_features: true
    duration_features: true
    interaction_features: true
    
  validation:
    cv_folds: 5
    early_stopping_rounds: 10
    eval_metric: "auc"

lstm_model:
  architecture:
    input_size: 5  # Number of sensor channels
    hidden_size: 64  # Hidden state dimension
    num_layers: 2  # Number of LSTM layers
    bidirectional: true  # Enable bidirectional processing
    dropout: 0.2  # Dropout rate between layers
    
  classifier:
    hidden_dims: [32, 16]  # Classifier hidden layer dimensions
    activation: "relu"  # Activation function
    dropout: 0.3  # Classifier dropout rate
    
  normalization:
    batch_norm: true  # Enable batch normalization
    layer_norm: false  # Enable layer normalization
    input_norm: true  # Enable input normalization
    
  regularization:
    weight_decay: 1e-4  # L2 regularization
    gradient_clip: 1.0  # Gradient clipping threshold
    
  training:
    batch_size: 32
    learning_rate: 0.001
    num_epochs: 100
    early_stopping_patience: 15
    
  data_processing:
    sequence_length: 300  # 5 minutes at 1Hz
    normalization: "z_score"
    padding: "zero"
    
  loss_function:
    type: "weighted_bce"
    pos_weight: 3.0  # For class imbalance

evaluation:
  metrics:
    - "auc_roc"
    - "auc_pr"
    - "f1_score"
    - "precision"
    - "recall"
    - "accuracy"
  
  cost_sensitive_defaults:
    false_positive_cost: 1.0
    false_negative_cost: 10.0
  
  test_size: 0.2
  stratify: true
  random_state: 42