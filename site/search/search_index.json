{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Steel Defect Prediction System Documentation","text":"<ul> <li> <p> Getting Started</p> <p>Get up and running quickly with our steel casting defect prediction system</p> <p> Quick Start</p> </li> <li> <p> User Guide</p> <p>Complete guide to using the dashboard and monitoring interface</p> <p> Dashboard Overview</p> </li> <li> <p> API Reference</p> <p>Comprehensive API documentation with interactive examples</p> <p> API Docs</p> </li> <li> <p> Architecture</p> <p>Deep dive into system architecture and design decisions</p> <p> System Overview</p> </li> </ul>"},{"location":"#overview","title":"Overview","text":"<p>The Steel Defect Prediction System is a comprehensive machine learning solution designed for continuous steel casting operations. It provides real-time defect prediction, quality monitoring, and advanced analytics to help optimize casting processes and reduce product defects.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Real-time Prediction: ML-powered defect prediction using multiple model types (XGBoost, LSTM)</li> <li>Interactive Dashboard: Comprehensive monitoring interface with Dash framework</li> <li>Historical Analysis: Advanced analytics for process optimization</li> <li>Alert Management: Configurable alerting system for proactive quality control</li> <li>Multi-model Comparison: Side-by-side model performance evaluation</li> </ul>"},{"location":"#quick-navigation","title":"Quick Navigation","text":""},{"location":"#for-new-users","title":"For New Users","text":"<ul> <li>Quick Start Guide - Get running in 5 minutes</li> <li>System Requirements - Hardware and software prerequisites</li> <li>First Prediction - Your first defect prediction</li> </ul>"},{"location":"#for-operators","title":"For Operators","text":"<ul> <li>Dashboard Overview - Navigate the monitoring interface</li> </ul>"},{"location":"#for-developers","title":"For Developers","text":"<ul> <li>Development Setup - Set up development environment</li> <li>Contributing Guide - How to contribute</li> </ul>"},{"location":"#for-system-administrators","title":"For System Administrators","text":"<ul> <li>System Overview - Understand the architecture</li> </ul>"},{"location":"#system-architecture","title":"System Architecture","text":"<pre><code>graph TB\n    A[Sensor Data] --&gt; B[Data Pipeline]\n    B --&gt; C[Feature Engineering]\n    C --&gt; D[ML Models]\n    D --&gt; E[Prediction Engine]\n    E --&gt; F[Dashboard]\n    E --&gt; G[Alert System]\n\n    D1[XGBoost Model] --&gt; E\n    D2[LSTM Model] --&gt; E\n\n    H[Historical Data] --&gt; I[Model Training]\n    I --&gt; D\n\n    style A fill:#e1f5fe\n    style F fill:#e8f5e8\n    style G fill:#fff3e0</code></pre>"},{"location":"#technology-stack","title":"Technology Stack","text":"<ul> <li>Machine Learning: XGBoost, PyTorch, scikit-learn</li> <li>Dashboard: Dash, Plotly, Bootstrap</li> <li>Data Processing: pandas, NumPy, PyArrow</li> <li>Infrastructure: Docker, Python 3.8+</li> <li>Documentation: MkDocs Material</li> </ul>"},{"location":"#latest-updates","title":"Latest Updates","text":"<p>Version 0.1.0</p> <ul> <li>Initial release with baseline XGBoost and LSTM models</li> <li>Complete dashboard interface with real-time monitoring</li> <li>Comprehensive alerting system</li> <li>Historical analysis and model comparison tools</li> </ul>"},{"location":"#support","title":"Support","text":"<ul> <li>Documentation: Browse this comprehensive guide</li> <li>Issues: GitHub Issues</li> <li>Discussions: GitHub Discussions</li> </ul> <p>Last updated: {{ now().strftime('%B %d, %Y') }}</p>"},{"location":"api-reference/authentication/","title":"Authentication","text":"<p>The Steel Defect Prediction System uses a robust authentication and authorization system to ensure secure access to APIs and protect sensitive operational data.</p>"},{"location":"api-reference/authentication/#overview","title":"Overview","text":"<p>Authentication features include:</p> <ul> <li>JWT-based token authentication</li> <li>Role-based access control (RBAC)</li> <li>API key authentication for service integrations</li> <li>OAuth 2.0 support for third-party integrations</li> <li>Multi-factor authentication (MFA) for sensitive operations</li> </ul>"},{"location":"api-reference/authentication/#authentication-methods","title":"Authentication Methods","text":""},{"location":"api-reference/authentication/#1-jwt-token-authentication","title":"1. JWT Token Authentication","text":"<p>Login and Token Generation</p> <pre><code>import requests\n\n# User login\nlogin_response = requests.post(\n    'http://localhost:8000/api/v1/auth/login',\n    json={\n        'username': 'operator_001',\n        'password': 'secure_password'\n    }\n)\n\nif login_response.status_code == 200:\n    tokens = login_response.json()\n    access_token = tokens['access_token']\n    refresh_token = tokens['refresh_token']\n\n    print(f\"Access token expires in: {tokens['expires_in']} seconds\")\n</code></pre> <p>Using Access Tokens</p> <pre><code># Make authenticated API calls\nheaders = {\n    'Authorization': f'Bearer {access_token}',\n    'Content-Type': 'application/json'\n}\n\n# Get current user info\nuser_info = requests.get(\n    'http://localhost:8000/api/v1/auth/me',\n    headers=headers\n)\n\nprint(f\"Current user: {user_info.json()['username']}\")\nprint(f\"Role: {user_info.json()['role']}\")\n</code></pre> <p>Token Refresh</p> <pre><code># Refresh expired access token\nrefresh_response = requests.post(\n    'http://localhost:8000/api/v1/auth/refresh',\n    json={'refresh_token': refresh_token}\n)\n\nif refresh_response.status_code == 200:\n    new_tokens = refresh_response.json()\n    access_token = new_tokens['access_token']\n</code></pre>"},{"location":"api-reference/authentication/#2-api-key-authentication","title":"2. API Key Authentication","text":"<p>Generate API Key</p> <pre><code># Generate API key for service integration\napi_key_response = requests.post(\n    'http://localhost:8000/api/v1/auth/api-keys',\n    headers=headers,\n    json={\n        'name': 'SCADA Integration',\n        'description': 'API key for SCADA system integration',\n        'permissions': ['predictions:read', 'sensors:read'],\n        'expires_at': '2024-12-31T23:59:59Z'\n    }\n)\n\napi_key = api_key_response.json()['api_key']\n</code></pre> <p>Using API Key</p> <pre><code># Use API key for authentication\napi_headers = {\n    'X-API-Key': api_key,\n    'Content-Type': 'application/json'\n}\n\n# Make API call with API key\nprediction_response = requests.post(\n    'http://localhost:8000/api/v1/predictions',\n    headers=api_headers,\n    json=sensor_data\n)\n</code></pre>"},{"location":"api-reference/authentication/#3-oauth-20-integration","title":"3. OAuth 2.0 Integration","text":"<p>Authorization Code Flow</p> <pre><code># Redirect user to authorization endpoint\nauth_url = (\n    'http://localhost:8000/api/v1/oauth/authorize'\n    '?client_id=your_client_id'\n    '&amp;response_type=code'\n    '&amp;redirect_uri=http://your-app.com/callback'\n    '&amp;scope=predictions:read sensors:write'\n    '&amp;state=random_state_string'\n)\n\n# User authorizes and is redirected with code\n# Exchange code for tokens\ntoken_response = requests.post(\n    'http://localhost:8000/api/v1/oauth/token',\n    data={\n        'grant_type': 'authorization_code',\n        'code': 'authorization_code_from_callback',\n        'redirect_uri': 'http://your-app.com/callback',\n        'client_id': 'your_client_id',\n        'client_secret': 'your_client_secret'\n    }\n)\n\noauth_tokens = token_response.json()\n</code></pre>"},{"location":"api-reference/authentication/#user-roles-and-permissions","title":"User Roles and Permissions","text":""},{"location":"api-reference/authentication/#role-definitions","title":"Role Definitions","text":"<pre><code># Role hierarchy and permissions\nroles = {\n    'operator': {\n        'permissions': [\n            'dashboard:read',\n            'predictions:read',\n            'alerts:read',\n            'alerts:acknowledge'\n        ],\n        'description': 'Basic operator access'\n    },\n    'supervisor': {\n        'inherits': ['operator'],\n        'permissions': [\n            'reports:read',\n            'analytics:read',\n            'users:read',\n            'alerts:manage'\n        ],\n        'description': 'Supervisor with analytics access'\n    },\n    'engineer': {\n        'inherits': ['supervisor'],\n        'permissions': [\n            'models:read',\n            'models:deploy',\n            'system:configure',\n            'predictions:write'\n        ],\n        'description': 'Engineering access for model management'\n    },\n    'admin': {\n        'inherits': ['engineer'],\n        'permissions': [\n            'users:write',\n            'users:delete',\n            'system:admin',\n            'api_keys:manage'\n        ],\n        'description': 'Full system administration'\n    }\n}\n</code></pre>"},{"location":"api-reference/authentication/#permission-checking","title":"Permission Checking","text":"<pre><code>from src.auth.permissions import check_permission\n\n# Check if user has permission\n@check_permission('predictions:write')\ndef create_prediction(user, sensor_data):\n    # Function only executes if user has permission\n    return prediction_engine.predict(sensor_data)\n\n# Manual permission check\ndef manual_check_example(user):\n    if user.has_permission('models:deploy'):\n        deploy_model()\n    else:\n        raise PermissionError(\"Insufficient permissions\")\n</code></pre>"},{"location":"api-reference/authentication/#multi-factor-authentication","title":"Multi-Factor Authentication","text":""},{"location":"api-reference/authentication/#setup-mfa","title":"Setup MFA","text":"<pre><code># Enable MFA for user\nmfa_setup = requests.post(\n    'http://localhost:8000/api/v1/auth/mfa/setup',\n    headers=headers,\n    json={'method': 'totp'}  # Time-based OTP\n)\n\nif mfa_setup.status_code == 200:\n    setup_data = mfa_setup.json()\n    qr_code_url = setup_data['qr_code']\n    backup_codes = setup_data['backup_codes']\n\n    print(f\"Scan QR code: {qr_code_url}\")\n    print(f\"Backup codes: {backup_codes}\")\n</code></pre>"},{"location":"api-reference/authentication/#mfa-login","title":"MFA Login","text":"<pre><code># Login with MFA\nlogin_mfa = requests.post(\n    'http://localhost:8000/api/v1/auth/login',\n    json={\n        'username': 'supervisor_001',\n        'password': 'secure_password',\n        'mfa_code': '123456'  # From authenticator app\n    }\n)\n</code></pre>"},{"location":"api-reference/authentication/#security-headers","title":"Security Headers","text":""},{"location":"api-reference/authentication/#required-headers","title":"Required Headers","text":"<pre><code># Security headers for API requests\nsecurity_headers = {\n    'Authorization': f'Bearer {access_token}',\n    'X-Request-ID': 'unique_request_id',\n    'X-Client-Version': '1.0.0',\n    'User-Agent': 'SteelDefectClient/1.0.0'\n}\n\n# Rate limiting headers in response\nresponse_headers = {\n    'X-RateLimit-Limit': '1000',\n    'X-RateLimit-Remaining': '998',\n    'X-RateLimit-Reset': '1640995200'\n}\n</code></pre>"},{"location":"api-reference/authentication/#cors-configuration","title":"CORS Configuration","text":"<pre><code># CORS settings for web applications\ncors_config = {\n    'allow_origins': [\n        'https://dashboard.steel-plant.com',\n        'https://mobile.steel-plant.com'\n    ],\n    'allow_methods': ['GET', 'POST', 'PUT', 'DELETE'],\n    'allow_headers': [\n        'Authorization',\n        'Content-Type',\n        'X-API-Key'\n    ],\n    'expose_headers': [\n        'X-RateLimit-Limit',\n        'X-RateLimit-Remaining'\n    ]\n}\n</code></pre>"},{"location":"api-reference/authentication/#token-management","title":"Token Management","text":""},{"location":"api-reference/authentication/#token-information","title":"Token Information","text":"<pre><code># Get token information\ntoken_info = requests.get(\n    'http://localhost:8000/api/v1/auth/token/info',\n    headers={'Authorization': f'Bearer {access_token}'}\n)\n\ntoken_details = token_info.json()\nprint(f\"Token expires at: {token_details['expires_at']}\")\nprint(f\"Issued at: {token_details['issued_at']}\")\nprint(f\"Token ID: {token_details['jti']}\")\n</code></pre>"},{"location":"api-reference/authentication/#token-revocation","title":"Token Revocation","text":"<pre><code># Revoke access token\nrevoke_response = requests.post(\n    'http://localhost:8000/api/v1/auth/revoke',\n    json={'token': access_token}\n)\n\n# Revoke all user tokens (logout from all devices)\nrevoke_all = requests.post(\n    'http://localhost:8000/api/v1/auth/revoke-all',\n    headers={'Authorization': f'Bearer {access_token}'}\n)\n</code></pre>"},{"location":"api-reference/authentication/#error-handling","title":"Error Handling","text":""},{"location":"api-reference/authentication/#authentication-errors","title":"Authentication Errors","text":"<pre><code>def handle_auth_errors(response):\n    if response.status_code == 401:\n        error_data = response.json()\n\n        if error_data['error'] == 'token_expired':\n            # Try to refresh token\n            return refresh_token_and_retry()\n        elif error_data['error'] == 'invalid_token':\n            # Redirect to login\n            return redirect_to_login()\n        elif error_data['error'] == 'mfa_required':\n            # Prompt for MFA code\n            return prompt_for_mfa()\n\n    elif response.status_code == 403:\n        # Insufficient permissions\n        raise PermissionError(\"Access denied\")\n\n    return response\n</code></pre>"},{"location":"api-reference/authentication/#retry-logic","title":"Retry Logic","text":"<pre><code>import time\nfrom functools import wraps\n\ndef with_auth_retry(max_retries=3):\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            for attempt in range(max_retries):\n                try:\n                    response = func(*args, **kwargs)\n                    if response.status_code == 401:\n                        # Try to refresh token\n                        refresh_access_token()\n                        continue\n                    return response\n                except Exception as e:\n                    if attempt == max_retries - 1:\n                        raise\n                    time.sleep(2 ** attempt)  # Exponential backoff\n\n        return wrapper\n    return decorator\n\n@with_auth_retry()\ndef make_api_call(endpoint, data):\n    return requests.post(endpoint, json=data, headers=auth_headers)\n</code></pre>"},{"location":"api-reference/authentication/#api-client-library","title":"API Client Library","text":""},{"location":"api-reference/authentication/#python-client","title":"Python Client","text":"<pre><code>from steel_defect_client import SteelDefectClient\n\n# Initialize client with authentication\nclient = SteelDefectClient(\n    base_url='http://localhost:8000',\n    username='operator_001',\n    password='secure_password'\n)\n\n# Client handles authentication automatically\npredictions = client.predictions.create(sensor_data)\nalerts = client.alerts.list(status='active')\n</code></pre>"},{"location":"api-reference/authentication/#javascript-client","title":"JavaScript Client","text":"<pre><code>// JavaScript SDK with automatic token management\nimport SteelDefectSDK from 'steel-defect-sdk';\n\nconst client = new SteelDefectSDK({\n    baseURL: 'http://localhost:8000',\n    apiKey: 'your_api_key'\n});\n\n// Make authenticated requests\nconst predictions = await client.predictions.create(sensorData);\nconst alerts = await client.alerts.list({ status: 'active' });\n</code></pre>"},{"location":"api-reference/authentication/#security-best-practices","title":"Security Best Practices","text":""},{"location":"api-reference/authentication/#token-security","title":"Token Security","text":"<pre><code># Secure token storage\nimport keyring\n\n# Store token securely\nkeyring.set_password(\"steel_defect_system\", \"access_token\", access_token)\n\n# Retrieve token securely\nstored_token = keyring.get_password(\"steel_defect_system\", \"access_token\")\n</code></pre>"},{"location":"api-reference/authentication/#network-security","title":"Network Security","text":"<pre><code># Use HTTPS for all API calls\nimport requests\nfrom requests.adapters import HTTPAdapter\nfrom urllib3.util.retry import Retry\n\n# Configure secure session\nsession = requests.Session()\nsession.verify = True  # Verify SSL certificates\n\n# Configure retry strategy\nretry_strategy = Retry(\n    total=3,\n    backoff_factor=1,\n    status_forcelist=[429, 500, 502, 503, 504]\n)\n\nadapter = HTTPAdapter(max_retries=retry_strategy)\nsession.mount(\"https://\", adapter)\n</code></pre> <p>This authentication system provides comprehensive security while maintaining ease of use for various integration scenarios.</p>"},{"location":"api-reference/dashboard-integration/","title":"Dashboard Integration API","text":"<p>The Steel Defect Prediction System provides a Dash-based dashboard with programmatic access through Python modules and callback interfaces. This page documents the integration patterns and programmatic APIs.</p>"},{"location":"api-reference/dashboard-integration/#architecture-overview","title":"Architecture Overview","text":"<p>The system uses Dash (Plotly) for the web interface rather than traditional REST APIs. Integration is achieved through:</p> <ul> <li>Python Module APIs: Direct Python integration</li> <li>Dashboard Callbacks: Real-time updates via Dash callbacks</li> <li>Data Interfaces: Programmatic access to prediction engines</li> <li>Component APIs: Reusable dashboard components</li> </ul>"},{"location":"api-reference/dashboard-integration/#python-module-integration","title":"Python Module Integration","text":""},{"location":"api-reference/dashboard-integration/#prediction-engine-api","title":"Prediction Engine API","text":"<p>The core prediction functionality is available through Python modules:</p> <pre><code>from src.inference.prediction_engine import PredictionEngine\nfrom src.models.baseline_model import BaselineModel\nfrom src.models.lstm_model import LSTMModel\n\n# Initialize prediction engine\nengine = PredictionEngine()\n\n# Make predictions\nprediction = engine.predict(sensor_data)\nprint(f\"Defect probability: {prediction['defect_probability']}\")\n</code></pre>"},{"location":"api-reference/dashboard-integration/#predictionengine-class","title":"PredictionEngine Class","text":"<pre><code>class PredictionEngine:\n    \"\"\"Main prediction engine for defect detection\"\"\"\n\n    def __init__(self, config: Dict = None):\n        \"\"\"\n        Initialize prediction engine with models.\n\n        Args:\n            config: Configuration dictionary\n        \"\"\"\n\n    def predict(self, data: Dict) -&gt; Dict:\n        \"\"\"\n        Generate defect predictions.\n\n        Args:\n            data: Sensor data dictionary\n\n        Returns:\n            Prediction results with confidence scores\n        \"\"\"\n\n    def predict_batch(self, data: List[Dict]) -&gt; List[Dict]:\n        \"\"\"\n        Generate batch predictions.\n\n        Args:\n            data: List of sensor data dictionaries\n\n        Returns:\n            List of prediction results\n        \"\"\"\n</code></pre>"},{"location":"api-reference/dashboard-integration/#data-interface-api","title":"Data Interface API","text":"<p>Access and manipulate data through standardized interfaces:</p> <pre><code>from src.data.data_connectors import DataConnector\nfrom src.features.feature_engineering import FeatureEngineer\n\n# Data access\nconnector = DataConnector()\ndata = connector.get_latest_data(limit=100)\n\n# Feature engineering\nengineer = FeatureEngineer()\nfeatures = engineer.transform(data)\n</code></pre>"},{"location":"api-reference/dashboard-integration/#dashboard-component-apis","title":"Dashboard Component APIs","text":""},{"location":"api-reference/dashboard-integration/#component-integration","title":"Component Integration","text":"<p>Reusable dashboard components for custom applications:</p> <pre><code>from src.visualization.components import (\n    PredictionDisplay,\n    ModelComparison,\n    SensorMonitoring,\n    AlertManagement\n)\n\n# Create component instances\nprediction_display = PredictionDisplay()\nmodel_comparison = ModelComparison()\nsensor_monitoring = SensorMonitoring()\nalert_management = AlertManagement()\n</code></pre>"},{"location":"api-reference/dashboard-integration/#predictiondisplay-component","title":"PredictionDisplay Component","text":"<p>Real-time prediction visualization:</p> <pre><code>class PredictionDisplay:\n    \"\"\"Real-time prediction display component\"\"\"\n\n    def get_layout(self, initial_data: Dict = None) -&gt; dbc.Container:\n        \"\"\"\n        Get the component layout.\n\n        Args:\n            initial_data: Initial data for display\n\n        Returns:\n            Dash Bootstrap Container with layout\n        \"\"\"\n\n    def update_predictions(self, prediction_data: Dict) -&gt; Dict:\n        \"\"\"\n        Update prediction display with new data.\n\n        Args:\n            prediction_data: Latest prediction results\n\n        Returns:\n            Updated component state\n        \"\"\"\n</code></pre>"},{"location":"api-reference/dashboard-integration/#usage-example","title":"Usage Example","text":"<pre><code># Initialize component\ndisplay = PredictionDisplay()\n\n# Get layout for embedding\nlayout = display.get_layout()\n\n# In Dash callback\n@app.callback(\n    Output('prediction-display', 'children'),\n    [Input('interval-component', 'n_intervals')]\n)\ndef update_display(n):\n    # Get latest predictions\n    predictions = prediction_engine.get_latest_predictions()\n\n    # Update display\n    return display.update_predictions(predictions)\n</code></pre>"},{"location":"api-reference/dashboard-integration/#modelcomparison-component","title":"ModelComparison Component","text":"<p>Compare ML model performance:</p> <pre><code>class ModelComparison:\n    \"\"\"Model performance comparison component\"\"\"\n\n    def get_dashboard_layout(self, model_results: Dict) -&gt; dbc.Container:\n        \"\"\"\n        Create model comparison dashboard.\n\n        Args:\n            model_results: Dictionary with model performance data\n\n        Returns:\n            Complete dashboard layout\n        \"\"\"\n\n    def create_roc_curves(self, model_results: Dict) -&gt; go.Figure:\n        \"\"\"Create ROC curve comparison chart\"\"\"\n\n    def create_feature_importance(self, model_results: Dict) -&gt; go.Figure:\n        \"\"\"Create feature importance comparison\"\"\"\n</code></pre>"},{"location":"api-reference/dashboard-integration/#model-results-format","title":"Model Results Format","text":"<pre><code>model_results = {\n    'XGBoost': {\n        'y_true': np.array([0, 1, 0, 1, ...]),           # True labels\n        'y_pred': np.array([0, 1, 0, 0, ...]),           # Predicted labels\n        'y_pred_proba': np.array([0.1, 0.9, 0.2, ...]), # Probabilities\n        'feature_importance': {                           # Feature importance\n            'temperature': 0.35,\n            'pressure': 0.28,\n            'flow_rate': 0.20,\n            # ...\n        },\n        'metrics': {                                      # Performance metrics\n            'accuracy': 0.87,\n            'precision': 0.84,\n            'recall': 0.82,\n            'f1_score': 0.83\n        }\n    },\n    'LSTM': {\n        # Similar structure for LSTM model\n        'attention_weights': np.array([...])  # Additional for LSTM\n    }\n}\n</code></pre>"},{"location":"api-reference/dashboard-integration/#sensormonitoring-component","title":"SensorMonitoring Component","text":"<p>Real-time sensor data visualization:</p> <pre><code>class SensorMonitoring:\n    \"\"\"Real-time sensor monitoring component\"\"\"\n\n    def create_sensor_charts(self, sensor_data: pd.DataFrame) -&gt; List[go.Figure]:\n        \"\"\"\n        Create sensor monitoring charts.\n\n        Args:\n            sensor_data: DataFrame with sensor readings\n\n        Returns:\n            List of Plotly figures\n        \"\"\"\n\n    def get_alert_indicators(self, sensor_data: pd.DataFrame) -&gt; Dict:\n        \"\"\"\n        Generate alert indicators based on sensor data.\n\n        Args:\n            sensor_data: Current sensor readings\n\n        Returns:\n            Alert status dictionary\n        \"\"\"\n</code></pre>"},{"location":"api-reference/dashboard-integration/#data-formats","title":"Data Formats","text":""},{"location":"api-reference/dashboard-integration/#sensor-data-format","title":"Sensor Data Format","text":"<pre><code>sensor_data = {\n    \"timestamp\": \"2025-07-20T22:18:46Z\",\n    \"cast_id\": \"CAST_20250720_001\",\n    \"sensors\": {\n        \"mold_temperature\": 1520.5,        # \u00b0C\n        \"mold_level\": 150.2,               # mm\n        \"casting_speed\": 1.2,              # m/min\n        \"cooling_water_flow\": 200.8,       # L/min\n        \"superheat\": 25.3,                 # \u00b0C\n        \"mold_powder_consumption\": 0.5,    # kg/min\n        \"secondary_cooling_zones\": [       # Multiple zones\n            {\"zone\": 1, \"water_flow\": 50.2, \"temperature\": 800.1},\n            {\"zone\": 2, \"water_flow\": 45.8, \"temperature\": 650.3},\n            # ...\n        ],\n        \"oscillation_frequency\": 180.0,    # cycles/min\n        \"oscillation_amplitude\": 4.5       # mm\n    },\n    \"process_parameters\": {\n        \"steel_grade\": \"C45\",\n        \"slab_width\": 1200,                # mm\n        \"slab_thickness\": 220,             # mm\n        \"tundish_temperature\": 1545.2      # \u00b0C\n    }\n}\n</code></pre>"},{"location":"api-reference/dashboard-integration/#prediction-response-format","title":"Prediction Response Format","text":"<pre><code>prediction_response = {\n    \"prediction_id\": \"pred_abc123def456\",\n    \"timestamp\": \"2025-07-20T22:18:46Z\",\n    \"cast_id\": \"CAST_20250720_001\",\n    \"defect_probability\": 0.15,           # 0-1 scale\n    \"confidence_score\": 0.89,             # Model confidence\n    \"model_predictions\": {                # Individual model results\n        \"baseline_xgboost\": {\n            \"probability\": 0.12,\n            \"confidence\": 0.87,\n            \"features_used\": 25\n        },\n        \"lstm_sequence\": {\n            \"probability\": 0.18,\n            \"confidence\": 0.91,\n            \"sequence_length\": 60\n        },\n        \"ensemble\": {\n            \"probability\": 0.15,\n            \"confidence\": 0.89,\n            \"weights\": {\n                \"baseline\": 0.4,\n                \"lstm\": 0.6\n            }\n        }\n    },\n    \"alert_level\": \"low\",                 # low, medium, high\n    \"risk_factors\": [                     # Contributing factors\n        {\n            \"factor\": \"temperature_variance\",\n            \"impact\": 0.08,\n            \"description\": \"Temperature fluctuation detected\"\n        }\n    ],\n    \"recommendations\": [                   # Actionable recommendations\n        \"Monitor mold temperature stability\",\n        \"Check cooling water flow consistency\"\n    ]\n}\n</code></pre>"},{"location":"api-reference/dashboard-integration/#dashboard-callbacks","title":"Dashboard Callbacks","text":""},{"location":"api-reference/dashboard-integration/#real-time-updates","title":"Real-time Updates","text":"<p>Dashboard components use Dash callbacks for real-time updates:</p> <pre><code>@app.callback(\n    [Output('prediction-chart', 'figure'),\n     Output('confidence-indicator', 'children'),\n     Output('alert-status', 'color')],\n    [Input('interval-component', 'n_intervals')],\n    [State('theme-store', 'data')]\n)\ndef update_realtime_display(n_intervals, theme):\n    \"\"\"\n    Update real-time prediction display.\n\n    Args:\n        n_intervals: Interval counter\n        theme: Current theme setting\n\n    Returns:\n        Tuple of updated components\n    \"\"\"\n    # Get latest predictions\n    predictions = prediction_engine.get_latest_predictions()\n\n    # Update chart\n    fig = create_prediction_chart(predictions, theme)\n\n    # Update confidence indicator\n    confidence = predictions.get('confidence_score', 0)\n    confidence_text = f\"Confidence: {confidence:.1%}\"\n\n    # Update alert status\n    alert_level = predictions.get('alert_level', 'low')\n    alert_color = {\n        'low': 'success',\n        'medium': 'warning', \n        'high': 'danger'\n    }.get(alert_level, 'secondary')\n\n    return fig, confidence_text, alert_color\n</code></pre>"},{"location":"api-reference/dashboard-integration/#interactive-controls","title":"Interactive Controls","text":"<pre><code>@app.callback(\n    Output('model-comparison-chart', 'figure'),\n    [Input('model-selector', 'value'),\n     Input('metric-selector', 'value')],\n    [State('model-results-store', 'data')]\n)\ndef update_model_comparison(selected_models, selected_metric, model_results):\n    \"\"\"\n    Update model comparison chart based on user selection.\n\n    Args:\n        selected_models: List of selected model names\n        selected_metric: Selected performance metric\n        model_results: Stored model results data\n\n    Returns:\n        Updated comparison chart\n    \"\"\"\n    return model_comparison.create_comparison_chart(\n        selected_models, selected_metric, model_results\n    )\n</code></pre>"},{"location":"api-reference/dashboard-integration/#configuration-api","title":"Configuration API","text":""},{"location":"api-reference/dashboard-integration/#dashboard-configuration","title":"Dashboard Configuration","text":"<p>Configure dashboard behavior programmatically:</p> <pre><code>dashboard_config = {\n    \"refresh_interval\": 5000,              # Milliseconds\n    \"theme\": \"plotly_white\",               # Default theme\n    \"auto_refresh\": True,                  # Enable auto-refresh\n    \"alert_thresholds\": {                  # Alert configuration\n        \"high\": 0.8,\n        \"medium\": 0.5,\n        \"low\": 0.2\n    },\n    \"chart_settings\": {                    # Chart preferences\n        \"height\": 400,\n        \"show_legend\": True,\n        \"color_scheme\": \"viridis\"\n    },\n    \"data_retention\": {                    # Data management\n        \"realtime_hours\": 24,\n        \"historical_days\": 365\n    }\n}\n</code></pre>"},{"location":"api-reference/dashboard-integration/#model-configuration","title":"Model Configuration","text":"<pre><code>model_config = {\n    \"baseline_model\": {\n        \"type\": \"xgboost\",\n        \"n_estimators\": 100,\n        \"max_depth\": 6,\n        \"learning_rate\": 0.1,\n        \"feature_selection\": \"auto\"\n    },\n    \"lstm_model\": {\n        \"type\": \"lstm\",\n        \"sequence_length\": 60,\n        \"hidden_size\": 128,\n        \"num_layers\": 2,\n        \"dropout\": 0.2,\n        \"bidirectional\": True\n    },\n    \"ensemble\": {\n        \"method\": \"weighted_average\",\n        \"weights\": {\n            \"baseline\": 0.4,\n            \"lstm\": 0.6\n        }\n    }\n}\n</code></pre>"},{"location":"api-reference/dashboard-integration/#integration-examples","title":"Integration Examples","text":""},{"location":"api-reference/dashboard-integration/#custom-dashboard-integration","title":"Custom Dashboard Integration","text":"<pre><code>import dash\nfrom dash import dcc, html\nimport dash_bootstrap_components as dbc\nfrom src.visualization.components import ModelComparison, PredictionDisplay\n\n# Create custom dashboard\napp = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n\n# Initialize components\nprediction_display = PredictionDisplay()\nmodel_comparison = ModelComparison()\n\n# Custom layout\napp.layout = dbc.Container([\n    html.H1(\"Custom Steel Defect Dashboard\"),\n\n    # Real-time predictions\n    dbc.Row([\n        dbc.Col([\n            html.H3(\"Real-time Predictions\"),\n            prediction_display.get_layout()\n        ], width=8),\n\n        # Alert panel\n        dbc.Col([\n            html.H3(\"Alerts\"),\n            html.Div(id=\"alert-panel\")\n        ], width=4)\n    ]),\n\n    # Model comparison\n    dbc.Row([\n        dbc.Col([\n            html.H3(\"Model Performance\"),\n            model_comparison.get_dashboard_layout({})\n        ], width=12)\n    ]),\n\n    # Auto-refresh\n    dcc.Interval(\n        id='interval-component',\n        interval=5000,  # Update every 5 seconds\n        n_intervals=0\n    )\n])\n\nif __name__ == '__main__':\n    app.run_server(debug=True)\n</code></pre>"},{"location":"api-reference/dashboard-integration/#programmatic-prediction","title":"Programmatic Prediction","text":"<pre><code>from src.inference.prediction_engine import PredictionEngine\nimport pandas as pd\n\n# Initialize engine\nengine = PredictionEngine()\n\n# Load sensor data\nsensor_data = pd.read_csv('sensor_readings.csv')\n\n# Generate predictions\npredictions = []\nfor _, row in sensor_data.iterrows():\n    prediction = engine.predict(row.to_dict())\n    predictions.append(prediction)\n\n# Analyze results\nresults_df = pd.DataFrame(predictions)\nhigh_risk_casts = results_df[results_df['defect_probability'] &gt; 0.8]\n\nprint(f\"High risk casts: {len(high_risk_casts)}\")\nprint(f\"Average confidence: {results_df['confidence_score'].mean():.2f}\")\n</code></pre>"},{"location":"api-reference/dashboard-integration/#error-handling","title":"Error Handling","text":""},{"location":"api-reference/dashboard-integration/#common-exceptions","title":"Common Exceptions","text":"<pre><code>from src.utils.exceptions import (\n    PredictionError,\n    DataValidationError,\n    ModelNotFoundError\n)\n\ntry:\n    prediction = engine.predict(sensor_data)\nexcept PredictionError as e:\n    print(f\"Prediction failed: {e}\")\nexcept DataValidationError as e:\n    print(f\"Invalid data format: {e}\")\nexcept ModelNotFoundError as e:\n    print(f\"Model not available: {e}\")\n</code></pre>"},{"location":"api-reference/dashboard-integration/#graceful-degradation","title":"Graceful Degradation","text":"<pre><code>def safe_prediction(sensor_data):\n    \"\"\"Make prediction with fallback handling\"\"\"\n    try:\n        return engine.predict(sensor_data)\n    except Exception as e:\n        logger.error(f\"Prediction error: {e}\")\n        return {\n            \"defect_probability\": 0.0,\n            \"confidence_score\": 0.0,\n            \"alert_level\": \"unknown\",\n            \"error\": str(e)\n        }\n</code></pre> <p>Next: System Overview \u2192</p>"},{"location":"api-reference/data-endpoints/","title":"Data Endpoints","text":"<p>The Data API provides access to sensor data, historical records, and data management capabilities for the Steel Defect Prediction System.</p>"},{"location":"api-reference/data-endpoints/#base-url","title":"Base URL","text":"<pre><code>http://localhost:8000/api/v1/data\n</code></pre>"},{"location":"api-reference/data-endpoints/#endpoints-overview","title":"Endpoints Overview","text":"Method Endpoint Description GET <code>/data/sensors/current</code> Get current sensor readings GET <code>/data/sensors/history</code> Get historical sensor data POST <code>/data/sensors</code> Submit new sensor data GET <code>/data/casts</code> Get casting information GET <code>/data/quality</code> Get quality inspection data POST <code>/data/export</code> Export data to various formats"},{"location":"api-reference/data-endpoints/#current-sensor-data","title":"Current Sensor Data","text":"<p>GET <code>/api/v1/data/sensors/current</code></p> <p>Get the most recent sensor readings from all production lines.</p>"},{"location":"api-reference/data-endpoints/#response","title":"Response","text":"<pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"lines\": {\n    \"LINE_01\": {\n      \"mold_temperature\": 1525.4,\n      \"casting_speed\": 1.12,\n      \"cooling_water_flow\": 195.8,\n      \"oxygen_content\": 0.025,\n      \"carbon_content\": 0.18,\n      \"steel_grade\": \"304L\",\n      \"status\": \"active\",\n      \"last_updated\": \"2024-01-15T10:29:55Z\"\n    },\n    \"LINE_02\": {\n      \"mold_temperature\": 1530.1,\n      \"casting_speed\": 1.08,\n      \"cooling_water_flow\": 198.2,\n      \"oxygen_content\": 0.028,\n      \"carbon_content\": 0.16,\n      \"steel_grade\": \"316L\",\n      \"status\": \"active\",\n      \"last_updated\": \"2024-01-15T10:29:58Z\"\n    }\n  }\n}\n</code></pre>"},{"location":"api-reference/data-endpoints/#query-parameters","title":"Query Parameters","text":"Parameter Type Description <code>line_id</code> string Filter by production line <code>format</code> string Response format (json, csv)"},{"location":"api-reference/data-endpoints/#historical-sensor-data","title":"Historical Sensor Data","text":"<p>GET <code>/api/v1/data/sensors/history</code></p> <p>Retrieve historical sensor data with flexible filtering options.</p>"},{"location":"api-reference/data-endpoints/#query-parameters_1","title":"Query Parameters","text":"Parameter Type Description Required <code>start_date</code> string Start date (ISO 8601) Yes <code>end_date</code> string End date (ISO 8601) Yes <code>line_id</code> string Production line ID No <code>parameters</code> array Sensor parameters to include No <code>aggregation</code> string Data aggregation (raw, minute, hour, day) No <code>limit</code> integer Maximum records (max 10000) No"},{"location":"api-reference/data-endpoints/#example-request","title":"Example Request","text":"<pre><code>import requests\n\nresponse = requests.get(\n    'http://localhost:8000/api/v1/data/sensors/history',\n    headers={'Authorization': 'Bearer your_access_token'},\n    params={\n        'start_date': '2024-01-14T00:00:00Z',\n        'end_date': '2024-01-15T00:00:00Z',\n        'line_id': 'LINE_01',\n        'parameters': ['mold_temperature', 'casting_speed'],\n        'aggregation': 'minute'\n    }\n)\n\ndata = response.json()\n</code></pre>"},{"location":"api-reference/data-endpoints/#response_1","title":"Response","text":"<pre><code>{\n  \"data\": [\n    {\n      \"timestamp\": \"2024-01-14T00:01:00Z\",\n      \"line_id\": \"LINE_01\",\n      \"mold_temperature\": 1523.2,\n      \"casting_speed\": 1.10\n    },\n    {\n      \"timestamp\": \"2024-01-14T00:02:00Z\", \n      \"line_id\": \"LINE_01\",\n      \"mold_temperature\": 1524.1,\n      \"casting_speed\": 1.11\n    }\n  ],\n  \"metadata\": {\n    \"total_records\": 1440,\n    \"aggregation\": \"minute\",\n    \"parameters\": [\"mold_temperature\", \"casting_speed\"]\n  }\n}\n</code></pre>"},{"location":"api-reference/data-endpoints/#submit-sensor-data","title":"Submit Sensor Data","text":"<p>POST <code>/api/v1/data/sensors</code></p> <p>Submit new sensor readings to the system.</p>"},{"location":"api-reference/data-endpoints/#request-body","title":"Request Body","text":"<pre><code>{\n  \"line_id\": \"LINE_01\",\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"sensor_data\": {\n    \"mold_temperature\": 1525.4,\n    \"casting_speed\": 1.12,\n    \"cooling_water_flow\": 195.8,\n    \"oxygen_content\": 0.025,\n    \"carbon_content\": 0.18,\n    \"steel_grade\": \"304L\"\n  },\n  \"quality_flags\": {\n    \"temperature_sensor\": \"good\",\n    \"speed_sensor\": \"good\", \n    \"flow_sensor\": \"warning\"\n  }\n}\n</code></pre>"},{"location":"api-reference/data-endpoints/#response_2","title":"Response","text":"<pre><code>{\n  \"status\": \"success\",\n  \"data_id\": \"data_abc123\",\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"validation_results\": {\n    \"valid_parameters\": 6,\n    \"warnings\": [\"flow_sensor quality flag is warning\"],\n    \"errors\": []\n  }\n}\n</code></pre>"},{"location":"api-reference/data-endpoints/#casting-information","title":"Casting Information","text":"<p>GET <code>/api/v1/data/casts</code></p> <p>Retrieve information about casting operations.</p>"},{"location":"api-reference/data-endpoints/#query-parameters_2","title":"Query Parameters","text":"Parameter Type Description <code>cast_id</code> string Specific cast ID <code>start_date</code> string Start date filter <code>end_date</code> string End date filter <code>steel_grade</code> string Steel grade filter <code>status</code> string Cast status (active, completed, aborted)"},{"location":"api-reference/data-endpoints/#response_3","title":"Response","text":"<pre><code>{\n  \"casts\": [\n    {\n      \"cast_id\": \"CAST_20240115_001\",\n      \"line_id\": \"LINE_01\",\n      \"steel_grade\": \"304L\",\n      \"start_time\": \"2024-01-15T08:00:00Z\",\n      \"end_time\": \"2024-01-15T12:30:00Z\",\n      \"status\": \"completed\",\n      \"total_weight\": 25.4,\n      \"quality_score\": 0.92,\n      \"defect_count\": 2,\n      \"operator_id\": \"OP_001\"\n    }\n  ],\n  \"pagination\": {\n    \"total\": 156,\n    \"limit\": 20,\n    \"offset\": 0\n  }\n}\n</code></pre>"},{"location":"api-reference/data-endpoints/#quality-data","title":"Quality Data","text":"<p>GET <code>/api/v1/data/quality</code></p> <p>Access quality inspection data and test results.</p>"},{"location":"api-reference/data-endpoints/#response_4","title":"Response","text":"<pre><code>{\n  \"quality_records\": [\n    {\n      \"inspection_id\": \"QI_20240115_001\",\n      \"cast_id\": \"CAST_20240115_001\",\n      \"inspection_time\": \"2024-01-15T13:00:00Z\",\n      \"inspector_id\": \"QC_002\",\n      \"results\": {\n        \"surface_quality\": \"excellent\",\n        \"dimensional_accuracy\": 0.98,\n        \"mechanical_properties\": {\n          \"tensile_strength\": 520,\n          \"yield_strength\": 210,\n          \"elongation\": 40\n        },\n        \"chemical_composition\": {\n          \"carbon\": 0.18,\n          \"chromium\": 18.2,\n          \"nickel\": 8.1\n        },\n        \"defects\": [\n          {\n            \"type\": \"surface_crack\",\n            \"severity\": \"minor\",\n            \"location\": \"section_B\"\n          }\n        ]\n      },\n      \"overall_grade\": \"A\"\n    }\n  ]\n}\n</code></pre>"},{"location":"api-reference/data-endpoints/#data-export","title":"Data Export","text":"<p>POST <code>/api/v1/data/export</code></p> <p>Export data in various formats for analysis or reporting.</p>"},{"location":"api-reference/data-endpoints/#request-body_1","title":"Request Body","text":"<pre><code>{\n  \"export_type\": \"sensor_data\",\n  \"format\": \"csv\",\n  \"filters\": {\n    \"start_date\": \"2024-01-14T00:00:00Z\",\n    \"end_date\": \"2024-01-15T00:00:00Z\",\n    \"line_id\": \"LINE_01\",\n    \"parameters\": [\"mold_temperature\", \"casting_speed\", \"defect_probability\"]\n  },\n  \"options\": {\n    \"include_headers\": true,\n    \"aggregation\": \"minute\",\n    \"compression\": \"gzip\"\n  }\n}\n</code></pre>"},{"location":"api-reference/data-endpoints/#response_5","title":"Response","text":"<pre><code>{\n  \"export_id\": \"export_xyz789\",\n  \"status\": \"processing\",\n  \"estimated_completion\": \"2024-01-15T10:35:00Z\",\n  \"download_url\": null,\n  \"file_size_estimate\": \"2.5 MB\"\n}\n</code></pre>"},{"location":"api-reference/data-endpoints/#check-export-status","title":"Check Export Status","text":"<p>GET <code>/api/v1/data/export/{export_id}/status</code></p> <pre><code>{\n  \"export_id\": \"export_xyz789\",\n  \"status\": \"completed\",\n  \"download_url\": \"https://api.example.com/downloads/export_xyz789.csv.gz\",\n  \"file_size\": \"2.3 MB\",\n  \"expires_at\": \"2024-01-16T10:35:00Z\"\n}\n</code></pre>"},{"location":"api-reference/data-endpoints/#data-validation","title":"Data Validation","text":"<p>POST <code>/api/v1/data/validate</code></p> <p>Validate sensor data before submission.</p>"},{"location":"api-reference/data-endpoints/#request-body_2","title":"Request Body","text":"<pre><code>{\n  \"sensor_data\": {\n    \"mold_temperature\": 1525.4,\n    \"casting_speed\": 1.12,\n    \"cooling_water_flow\": 195.8\n  },\n  \"validation_rules\": [\"range_check\", \"trend_analysis\", \"anomaly_detection\"]\n}\n</code></pre>"},{"location":"api-reference/data-endpoints/#response_6","title":"Response","text":"<pre><code>{\n  \"validation_results\": {\n    \"overall_status\": \"valid\",\n    \"checks\": {\n      \"range_check\": {\n        \"status\": \"passed\",\n        \"details\": \"All parameters within normal ranges\"\n      },\n      \"trend_analysis\": {\n        \"status\": \"warning\",\n        \"details\": \"Temperature trending upward\"\n      },\n      \"anomaly_detection\": {\n        \"status\": \"passed\", \n        \"details\": \"No anomalies detected\"\n      }\n    },\n    \"recommendations\": [\n      \"Monitor temperature trend closely\"\n    ]\n  }\n}\n</code></pre>"},{"location":"api-reference/data-endpoints/#data-statistics","title":"Data Statistics","text":"<p>GET <code>/api/v1/data/statistics</code></p> <p>Get statistical summaries of sensor data.</p>"},{"location":"api-reference/data-endpoints/#query-parameters_3","title":"Query Parameters","text":"Parameter Type Description <code>parameter</code> string Sensor parameter name <code>time_period</code> string Time period (hour, day, week, month) <code>line_id</code> string Production line filter"},{"location":"api-reference/data-endpoints/#response_7","title":"Response","text":"<pre><code>{\n  \"parameter\": \"mold_temperature\",\n  \"time_period\": \"day\",\n  \"statistics\": {\n    \"count\": 1440,\n    \"mean\": 1525.7,\n    \"median\": 1525.4,\n    \"std_dev\": 12.3,\n    \"min\": 1498.2,\n    \"max\": 1553.1,\n    \"percentiles\": {\n      \"25\": 1517.8,\n      \"75\": 1533.2,\n      \"95\": 1546.9\n    }\n  },\n  \"trend\": {\n    \"direction\": \"stable\",\n    \"slope\": 0.02,\n    \"r_squared\": 0.15\n  }\n}\n</code></pre>"},{"location":"api-reference/data-endpoints/#real-time-data-stream","title":"Real-time Data Stream","text":"<p>GET <code>/api/v1/data/stream</code> (WebSocket)</p> <p>Subscribe to real-time sensor data updates.</p>"},{"location":"api-reference/data-endpoints/#websocket-example","title":"WebSocket Example","text":"<pre><code>import websocket\nimport json\n\ndef on_message(ws, message):\n    data = json.loads(message)\n    print(f\"Line {data['line_id']}: Temp={data['mold_temperature']}\")\n\ndef on_open(ws):\n    # Subscribe to specific parameters\n    ws.send(json.dumps({\n        \"action\": \"subscribe\",\n        \"line_id\": \"LINE_01\",\n        \"parameters\": [\"mold_temperature\", \"casting_speed\"]\n    }))\n\nws = websocket.WebSocketApp(\n    \"ws://localhost:8000/api/v1/data/stream\",\n    header={\"Authorization\": \"Bearer your_access_token\"},\n    on_message=on_message,\n    on_open=on_open\n)\n\nws.run_forever()\n</code></pre>"},{"location":"api-reference/data-endpoints/#error-handling","title":"Error Handling","text":""},{"location":"api-reference/data-endpoints/#common-error-codes","title":"Common Error Codes","text":"Status Code Error Code Description 400 <code>invalid_date_range</code> Invalid date range specified 400 <code>invalid_parameters</code> Invalid sensor parameters 413 <code>payload_too_large</code> Request payload exceeds limit 422 <code>validation_failed</code> Data validation failed 429 <code>rate_limit_exceeded</code> Too many requests"},{"location":"api-reference/data-endpoints/#example-error-response","title":"Example Error Response","text":"<pre><code>{\n  \"error\": {\n    \"code\": \"invalid_date_range\",\n    \"message\": \"End date must be after start date\",\n    \"details\": {\n      \"start_date\": \"2024-01-15T00:00:00Z\",\n      \"end_date\": \"2024-01-14T00:00:00Z\"\n    }\n  },\n  \"request_id\": \"req_67890\"\n}\n</code></pre> <p>This Data API provides comprehensive access to all sensor data and operational information needed for effective steel defect monitoring and analysis.</p>"},{"location":"api-reference/monitoring-endpoints/","title":"Monitoring Endpoints","text":"<p>The Monitoring API provides system health, performance metrics, and operational monitoring capabilities for the Steel Defect Prediction System.</p>"},{"location":"api-reference/monitoring-endpoints/#base-url","title":"Base URL","text":"<pre><code>http://localhost:8000/api/v1/monitoring\n</code></pre>"},{"location":"api-reference/monitoring-endpoints/#endpoints-overview","title":"Endpoints Overview","text":"Method Endpoint Description GET <code>/monitoring/health</code> System health check GET <code>/monitoring/metrics</code> Performance metrics GET <code>/monitoring/alerts</code> Active system alerts GET <code>/monitoring/status</code> Overall system status POST <code>/monitoring/alerts/acknowledge</code> Acknowledge alerts"},{"location":"api-reference/monitoring-endpoints/#health-check","title":"Health Check","text":"<p>GET <code>/api/v1/monitoring/health</code></p> <p>Basic health check endpoint for load balancers and monitoring systems.</p>"},{"location":"api-reference/monitoring-endpoints/#response","title":"Response","text":"<pre><code>{\n  \"status\": \"healthy\",\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"version\": \"2.1.0\",\n  \"uptime_seconds\": 86400,\n  \"components\": {\n    \"database\": \"healthy\",\n    \"prediction_engine\": \"healthy\", \n    \"cache\": \"healthy\",\n    \"message_queue\": \"healthy\"\n  }\n}\n</code></pre>"},{"location":"api-reference/monitoring-endpoints/#status-codes","title":"Status Codes","text":"<ul> <li><code>200 OK</code>: System is healthy</li> <li><code>503 Service Unavailable</code>: System is unhealthy</li> </ul>"},{"location":"api-reference/monitoring-endpoints/#detailed-health","title":"Detailed Health","text":"<p>GET <code>/api/v1/monitoring/health/detailed</code></p> <p>Comprehensive health information including component details.</p>"},{"location":"api-reference/monitoring-endpoints/#response_1","title":"Response","text":"<pre><code>{\n  \"status\": \"healthy\",\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"overall_score\": 0.98,\n  \"components\": {\n    \"database\": {\n      \"status\": \"healthy\",\n      \"response_time_ms\": 15,\n      \"connection_pool\": {\n        \"active\": 5,\n        \"idle\": 15,\n        \"max\": 20\n      },\n      \"last_check\": \"2024-01-15T10:29:55Z\"\n    },\n    \"prediction_engine\": {\n      \"status\": \"healthy\",\n      \"model_version\": \"v2.1.0\",\n      \"avg_prediction_time_ms\": 45,\n      \"predictions_per_second\": 22.5,\n      \"gpu_utilization\": 0.65,\n      \"memory_usage_mb\": 2048\n    },\n    \"cache\": {\n      \"status\": \"healthy\",\n      \"hit_rate\": 0.89,\n      \"memory_usage_mb\": 512,\n      \"evictions_per_hour\": 150\n    },\n    \"message_queue\": {\n      \"status\": \"healthy\",\n      \"queue_depth\": 23,\n      \"messages_per_second\": 45.2,\n      \"consumer_lag_ms\": 120\n    }\n  },\n  \"dependencies\": {\n    \"external_sensors\": {\n      \"LINE_01\": \"connected\",\n      \"LINE_02\": \"connected\",\n      \"LINE_03\": \"disconnected\"\n    },\n    \"scada_system\": \"connected\",\n    \"notification_service\": \"connected\"\n  }\n}\n</code></pre>"},{"location":"api-reference/monitoring-endpoints/#performance-metrics","title":"Performance Metrics","text":"<p>GET <code>/api/v1/monitoring/metrics</code></p> <p>Retrieve system performance metrics in Prometheus format.</p>"},{"location":"api-reference/monitoring-endpoints/#query-parameters","title":"Query Parameters","text":"Parameter Type Description <code>format</code> string Response format (prometheus, json) <code>category</code> string Metric category filter <code>time_range</code> string Time range for metrics"},{"location":"api-reference/monitoring-endpoints/#response-json-format","title":"Response (JSON Format)","text":"<pre><code>{\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"metrics\": {\n    \"system\": {\n      \"cpu_usage_percent\": 45.2,\n      \"memory_usage_percent\": 67.8,\n      \"disk_usage_percent\": 34.1,\n      \"network_io_mbps\": 125.6\n    },\n    \"application\": {\n      \"total_requests\": 150245,\n      \"requests_per_second\": 42.5,\n      \"average_response_time_ms\": 89,\n      \"error_rate_percent\": 0.12,\n      \"active_connections\": 156\n    },\n    \"predictions\": {\n      \"total_predictions\": 25689,\n      \"predictions_per_hour\": 1250,\n      \"average_confidence\": 0.87,\n      \"high_risk_predictions\": 256,\n      \"model_accuracy\": 0.923\n    },\n    \"data_quality\": {\n      \"sensor_uptime_percent\": 98.5,\n      \"data_completeness_percent\": 97.2,\n      \"anomaly_rate_percent\": 2.1,\n      \"validation_errors_per_hour\": 5\n    }\n  }\n}\n</code></pre>"},{"location":"api-reference/monitoring-endpoints/#response-prometheus-format","title":"Response (Prometheus Format)","text":"<pre><code># HELP steel_predictions_total Total number of predictions made\n# TYPE steel_predictions_total counter\nsteel_predictions_total 25689\n\n# HELP steel_prediction_accuracy Current model accuracy\n# TYPE steel_prediction_accuracy gauge  \nsteel_prediction_accuracy 0.923\n\n# HELP steel_response_time_seconds Response time in seconds\n# TYPE steel_response_time_seconds histogram\nsteel_response_time_seconds_bucket{le=\"0.1\"} 12450\nsteel_response_time_seconds_bucket{le=\"0.5\"} 24890\nsteel_response_time_seconds_bucket{le=\"1.0\"} 25689\n</code></pre>"},{"location":"api-reference/monitoring-endpoints/#system-status","title":"System Status","text":"<p>GET <code>/api/v1/monitoring/status</code></p> <p>Overall system operational status with summary information.</p>"},{"location":"api-reference/monitoring-endpoints/#response_2","title":"Response","text":"<pre><code>{\n  \"overall_status\": \"operational\",\n  \"status_code\": 200,\n  \"last_updated\": \"2024-01-15T10:30:00Z\",\n  \"summary\": {\n    \"total_lines\": 3,\n    \"active_lines\": 2,\n    \"inactive_lines\": 1,\n    \"total_alerts\": 5,\n    \"critical_alerts\": 0,\n    \"warning_alerts\": 3,\n    \"info_alerts\": 2\n  },\n  \"production_lines\": {\n    \"LINE_01\": {\n      \"status\": \"active\",\n      \"current_cast\": \"CAST_20240115_001\",\n      \"defect_probability\": 0.156,\n      \"last_prediction\": \"2024-01-15T10:29:55Z\"\n    },\n    \"LINE_02\": {\n      \"status\": \"active\", \n      \"current_cast\": \"CAST_20240115_002\",\n      \"defect_probability\": 0.734,\n      \"last_prediction\": \"2024-01-15T10:29:58Z\"\n    },\n    \"LINE_03\": {\n      \"status\": \"maintenance\",\n      \"last_active\": \"2024-01-15T08:00:00Z\",\n      \"estimated_return\": \"2024-01-15T14:00:00Z\"\n    }\n  },\n  \"recent_activity\": {\n    \"predictions_last_hour\": 1250,\n    \"alerts_last_hour\": 8,\n    \"data_points_received\": 15600\n  }\n}\n</code></pre>"},{"location":"api-reference/monitoring-endpoints/#active-alerts","title":"Active Alerts","text":"<p>GET <code>/api/v1/monitoring/alerts</code></p> <p>Retrieve current system alerts and notifications.</p>"},{"location":"api-reference/monitoring-endpoints/#query-parameters_1","title":"Query Parameters","text":"Parameter Type Description <code>severity</code> string Filter by severity (critical, warning, info) <code>category</code> string Filter by category <code>acknowledged</code> boolean Filter by acknowledgment status <code>limit</code> integer Maximum number of alerts"},{"location":"api-reference/monitoring-endpoints/#response_3","title":"Response","text":"<pre><code>{\n  \"alerts\": [\n    {\n      \"alert_id\": \"ALT_001\",\n      \"severity\": \"warning\",\n      \"category\": \"data_quality\",\n      \"title\": \"Sensor Communication Intermittent\",\n      \"description\": \"LINE_03 temperature sensor experiencing intermittent communication\",\n      \"created_at\": \"2024-01-15T09:15:00Z\",\n      \"acknowledged\": false,\n      \"line_id\": \"LINE_03\",\n      \"sensor_id\": \"TEMP_03\",\n      \"impact\": \"Medium - May affect prediction accuracy\"\n    },\n    {\n      \"alert_id\": \"ALT_002\",\n      \"severity\": \"info\",\n      \"category\": \"system\",\n      \"title\": \"High CPU Usage\",\n      \"description\": \"CPU usage above 80% for 10 minutes\",\n      \"created_at\": \"2024-01-15T10:20:00Z\",\n      \"acknowledged\": true,\n      \"acknowledged_by\": \"admin_001\",\n      \"acknowledged_at\": \"2024-01-15T10:25:00Z\"\n    }\n  ],\n  \"summary\": {\n    \"total_alerts\": 5,\n    \"by_severity\": {\n      \"critical\": 0,\n      \"warning\": 3,\n      \"info\": 2\n    },\n    \"acknowledged\": 2,\n    \"unacknowledged\": 3\n  }\n}\n</code></pre>"},{"location":"api-reference/monitoring-endpoints/#acknowledge-alerts","title":"Acknowledge Alerts","text":"<p>POST <code>/api/v1/monitoring/alerts/acknowledge</code></p> <p>Acknowledge one or more system alerts.</p>"},{"location":"api-reference/monitoring-endpoints/#request-body","title":"Request Body","text":"<pre><code>{\n  \"alert_ids\": [\"ALT_001\", \"ALT_002\"],\n  \"acknowledged_by\": \"operator_001\",\n  \"note\": \"Investigating sensor communication issue\"\n}\n</code></pre>"},{"location":"api-reference/monitoring-endpoints/#response_4","title":"Response","text":"<pre><code>{\n  \"acknowledged_count\": 2,\n  \"failed_count\": 0,\n  \"results\": [\n    {\n      \"alert_id\": \"ALT_001\",\n      \"status\": \"acknowledged\",\n      \"acknowledged_at\": \"2024-01-15T10:30:00Z\"\n    },\n    {\n      \"alert_id\": \"ALT_002\", \n      \"status\": \"acknowledged\",\n      \"acknowledged_at\": \"2024-01-15T10:30:00Z\"\n    }\n  ]\n}\n</code></pre>"},{"location":"api-reference/monitoring-endpoints/#performance-history","title":"Performance History","text":"<p>GET <code>/api/v1/monitoring/performance/history</code></p> <p>Historical performance metrics for trend analysis.</p>"},{"location":"api-reference/monitoring-endpoints/#query-parameters_2","title":"Query Parameters","text":"Parameter Type Description <code>metric</code> string Specific metric name <code>start_time</code> string Start time (ISO 8601) <code>end_time</code> string End time (ISO 8601) <code>resolution</code> string Data resolution (minute, hour, day)"},{"location":"api-reference/monitoring-endpoints/#response_5","title":"Response","text":"<pre><code>{\n  \"metric\": \"predictions_per_hour\",\n  \"resolution\": \"hour\",\n  \"data_points\": [\n    {\n      \"timestamp\": \"2024-01-15T08:00:00Z\",\n      \"value\": 1150,\n      \"quality\": \"good\"\n    },\n    {\n      \"timestamp\": \"2024-01-15T09:00:00Z\",\n      \"value\": 1275,\n      \"quality\": \"good\"\n    },\n    {\n      \"timestamp\": \"2024-01-15T10:00:00Z\",\n      \"value\": 1320,\n      \"quality\": \"good\"\n    }\n  ],\n  \"statistics\": {\n    \"average\": 1248.3,\n    \"min\": 1150,\n    \"max\": 1320,\n    \"trend\": \"increasing\"\n  }\n}\n</code></pre>"},{"location":"api-reference/monitoring-endpoints/#system-logs","title":"System Logs","text":"<p>GET <code>/api/v1/monitoring/logs</code></p> <p>Access system logs for troubleshooting and analysis.</p>"},{"location":"api-reference/monitoring-endpoints/#query-parameters_3","title":"Query Parameters","text":"Parameter Type Description <code>level</code> string Log level (debug, info, warning, error) <code>component</code> string Component filter <code>start_time</code> string Start time filter <code>end_time</code> string End time filter <code>limit</code> integer Maximum log entries"},{"location":"api-reference/monitoring-endpoints/#response_6","title":"Response","text":"<pre><code>{\n  \"logs\": [\n    {\n      \"timestamp\": \"2024-01-15T10:29:55Z\",\n      \"level\": \"info\",\n      \"component\": \"prediction_engine\",\n      \"message\": \"Prediction completed for LINE_01\",\n      \"metadata\": {\n        \"prediction_id\": \"pred_789abc\",\n        \"processing_time_ms\": 45,\n        \"confidence\": 0.892\n      }\n    },\n    {\n      \"timestamp\": \"2024-01-15T10:29:50Z\",\n      \"level\": \"warning\",\n      \"component\": \"data_collector\",\n      \"message\": \"Sensor reading outside normal range\",\n      \"metadata\": {\n        \"line_id\": \"LINE_02\",\n        \"sensor\": \"mold_temperature\",\n        \"value\": 1580.5,\n        \"normal_range\": \"1480-1570\"\n      }\n    }\n  ],\n  \"pagination\": {\n    \"total\": 5647,\n    \"limit\": 100,\n    \"offset\": 0\n  }\n}\n</code></pre>"},{"location":"api-reference/monitoring-endpoints/#websocket-monitoring","title":"WebSocket Monitoring","text":"<p>WebSocket <code>/api/v1/monitoring/stream</code></p> <p>Real-time monitoring updates via WebSocket connection.</p>"},{"location":"api-reference/monitoring-endpoints/#connection-example","title":"Connection Example","text":"<pre><code>import websocket\nimport json\n\ndef on_message(ws, message):\n    data = json.loads(message)\n    if data['type'] == 'metric_update':\n        print(f\"Metric update: {data['metric']} = {data['value']}\")\n    elif data['type'] == 'alert':\n        print(f\"New alert: {data['severity']} - {data['title']}\")\n\ndef on_open(ws):\n    # Subscribe to specific monitoring channels\n    ws.send(json.dumps({\n        \"action\": \"subscribe\",\n        \"channels\": [\"system_metrics\", \"alerts\", \"performance\"]\n    }))\n\nws = websocket.WebSocketApp(\n    \"ws://localhost:8000/api/v1/monitoring/stream\",\n    header={\"Authorization\": \"Bearer your_access_token\"},\n    on_message=on_message,\n    on_open=on_open\n)\n\nws.run_forever()\n</code></pre>"},{"location":"api-reference/monitoring-endpoints/#custom-monitoring","title":"Custom Monitoring","text":"<p>POST <code>/api/v1/monitoring/custom-metrics</code></p> <p>Submit custom application metrics.</p>"},{"location":"api-reference/monitoring-endpoints/#request-body_1","title":"Request Body","text":"<pre><code>{\n  \"metrics\": [\n    {\n      \"name\": \"custom_efficiency_score\",\n      \"value\": 0.87,\n      \"timestamp\": \"2024-01-15T10:30:00Z\",\n      \"tags\": {\n        \"line_id\": \"LINE_01\",\n        \"shift\": \"day\"\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"api-reference/monitoring-endpoints/#response_7","title":"Response","text":"<pre><code>{\n  \"accepted_metrics\": 1,\n  \"rejected_metrics\": 0,\n  \"processing_time_ms\": 12\n}\n</code></pre> <p>This monitoring API provides comprehensive observability into the Steel Defect Prediction System, enabling proactive maintenance and optimization of system performance.</p>"},{"location":"api-reference/prediction-endpoints/","title":"Prediction Endpoints","text":"<p>The Prediction API provides real-time defect prediction capabilities for continuous steel casting operations.</p>"},{"location":"api-reference/prediction-endpoints/#base-url","title":"Base URL","text":"<pre><code>http://localhost:8000/api/v1/predictions\n</code></pre>"},{"location":"api-reference/prediction-endpoints/#endpoints-overview","title":"Endpoints Overview","text":"Method Endpoint Description POST <code>/predictions</code> Create new prediction GET <code>/predictions/{id}</code> Get prediction by ID GET <code>/predictions</code> List predictions POST <code>/predictions/batch</code> Batch predictions GET <code>/predictions/stream</code> Real-time prediction stream"},{"location":"api-reference/prediction-endpoints/#create-prediction","title":"Create Prediction","text":"<p>POST <code>/api/v1/predictions</code></p> <p>Create a new defect prediction based on sensor data.</p>"},{"location":"api-reference/prediction-endpoints/#request-body","title":"Request Body","text":"<pre><code>{\n  \"sensor_data\": {\n    \"mold_temperature\": 1525.4,\n    \"casting_speed\": 1.12,\n    \"cooling_water_flow\": 195.8,\n    \"oxygen_content\": 0.025,\n    \"carbon_content\": 0.18,\n    \"steel_grade\": \"304L\",\n    \"tundish_temperature\": 1545.0\n  },\n  \"metadata\": {\n    \"cast_id\": \"CAST_20240115_001\",\n    \"line_id\": \"LINE_01\",\n    \"operator_id\": \"OP_001\",\n    \"timestamp\": \"2024-01-15T10:30:00Z\"\n  }\n}\n</code></pre>"},{"location":"api-reference/prediction-endpoints/#response","title":"Response","text":"<pre><code>{\n  \"prediction_id\": \"pred_789abc123\",\n  \"defect_probability\": 0.156,\n  \"confidence\": 0.892,\n  \"risk_level\": \"low\",\n  \"processing_time_ms\": 45,\n  \"model_version\": \"v2.1.0\",\n  \"prediction_details\": {\n    \"feature_importance\": {\n      \"mold_temperature\": 0.342,\n      \"casting_speed\": 0.287,\n      \"cooling_water_flow\": 0.198,\n      \"oxygen_content\": 0.173\n    },\n    \"threshold_analysis\": {\n      \"warning_threshold\": 0.6,\n      \"critical_threshold\": 0.8,\n      \"current_status\": \"normal\"\n    }\n  },\n  \"timestamp\": \"2024-01-15T10:30:00.123Z\"\n}\n</code></pre>"},{"location":"api-reference/prediction-endpoints/#example-usage","title":"Example Usage","text":"<pre><code>import requests\n\n# Prediction request\nresponse = requests.post(\n    'http://localhost:8000/api/v1/predictions',\n    headers={\n        'Authorization': 'Bearer your_access_token',\n        'Content-Type': 'application/json'\n    },\n    json={\n        \"sensor_data\": {\n            \"mold_temperature\": 1525.4,\n            \"casting_speed\": 1.12,\n            \"cooling_water_flow\": 195.8,\n            \"oxygen_content\": 0.025,\n            \"carbon_content\": 0.18,\n            \"steel_grade\": \"304L\"\n        },\n        \"metadata\": {\n            \"cast_id\": \"CAST_20240115_001\",\n            \"line_id\": \"LINE_01\"\n        }\n    }\n)\n\nprediction = response.json()\nprint(f\"Defect probability: {prediction['defect_probability']:.3f}\")\nprint(f\"Risk level: {prediction['risk_level']}\")\n</code></pre>"},{"location":"api-reference/prediction-endpoints/#get-prediction-by-id","title":"Get Prediction by ID","text":"<p>GET <code>/api/v1/predictions/{prediction_id}</code></p> <p>Retrieve a specific prediction by its ID.</p>"},{"location":"api-reference/prediction-endpoints/#response_1","title":"Response","text":"<pre><code>{\n  \"prediction_id\": \"pred_789abc123\",\n  \"defect_probability\": 0.156,\n  \"confidence\": 0.892,\n  \"risk_level\": \"low\",\n  \"sensor_data\": {\n    \"mold_temperature\": 1525.4,\n    \"casting_speed\": 1.12,\n    \"cooling_water_flow\": 195.8\n  },\n  \"created_at\": \"2024-01-15T10:30:00.123Z\",\n  \"model_version\": \"v2.1.0\"\n}\n</code></pre>"},{"location":"api-reference/prediction-endpoints/#list-predictions","title":"List Predictions","text":"<p>GET <code>/api/v1/predictions</code></p> <p>Retrieve a list of predictions with optional filtering.</p>"},{"location":"api-reference/prediction-endpoints/#query-parameters","title":"Query Parameters","text":"Parameter Type Description Default <code>limit</code> integer Number of results (max 100) 20 <code>offset</code> integer Results offset 0 <code>start_date</code> string Start date (ISO 8601) - <code>end_date</code> string End date (ISO 8601) - <code>cast_id</code> string Filter by cast ID - <code>line_id</code> string Filter by production line - <code>risk_level</code> string Filter by risk level - <code>min_probability</code> float Minimum defect probability - <code>max_probability</code> float Maximum defect probability -"},{"location":"api-reference/prediction-endpoints/#example-request","title":"Example Request","text":"<pre><code># List recent high-risk predictions\nresponse = requests.get(\n    'http://localhost:8000/api/v1/predictions',\n    headers={'Authorization': 'Bearer your_access_token'},\n    params={\n        'risk_level': 'high',\n        'limit': 50,\n        'start_date': '2024-01-15T00:00:00Z'\n    }\n)\n\npredictions = response.json()\n</code></pre>"},{"location":"api-reference/prediction-endpoints/#response_2","title":"Response","text":"<pre><code>{\n  \"predictions\": [\n    {\n      \"prediction_id\": \"pred_789abc123\",\n      \"defect_probability\": 0.156,\n      \"risk_level\": \"low\",\n      \"created_at\": \"2024-01-15T10:30:00Z\"\n    }\n  ],\n  \"pagination\": {\n    \"total\": 1523,\n    \"limit\": 20,\n    \"offset\": 0,\n    \"has_next\": true\n  }\n}\n</code></pre>"},{"location":"api-reference/prediction-endpoints/#batch-predictions","title":"Batch Predictions","text":"<p>POST <code>/api/v1/predictions/batch</code></p> <p>Process multiple sensor readings in a single request for improved efficiency.</p>"},{"location":"api-reference/prediction-endpoints/#request-body_1","title":"Request Body","text":"<pre><code>{\n  \"predictions\": [\n    {\n      \"id\": \"batch_001\",\n      \"sensor_data\": {\n        \"mold_temperature\": 1525.4,\n        \"casting_speed\": 1.12,\n        \"cooling_water_flow\": 195.8\n      }\n    },\n    {\n      \"id\": \"batch_002\", \n      \"sensor_data\": {\n        \"mold_temperature\": 1530.1,\n        \"casting_speed\": 1.08,\n        \"cooling_water_flow\": 198.2\n      }\n    }\n  ],\n  \"options\": {\n    \"return_details\": true,\n    \"async_processing\": false\n  }\n}\n</code></pre>"},{"location":"api-reference/prediction-endpoints/#response_3","title":"Response","text":"<pre><code>{\n  \"batch_id\": \"batch_xyz789\",\n  \"total_predictions\": 2,\n  \"processing_time_ms\": 89,\n  \"results\": [\n    {\n      \"id\": \"batch_001\",\n      \"prediction_id\": \"pred_001abc\",\n      \"defect_probability\": 0.156,\n      \"risk_level\": \"low\",\n      \"status\": \"success\"\n    },\n    {\n      \"id\": \"batch_002\",\n      \"prediction_id\": \"pred_002def\", \n      \"defect_probability\": 0.734,\n      \"risk_level\": \"high\",\n      \"status\": \"success\"\n    }\n  ]\n}\n</code></pre>"},{"location":"api-reference/prediction-endpoints/#real-time-prediction-stream","title":"Real-time Prediction Stream","text":"<p>GET <code>/api/v1/predictions/stream</code></p> <p>Establish a Server-Sent Events (SSE) connection for real-time prediction updates.</p>"},{"location":"api-reference/prediction-endpoints/#websocket-connection","title":"WebSocket Connection","text":"<pre><code>import websocket\nimport json\n\ndef on_message(ws, message):\n    prediction = json.loads(message)\n    print(f\"New prediction: {prediction['defect_probability']:.3f}\")\n\ndef on_open(ws):\n    # Subscribe to specific production line\n    ws.send(json.dumps({\n        \"action\": \"subscribe\",\n        \"line_id\": \"LINE_01\"\n    }))\n\n# Connect to WebSocket\nws = websocket.WebSocketApp(\n    \"ws://localhost:8000/api/v1/predictions/stream\",\n    header={\"Authorization\": \"Bearer your_access_token\"},\n    on_message=on_message,\n    on_open=on_open\n)\n\nws.run_forever()\n</code></pre>"},{"location":"api-reference/prediction-endpoints/#sse-connection","title":"SSE Connection","text":"<pre><code>import requests\n\n# Stream predictions via SSE\nresponse = requests.get(\n    'http://localhost:8000/api/v1/predictions/stream',\n    headers={\n        'Authorization': 'Bearer your_access_token',\n        'Accept': 'text/event-stream'\n    },\n    stream=True\n)\n\nfor line in response.iter_lines():\n    if line.startswith(b'data: '):\n        data = json.loads(line[6:])\n        print(f\"Prediction: {data['defect_probability']:.3f}\")\n</code></pre>"},{"location":"api-reference/prediction-endpoints/#model-information","title":"Model Information","text":"<p>GET <code>/api/v1/predictions/model/info</code></p> <p>Get information about the current prediction model.</p>"},{"location":"api-reference/prediction-endpoints/#response_4","title":"Response","text":"<pre><code>{\n  \"model_name\": \"LSTM_Defect_Predictor\",\n  \"version\": \"v2.1.0\",\n  \"training_date\": \"2024-01-10T08:00:00Z\",\n  \"accuracy\": 0.923,\n  \"precision\": 0.891,\n  \"recall\": 0.956,\n  \"f1_score\": 0.922,\n  \"feature_count\": 12,\n  \"supported_steel_grades\": [\"304L\", \"316L\", \"410\"],\n  \"update_frequency\": \"weekly\"\n}\n</code></pre>"},{"location":"api-reference/prediction-endpoints/#feature-importance","title":"Feature Importance","text":"<p>GET <code>/api/v1/predictions/features/importance</code></p> <p>Get global feature importance for the prediction model.</p>"},{"location":"api-reference/prediction-endpoints/#response_5","title":"Response","text":"<pre><code>{\n  \"feature_importance\": {\n    \"mold_temperature\": 0.298,\n    \"casting_speed\": 0.245,\n    \"cooling_water_flow\": 0.187,\n    \"oxygen_content\": 0.134,\n    \"carbon_content\": 0.089,\n    \"steel_grade\": 0.047\n  },\n  \"model_version\": \"v2.1.0\",\n  \"calculation_date\": \"2024-01-15T12:00:00Z\"\n}\n</code></pre>"},{"location":"api-reference/prediction-endpoints/#error-responses","title":"Error Responses","text":""},{"location":"api-reference/prediction-endpoints/#common-error-codes","title":"Common Error Codes","text":"Status Code Error Code Description 400 <code>invalid_sensor_data</code> Invalid or missing sensor data 401 <code>unauthorized</code> Authentication required 403 <code>insufficient_permissions</code> Lack required permissions 422 <code>validation_error</code> Request validation failed 429 <code>rate_limit_exceeded</code> Too many requests 500 <code>prediction_error</code> Internal prediction error"},{"location":"api-reference/prediction-endpoints/#error-response-format","title":"Error Response Format","text":"<pre><code>{\n  \"error\": {\n    \"code\": \"invalid_sensor_data\",\n    \"message\": \"Required field 'mold_temperature' is missing\",\n    \"details\": {\n      \"missing_fields\": [\"mold_temperature\"],\n      \"provided_fields\": [\"casting_speed\", \"cooling_water_flow\"]\n    }\n  },\n  \"request_id\": \"req_12345\",\n  \"timestamp\": \"2024-01-15T10:30:00Z\"\n}\n</code></pre>"},{"location":"api-reference/prediction-endpoints/#rate-limiting","title":"Rate Limiting","text":"<p>Rate limits apply to prediction endpoints:</p> <ul> <li>Standard users: 1000 predictions/hour</li> <li>Premium users: 5000 predictions/hour  </li> <li>Batch endpoint: 100 batches/hour (max 50 predictions per batch)</li> </ul> <p>Rate limit headers are included in responses:</p> <pre><code>X-RateLimit-Limit: 1000\nX-RateLimit-Remaining: 997\nX-RateLimit-Reset: 1640995200\n</code></pre>"},{"location":"api-reference/prediction-endpoints/#sdk-examples","title":"SDK Examples","text":""},{"location":"api-reference/prediction-endpoints/#python-sdk","title":"Python SDK","text":"<pre><code>from steel_defect_client import SteelDefectClient\n\nclient = SteelDefectClient(\n    base_url='http://localhost:8000',\n    api_key='your_api_key'\n)\n\n# Simple prediction\nprediction = client.predictions.create({\n    'mold_temperature': 1525.4,\n    'casting_speed': 1.12,\n    'cooling_water_flow': 195.8\n})\n\n# Batch predictions\nbatch_result = client.predictions.create_batch([\n    {'mold_temperature': 1525.4, 'casting_speed': 1.12},\n    {'mold_temperature': 1530.1, 'casting_speed': 1.08}\n])\n\n# Stream predictions\nfor prediction in client.predictions.stream():\n    print(f\"Real-time prediction: {prediction.defect_probability}\")\n</code></pre>"},{"location":"api-reference/prediction-endpoints/#javascript-sdk","title":"JavaScript SDK","text":"<pre><code>import { SteelDefectAPI } from 'steel-defect-sdk';\n\nconst api = new SteelDefectAPI({\n    baseURL: 'http://localhost:8000',\n    apiKey: 'your_api_key'\n});\n\n// Create prediction\nconst prediction = await api.predictions.create({\n    sensor_data: {\n        mold_temperature: 1525.4,\n        casting_speed: 1.12,\n        cooling_water_flow: 195.8\n    }\n});\n\n// Real-time stream\nconst stream = api.predictions.stream();\nstream.on('prediction', (data) =&gt; {\n    console.log('New prediction:', data.defect_probability);\n});\n</code></pre> <p>This prediction API provides comprehensive capabilities for integrating defect prediction into your steel casting operations with high performance and reliability.</p>"},{"location":"architecture/data-pipeline/","title":"Data Pipeline","text":"<p>The data pipeline manages the flow of sensor data from collection to storage and processing.</p>"},{"location":"architecture/data-pipeline/#overview","title":"Overview","text":"<p>Data flows through multiple stages: 1. Sensor data collection 2. Real-time validation 3. Preprocessing and cleaning 4. Storage in time-series database 5. Analytics and reporting</p>"},{"location":"architecture/data-pipeline/#pipeline-components","title":"Pipeline Components","text":""},{"location":"architecture/data-pipeline/#data-ingestion","title":"Data Ingestion","text":"<ul> <li>Real-time sensor feeds</li> <li>Batch data imports</li> <li>Data validation rules</li> </ul>"},{"location":"architecture/data-pipeline/#processing-engine","title":"Processing Engine","text":"<ul> <li>Stream processing with Apache Kafka</li> <li>Data transformation pipelines</li> <li>Quality assessment algorithms</li> </ul>"},{"location":"architecture/data-pipeline/#storage-layer","title":"Storage Layer","text":"<ul> <li>Time-series database (InfluxDB)</li> <li>Relational database (PostgreSQL)</li> <li>Object storage for models and reports</li> </ul>"},{"location":"architecture/deployment-topology/","title":"Deployment Topology","text":"<p>System deployment architecture and infrastructure components.</p>"},{"location":"architecture/deployment-topology/#production-environment","title":"Production Environment","text":"<ul> <li>Load-balanced application servers</li> <li>Database cluster with replication</li> <li>Monitoring and logging infrastructure</li> </ul>"},{"location":"architecture/deployment-topology/#high-availability","title":"High Availability","text":"<ul> <li>Multi-zone deployment</li> <li>Automatic failover</li> <li>Backup and recovery procedures</li> </ul>"},{"location":"architecture/deployment-topology/#scaling-strategy","title":"Scaling Strategy","text":"<ul> <li>Horizontal scaling for API servers</li> <li>Vertical scaling for ML processing</li> <li>Auto-scaling policies</li> </ul>"},{"location":"architecture/ml-pipeline/","title":"ML Pipeline","text":"<p>The machine learning pipeline handles model training, validation, and deployment.</p>"},{"location":"architecture/ml-pipeline/#components","title":"Components","text":""},{"location":"architecture/ml-pipeline/#data-preparation","title":"Data Preparation","text":"<ul> <li>Feature engineering</li> <li>Data splitting</li> <li>Validation datasets</li> </ul>"},{"location":"architecture/ml-pipeline/#model-training","title":"Model Training","text":"<ul> <li>LSTM neural networks</li> <li>Random Forest ensembles</li> <li>Gradient boosting models</li> </ul>"},{"location":"architecture/ml-pipeline/#model-validation","title":"Model Validation","text":"<ul> <li>Cross-validation</li> <li>Performance metrics</li> <li>A/B testing</li> </ul>"},{"location":"architecture/ml-pipeline/#deployment","title":"Deployment","text":"<ul> <li>Model versioning</li> <li>Canary deployments</li> <li>Performance monitoring</li> </ul>"},{"location":"architecture/security-model/","title":"Security Model","text":"<p>Security architecture ensuring data protection and system integrity.</p>"},{"location":"architecture/security-model/#authentication","title":"Authentication","text":"<ul> <li>JWT token-based authentication</li> <li>Role-based access control</li> <li>Multi-factor authentication</li> </ul>"},{"location":"architecture/security-model/#network-security","title":"Network Security","text":"<ul> <li>TLS encryption</li> <li>VPN connections</li> <li>Firewall rules</li> </ul>"},{"location":"architecture/security-model/#data-protection","title":"Data Protection","text":"<ul> <li>Encryption at rest</li> <li>Encryption in transit</li> <li>Data anonymization</li> </ul>"},{"location":"architecture/system-overview/","title":"System Architecture Overview","text":"<p>This document provides a comprehensive overview of the Steel Defect Prediction System architecture, including components, data flow, and integration patterns.</p>"},{"location":"architecture/system-overview/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>graph TB\n    subgraph \"Data Sources\"\n        A[Sensor Data]\n        B[Historical Data]\n        C[Configuration]\n    end\n\n    subgraph \"Data Pipeline\"\n        D[Data Ingestion]\n        E[Feature Engineering]\n        F[Data Validation]\n        G[Data Storage]\n    end\n\n    subgraph \"ML Pipeline\"\n        H[Model Training]\n        I[Model Validation]\n        J[Model Deployment]\n        K[Inference Engine]\n    end\n\n    subgraph \"Application Layer\"\n        L[Prediction API]\n        M[Dashboard Backend]\n        N[Alert System]\n        O[Monitoring]\n    end\n\n    subgraph \"User Interface\"\n        P[Web Dashboard]\n        Q[API Clients]\n        R[Alert Notifications]\n    end\n\n    A --&gt; D\n    B --&gt; D\n    C --&gt; D\n\n    D --&gt; E\n    E --&gt; F\n    F --&gt; G\n\n    G --&gt; H\n    H --&gt; I\n    I --&gt; J\n    J --&gt; K\n\n    K --&gt; L\n    K --&gt; M\n    K --&gt; N\n\n    L --&gt; Q\n    M --&gt; P\n    N --&gt; R\n    O --&gt; P\n\n    style A fill:#e1f5fe\n    style P fill:#e8f5e8\n    style K fill:#fff3e0\n    style N fill:#ffebee</code></pre>"},{"location":"architecture/system-overview/#component-architecture","title":"Component Architecture","text":""},{"location":"architecture/system-overview/#1-data-layer","title":"1. Data Layer","text":""},{"location":"architecture/system-overview/#data-sources","title":"Data Sources","text":"<ul> <li>Sensor Systems: Real-time sensor data streams</li> <li>Historical Database: Historical casting data</li> <li>Configuration Store: System and model configurations</li> <li>External Systems: ERP, MES integration</li> </ul>"},{"location":"architecture/system-overview/#data-storage","title":"Data Storage","text":"<pre><code>data/\n\u251c\u2500\u2500 raw/                 # Raw sensor data\n\u251c\u2500\u2500 processed/          # Cleaned and validated data\n\u251c\u2500\u2500 features/           # Engineered features\n\u251c\u2500\u2500 models/             # Trained model artifacts\n\u2514\u2500\u2500 results/            # Prediction results\n</code></pre>"},{"location":"architecture/system-overview/#2-processing-layer","title":"2. Processing Layer","text":""},{"location":"architecture/system-overview/#data-pipeline-components","title":"Data Pipeline Components","text":"<pre><code>graph LR\n    A[Raw Data] --&gt; B[Validation]\n    B --&gt; C[Cleaning]\n    C --&gt; D[Feature Engineering]\n    D --&gt; E[Normalization]\n    E --&gt; F[Storage]\n\n    subgraph \"Quality Checks\"\n        G[Range Validation]\n        H[Anomaly Detection]\n        I[Completeness Check]\n    end\n\n    B --&gt; G\n    B --&gt; H\n    B --&gt; I</code></pre>"},{"location":"architecture/system-overview/#key-components","title":"Key Components","text":"<ul> <li>Data Ingestion: <code>src/connectors/data_connectors.py</code></li> <li>Feature Engineering: <code>src/features/feature_engineering.py</code></li> <li>Data Validation: <code>src/data/data_validation.py</code></li> <li>Storage Management: <code>src/data/data_storage.py</code></li> </ul>"},{"location":"architecture/system-overview/#3-machine-learning-layer","title":"3. Machine Learning Layer","text":""},{"location":"architecture/system-overview/#model-architecture","title":"Model Architecture","text":"<pre><code>graph TB\n    subgraph \"Training Pipeline\"\n        A[Training Data]\n        B[Feature Selection]\n        C[Model Training]\n        D[Validation]\n        E[Model Registry]\n    end\n\n    subgraph \"Models\"\n        F[XGBoost Baseline]\n        G[LSTM Deep Learning]\n        H[Ensemble Model]\n    end\n\n    subgraph \"Inference Pipeline\"\n        I[Real-time Features]\n        J[Model Ensemble]\n        K[Prediction Output]\n        L[Confidence Scoring]\n    end\n\n    A --&gt; B\n    B --&gt; C\n    C --&gt; F\n    C --&gt; G\n    C --&gt; H\n\n    F --&gt; E\n    G --&gt; E\n    H --&gt; E\n\n    I --&gt; J\n    F --&gt; J\n    G --&gt; J\n    H --&gt; J\n\n    J --&gt; K\n    J --&gt; L</code></pre>"},{"location":"architecture/system-overview/#model-components","title":"Model Components","text":"<ul> <li>Baseline Model: XGBoost classifier with engineered features</li> <li>Deep Learning: LSTM for sequence modeling</li> <li>Ensemble: Weighted combination of multiple models</li> <li>Feature Engineering: Automated feature extraction and selection</li> </ul>"},{"location":"architecture/system-overview/#4-application-layer","title":"4. Application Layer","text":""},{"location":"architecture/system-overview/#service-architecture","title":"Service Architecture","text":"<pre><code># Core application structure\nsrc/\n\u251c\u2500\u2500 models/              # ML model implementations\n\u2502   \u251c\u2500\u2500 baseline_model.py\n\u2502   \u251c\u2500\u2500 lstm_model.py\n\u2502   \u2514\u2500\u2500 model_trainer.py\n\u251c\u2500\u2500 inference/           # Prediction engine\n\u2502   \u251c\u2500\u2500 prediction_engine.py\n\u2502   \u2514\u2500\u2500 inference_pipeline.py\n\u251c\u2500\u2500 visualization/       # Dashboard components\n\u2502   \u251c\u2500\u2500 dashboard.py\n\u2502   \u2514\u2500\u2500 components/\n\u251c\u2500\u2500 monitoring/          # System monitoring\n\u2502   \u251c\u2500\u2500 alert_system.py\n\u2502   \u2514\u2500\u2500 health_checks.py\n\u2514\u2500\u2500 utils/              # Shared utilities\n    \u251c\u2500\u2500 config.py\n    \u2514\u2500\u2500 logging.py\n</code></pre>"},{"location":"architecture/system-overview/#api-design","title":"API Design","text":"<pre><code>graph LR\n    subgraph \"API Layer\"\n        A[FastAPI App]\n        B[Authentication]\n        C[Rate Limiting]\n        D[Request Validation]\n    end\n\n    subgraph \"Business Logic\"\n        E[Prediction Service]\n        F[Data Service]\n        G[Alert Service]\n        H[Monitoring Service]\n    end\n\n    subgraph \"Data Access\"\n        I[Model Repository]\n        J[Data Repository]\n        K[Config Repository]\n    end\n\n    A --&gt; B\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    D --&gt; F\n    D --&gt; G\n    D --&gt; H\n\n    E --&gt; I\n    F --&gt; J\n    G --&gt; K\n    H --&gt; J</code></pre>"},{"location":"architecture/system-overview/#5-user-interface-layer","title":"5. User Interface Layer","text":""},{"location":"architecture/system-overview/#dashboard-architecture","title":"Dashboard Architecture","text":"<p>The dashboard is built using Dash (Plotly) with a component-based architecture:</p> <pre><code># Dashboard component structure\nsrc/visualization/\n\u251c\u2500\u2500 dashboard.py         # Main dashboard app\n\u251c\u2500\u2500 components/          # Reusable UI components\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 prediction_display.py\n\u2502   \u251c\u2500\u2500 model_comparison.py\n\u2502   \u251c\u2500\u2500 historical_analysis.py\n\u2502   \u251c\u2500\u2500 alert_management.py\n\u2502   \u2514\u2500\u2500 sensor_monitoring.py\n\u251c\u2500\u2500 layouts/            # Page layouts\n\u251c\u2500\u2500 callbacks/          # Interactive callbacks\n\u2514\u2500\u2500 utils/             # UI utilities\n</code></pre>"},{"location":"architecture/system-overview/#data-flow-architecture","title":"Data Flow Architecture","text":""},{"location":"architecture/system-overview/#real-time-prediction-flow","title":"Real-time Prediction Flow","text":"<pre><code>sequenceDiagram\n    participant S as Sensors\n    participant DC as Data Connector\n    participant FE as Feature Engine\n    participant IE as Inference Engine\n    participant DB as Dashboard\n    participant AS as Alert System\n\n    S-&gt;&gt;DC: Raw sensor data\n    DC-&gt;&gt;FE: Validated data\n    FE-&gt;&gt;IE: Engineered features\n    IE-&gt;&gt;IE: Model inference\n    IE-&gt;&gt;DB: Prediction results\n    IE-&gt;&gt;AS: Alert evaluation\n    AS-&gt;&gt;AS: Threshold check\n    DB-&gt;&gt;DB: UI update\n\n    Note over IE: Multiple model&lt;br/&gt;ensemble\n    Note over AS: Configurable&lt;br/&gt;thresholds</code></pre>"},{"location":"architecture/system-overview/#batch-processing-flow","title":"Batch Processing Flow","text":"<pre><code>sequenceDiagram\n    participant HD as Historical Data\n    participant DP as Data Pipeline\n    participant MT as Model Trainer\n    participant MR as Model Registry\n    participant IE as Inference Engine\n\n    HD-&gt;&gt;DP: Historical dataset\n    DP-&gt;&gt;DP: Feature engineering\n    DP-&gt;&gt;MT: Training data\n    MT-&gt;&gt;MT: Model training\n    MT-&gt;&gt;MR: Model artifacts\n    MR-&gt;&gt;IE: Updated models\n\n    Note over MT: Cross-validation&lt;br/&gt;and hyperparameter&lt;br/&gt;optimization</code></pre>"},{"location":"architecture/system-overview/#technology-stack","title":"Technology Stack","text":""},{"location":"architecture/system-overview/#core-technologies","title":"Core Technologies","text":"Layer Technology Purpose ML Framework PyTorch, scikit-learn, XGBoost Model development and training Data Processing pandas, NumPy, PyArrow Data manipulation and analysis Web Framework Dash, Plotly Interactive dashboard API Framework FastAPI RESTful API services Database SQLite/PostgreSQL Data persistence Caching Redis High-performance caching"},{"location":"architecture/system-overview/#development-tools","title":"Development Tools","text":"Category Tools Language Python 3.8+ Testing pytest, unittest Linting flake8, black, mypy Documentation MkDocs, Sphinx Containerization Docker, docker-compose CI/CD GitHub Actions"},{"location":"architecture/system-overview/#deployment-architecture","title":"Deployment Architecture","text":""},{"location":"architecture/system-overview/#development-environment","title":"Development Environment","text":"<pre><code># Local development stack\nservices:\n  app:\n    build: .\n    ports:\n      - \"8050:8050\"\n    volumes:\n      - .:/app\n    environment:\n      - ENV=development\n\n  database:\n    image: postgres:13\n    environment:\n      - POSTGRES_DB=steel_defect\n\n  redis:\n    image: redis:6-alpine\n</code></pre>"},{"location":"architecture/system-overview/#production-environment","title":"Production Environment","text":"<pre><code>graph TB\n    subgraph \"Load Balancer\"\n        A[HAProxy/nginx]\n    end\n\n    subgraph \"Application Tier\"\n        B[App Instance 1]\n        C[App Instance 2]\n        D[App Instance N]\n    end\n\n    subgraph \"Data Tier\"\n        E[PostgreSQL Primary]\n        F[PostgreSQL Replica]\n        G[Redis Cluster]\n    end\n\n    subgraph \"Monitoring\"\n        H[Prometheus]\n        I[Grafana]\n        J[ELK Stack]\n    end\n\n    A --&gt; B\n    A --&gt; C\n    A --&gt; D\n\n    B --&gt; E\n    C --&gt; E\n    D --&gt; E\n\n    E --&gt; F\n\n    B --&gt; G\n    C --&gt; G\n    D --&gt; G\n\n    B --&gt; H\n    C --&gt; H\n    D --&gt; H\n\n    H --&gt; I\n    H --&gt; J</code></pre>"},{"location":"architecture/system-overview/#security-architecture","title":"Security Architecture","text":""},{"location":"architecture/system-overview/#authentication-and-authorization","title":"Authentication and Authorization","text":"<pre><code>graph LR\n    subgraph \"Client\"\n        A[Web Browser]\n        B[API Client]\n    end\n\n    subgraph \"Auth Layer\"\n        C[Authentication Service]\n        D[Authorization Service]\n        E[Token Management]\n    end\n\n    subgraph \"Application\"\n        F[Dashboard]\n        G[API Endpoints]\n        H[Admin Interface]\n    end\n\n    A --&gt; C\n    B --&gt; C\n    C --&gt; D\n    D --&gt; E\n    E --&gt; F\n    E --&gt; G\n    E --&gt; H</code></pre>"},{"location":"architecture/system-overview/#security-measures","title":"Security Measures","text":"<ul> <li>Authentication: Token-based authentication</li> <li>Authorization: Role-based access control (RBAC)</li> <li>Data Encryption: TLS/SSL for data in transit</li> <li>Input Validation: Comprehensive request validation</li> <li>Rate Limiting: API rate limiting and throttling</li> <li>Audit Logging: Security event logging</li> </ul>"},{"location":"architecture/system-overview/#scalability-considerations","title":"Scalability Considerations","text":""},{"location":"architecture/system-overview/#horizontal-scaling","title":"Horizontal Scaling","text":"<ul> <li>Stateless Design: Application instances are stateless</li> <li>Load Balancing: Multiple app instances behind load balancer</li> <li>Database Scaling: Read replicas and connection pooling</li> <li>Caching Strategy: Distributed caching with Redis cluster</li> </ul>"},{"location":"architecture/system-overview/#performance-optimization","title":"Performance Optimization","text":"<ul> <li>Model Optimization: Model quantization and optimization</li> <li>Data Pipeline: Parallel processing and streaming</li> <li>Frontend: Lazy loading and caching</li> <li>API: Async processing and connection pooling</li> </ul>"},{"location":"architecture/system-overview/#integration-patterns","title":"Integration Patterns","text":""},{"location":"architecture/system-overview/#external-system-integration","title":"External System Integration","text":"<pre><code>graph LR\n    subgraph \"Steel Defect System\"\n        A[API Gateway]\n        B[Data Connectors]\n        C[Event Bus]\n    end\n\n    subgraph \"External Systems\"\n        D[MES System]\n        E[ERP System]\n        F[SCADA]\n        G[Quality Management]\n    end\n\n    D --&gt; B\n    E --&gt; B\n    F --&gt; B\n    G --&gt; A\n\n    B --&gt; C\n    A --&gt; C</code></pre>"},{"location":"architecture/system-overview/#integration-methods","title":"Integration Methods","text":"<ul> <li>REST APIs: Standard HTTP/JSON APIs</li> <li>WebSockets: Real-time data streaming</li> <li>Message Queues: Asynchronous processing</li> <li>File Transfer: Batch data exchange</li> <li>Database Integration: Direct database connections</li> </ul> <p>Next: Contributing Guide \u2192</p>"},{"location":"development/code-structure/","title":"Code Structure","text":"<p>Overview of the project code organization and architecture.</p>"},{"location":"development/code-structure/#directory-structure","title":"Directory Structure","text":"<ul> <li>/src - Application source code</li> <li>/tests - Test suites</li> <li>/docs - Documentation</li> <li>/configs - Configuration files</li> </ul>"},{"location":"development/code-structure/#module-organization","title":"Module Organization","text":"<ul> <li>API layer</li> <li>Business logic</li> <li>Data access layer</li> <li>ML models</li> </ul>"},{"location":"development/code-structure/#coding-patterns","title":"Coding Patterns","text":"<ul> <li>Dependency injection</li> <li>Factory patterns</li> <li>Repository pattern</li> </ul>"},{"location":"development/coding-standards/","title":"Coding Standards","text":"<p>Code quality standards and style guidelines.</p>"},{"location":"development/coding-standards/#python-standards","title":"Python Standards","text":"<ul> <li>PEP 8 compliance</li> <li>Type hints</li> <li>Docstring conventions</li> </ul>"},{"location":"development/coding-standards/#code-quality","title":"Code Quality","text":"<ul> <li>Linting with flake8</li> <li>Formatting with black</li> <li>Import sorting with isort</li> </ul>"},{"location":"development/coding-standards/#best-practices","title":"Best Practices","text":"<ul> <li>Error handling</li> <li>Logging standards</li> <li>Configuration management</li> </ul>"},{"location":"development/contributing/","title":"Contributing Guide","text":"<p>Thank you for your interest in contributing to the Steel Defect Prediction System! This guide provides everything you need to know to contribute effectively.</p>"},{"location":"development/contributing/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Getting Started</li> <li>Development Workflow</li> <li>Code Standards</li> <li>Testing Guidelines</li> <li>Documentation</li> <li>Pull Request Process</li> <li>Code of Conduct</li> </ul>"},{"location":"development/contributing/#getting-started","title":"Getting Started","text":""},{"location":"development/contributing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.8 or higher</li> <li>Git</li> <li>Virtual environment tool (venv, conda, etc.)</li> <li>Basic understanding of machine learning concepts</li> <li>Familiarity with Dash/Plotly for UI contributions</li> </ul>"},{"location":"development/contributing/#development-setup","title":"Development Setup","text":"<ol> <li> <p>Fork and Clone <pre><code># Fork the repository on GitHub, then clone your fork\ngit clone https://github.com/YOUR_USERNAME/steel_defect_demo.git\ncd steel_defect_demo\n\n# Add upstream remote\ngit remote add upstream https://github.com/dhar174/steel_defect_demo.git\n</code></pre></p> </li> <li> <p>Create Virtual Environment <pre><code># Using venv\npython -m venv steel_defect_env\nsource steel_defect_env/bin/activate  # Linux/macOS\n# steel_defect_env\\Scripts\\activate   # Windows\n\n# Using conda\nconda create -n steel_defect_env python=3.9\nconda activate steel_defect_env\n</code></pre></p> </li> <li> <p>Install Dependencies <pre><code># Install in development mode\npip install -e .\n\n# Install development dependencies\npip install -r requirements-docs.txt\n\n# Install pre-commit hooks (optional but recommended)\npip install pre-commit\npre-commit install\n</code></pre></p> </li> <li> <p>Verify Setup <pre><code># Run tests\npython -m pytest tests/ -v\n\n# Run demo to verify installation\npython demo_model_comparison.py\n</code></pre></p> </li> </ol>"},{"location":"development/contributing/#development-workflow","title":"Development Workflow","text":""},{"location":"development/contributing/#branch-strategy","title":"Branch Strategy","text":"<p>We use a feature branch workflow:</p> <pre><code>main branch (stable)\n\u251c\u2500\u2500 feature/new-model-type\n\u251c\u2500\u2500 bugfix/dashboard-loading-issue\n\u251c\u2500\u2500 docs/api-documentation\n\u2514\u2500\u2500 enhancement/alert-system-improvements\n</code></pre>"},{"location":"development/contributing/#creating-a-feature-branch","title":"Creating a Feature Branch","text":"<pre><code># Update main branch\ngit checkout main\ngit pull upstream main\n\n# Create and switch to feature branch\ngit checkout -b feature/your-feature-name\n\n# Push feature branch to your fork\ngit push -u origin feature/your-feature-name\n</code></pre>"},{"location":"development/contributing/#branch-naming-convention","title":"Branch Naming Convention","text":"<ul> <li>Features: <code>feature/description-of-feature</code></li> <li>Bug fixes: <code>bugfix/description-of-bug</code></li> <li>Documentation: <code>docs/description-of-docs</code></li> <li>Enhancements: <code>enhancement/description-of-enhancement</code></li> <li>Experimental: <code>experiment/description-of-experiment</code></li> </ul>"},{"location":"development/contributing/#code-standards","title":"Code Standards","text":""},{"location":"development/contributing/#python-code-style","title":"Python Code Style","text":"<p>We follow PEP 8 with some modifications:</p> <pre><code># Good: Clear, descriptive names\ndef calculate_defect_probability(sensor_data: Dict[str, float]) -&gt; float:\n    \"\"\"\n    Calculate defect probability based on sensor readings.\n\n    Args:\n        sensor_data: Dictionary containing sensor measurements\n\n    Returns:\n        Defect probability between 0 and 1\n\n    Raises:\n        ValueError: If sensor data is invalid\n    \"\"\"\n    if not sensor_data:\n        raise ValueError(\"Sensor data cannot be empty\")\n\n    # Implementation here\n    return probability\n\n# Bad: Unclear names and missing documentation\ndef calc(data):\n    if not data:\n        return 0\n    # What does this do?\n    return result\n</code></pre>"},{"location":"development/contributing/#code-formatting","title":"Code Formatting","text":"<p>We use Black for code formatting:</p> <pre><code># Format all Python files\nblack .\n\n# Check formatting without changes\nblack --check .\n\n# Format specific file\nblack src/models/baseline_model.py\n</code></pre>"},{"location":"development/contributing/#import-organization","title":"Import Organization","text":"<pre><code># Standard library imports\nimport os\nimport sys\nfrom typing import Dict, List, Optional\nfrom dataclasses import dataclass\n\n# Third-party imports\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Local imports\nfrom src.models.base_model import BaseModel\nfrom src.utils.config import Config\nfrom src.data.preprocessor import DataPreprocessor\n</code></pre>"},{"location":"development/contributing/#type-hints","title":"Type Hints","text":"<p>Use type hints for better code clarity:</p> <pre><code>from typing import Dict, List, Optional, Union, Tuple\n\ndef process_sensor_data(\n    data: Dict[str, float],\n    window_size: int = 60,\n    normalize: bool = True\n) -&gt; Tuple[np.ndarray, Dict[str, float]]:\n    \"\"\"Process sensor data with proper type hints.\"\"\"\n    # Implementation\n    return processed_data, metadata\n</code></pre>"},{"location":"development/contributing/#docstring-style","title":"Docstring Style","text":"<p>Use Google-style docstrings:</p> <pre><code>def train_model(\n    training_data: pd.DataFrame,\n    model_params: Dict[str, Any],\n    validation_split: float = 0.2\n) -&gt; Tuple[BaseModel, Dict[str, float]]:\n    \"\"\"\n    Train a machine learning model for defect prediction.\n\n    This function trains a model using the provided training data and\n    parameters, with automatic validation splitting and performance evaluation.\n\n    Args:\n        training_data: DataFrame containing training samples with features\n            and target labels. Must include 'defect_label' column.\n        model_params: Dictionary of model hyperparameters. Required keys\n            depend on model type (e.g., 'n_estimators' for XGBoost).\n        validation_split: Fraction of data to use for validation (0.0-1.0).\n            Defaults to 0.2 (20% validation).\n\n    Returns:\n        A tuple containing:\n            - Trained model instance\n            - Dictionary of validation metrics including accuracy, precision,\n              recall, and F1-score\n\n    Raises:\n        ValueError: If training_data is empty or missing required columns.\n        TypeError: If model_params is not a dictionary.\n\n    Example:\n        &gt;&gt;&gt; training_df = pd.read_csv('training_data.csv')\n        &gt;&gt;&gt; params = {'n_estimators': 100, 'max_depth': 6}\n        &gt;&gt;&gt; model, metrics = train_model(training_df, params)\n        &gt;&gt;&gt; print(f\"Accuracy: {metrics['accuracy']:.3f}\")\n        Accuracy: 0.876\n    \"\"\"\n    # Implementation here\n    pass\n</code></pre>"},{"location":"development/contributing/#testing-guidelines","title":"Testing Guidelines","text":""},{"location":"development/contributing/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 unit/                   # Unit tests\n\u2502   \u251c\u2500\u2500 test_models/\n\u2502   \u251c\u2500\u2500 test_data/\n\u2502   \u2514\u2500\u2500 test_utils/\n\u251c\u2500\u2500 integration/            # Integration tests\n\u2502   \u251c\u2500\u2500 test_pipeline/\n\u2502   \u2514\u2500\u2500 test_dashboard/\n\u251c\u2500\u2500 fixtures/              # Test data and fixtures\n\u2502   \u251c\u2500\u2500 sample_data.csv\n\u2502   \u2514\u2500\u2500 mock_models/\n\u2514\u2500\u2500 conftest.py            # Shared test configuration\n</code></pre>"},{"location":"development/contributing/#writing-unit-tests","title":"Writing Unit Tests","text":"<pre><code>import pytest\nimport pandas as pd\nimport numpy as np\nfrom unittest.mock import Mock, patch\n\nfrom src.models.baseline_model import BaselineModel\nfrom src.utils.exceptions import ModelNotTrainedError\n\nclass TestBaselineModel:\n    \"\"\"Test suite for BaselineModel class.\"\"\"\n\n    @pytest.fixture\n    def sample_data(self):\n        \"\"\"Create sample training data.\"\"\"\n        return pd.DataFrame({\n            'temperature': [1520, 1525, 1518, 1522],\n            'pressure': [150, 155, 148, 152],\n            'defect_label': [0, 1, 0, 1]\n        })\n\n    @pytest.fixture\n    def trained_model(self, sample_data):\n        \"\"\"Create a trained model instance.\"\"\"\n        model = BaselineModel()\n        model.train(sample_data)\n        return model\n\n    def test_model_initialization(self):\n        \"\"\"Test model initialization with default parameters.\"\"\"\n        model = BaselineModel()\n        assert model.is_trained is False\n        assert model.model_type == 'xgboost'\n\n    def test_model_training_success(self, sample_data):\n        \"\"\"Test successful model training.\"\"\"\n        model = BaselineModel()\n        metrics = model.train(sample_data)\n\n        assert model.is_trained is True\n        assert 'accuracy' in metrics\n        assert 0 &lt;= metrics['accuracy'] &lt;= 1\n\n    def test_model_training_invalid_data(self):\n        \"\"\"Test model training with invalid data.\"\"\"\n        model = BaselineModel()\n\n        with pytest.raises(ValueError, match=\"Training data cannot be empty\"):\n            model.train(pd.DataFrame())\n\n    def test_prediction_without_training(self):\n        \"\"\"Test prediction on untrained model raises error.\"\"\"\n        model = BaselineModel()\n        sensor_data = {'temperature': 1520, 'pressure': 150}\n\n        with pytest.raises(ModelNotTrainedError):\n            model.predict(sensor_data)\n\n    def test_prediction_success(self, trained_model):\n        \"\"\"Test successful prediction.\"\"\"\n        sensor_data = {'temperature': 1520, 'pressure': 150}\n        prediction = trained_model.predict(sensor_data)\n\n        assert 'defect_probability' in prediction\n        assert 0 &lt;= prediction['defect_probability'] &lt;= 1\n        assert 'confidence_score' in prediction\n\n    @patch('src.models.baseline_model.joblib.load')\n    def test_model_loading(self, mock_load):\n        \"\"\"Test model loading from file.\"\"\"\n        mock_load.return_value = Mock()\n\n        model = BaselineModel()\n        model.load('path/to/model.pkl')\n\n        assert model.is_trained is True\n        mock_load.assert_called_once_with('path/to/model.pkl')\n</code></pre>"},{"location":"development/contributing/#integration-tests","title":"Integration Tests","text":"<pre><code>import pytest\nfrom src.inference.prediction_engine import PredictionEngine\nfrom src.data.data_connectors import DataConnector\n\nclass TestPredictionPipeline:\n    \"\"\"Integration tests for the complete prediction pipeline.\"\"\"\n\n    def test_end_to_end_prediction(self):\n        \"\"\"Test complete prediction pipeline from data to result.\"\"\"\n        # Setup\n        engine = PredictionEngine()\n        connector = DataConnector()\n\n        # Get test data\n        test_data = connector.get_test_data()\n\n        # Make prediction\n        result = engine.predict(test_data)\n\n        # Verify result structure\n        assert 'defect_probability' in result\n        assert 'confidence_score' in result\n        assert 'model_predictions' in result\n        assert result['defect_probability'] &gt;= 0\n        assert result['defect_probability'] &lt;= 1\n</code></pre>"},{"location":"development/contributing/#test-data-management","title":"Test Data Management","text":"<pre><code># conftest.py - Shared test fixtures\nimport pytest\nimport pandas as pd\nimport numpy as np\n\n@pytest.fixture(scope=\"session\")\ndef sample_sensor_data():\n    \"\"\"Create sample sensor data for testing.\"\"\"\n    np.random.seed(42)  # Reproducible results\n\n    n_samples = 1000\n    data = {\n        'timestamp': pd.date_range('2024-01-01', periods=n_samples, freq='1min'),\n        'temperature': np.random.normal(1520, 10, n_samples),\n        'pressure': np.random.normal(150, 5, n_samples),\n        'flow_rate': np.random.normal(200, 20, n_samples),\n        'defect_label': np.random.binomial(1, 0.1, n_samples)  # 10% defect rate\n    }\n\n    return pd.DataFrame(data)\n\n@pytest.fixture\ndef mock_model():\n    \"\"\"Create a mock model for testing.\"\"\"\n    from unittest.mock import Mock\n\n    model = Mock()\n    model.predict.return_value = {\n        'defect_probability': 0.15,\n        'confidence_score': 0.89\n    }\n    model.is_trained = True\n\n    return model\n</code></pre>"},{"location":"development/contributing/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\npytest\n\n# Run with coverage\npytest --cov=src --cov-report=html\n\n# Run specific test file\npytest tests/unit/test_models/test_baseline_model.py\n\n# Run with verbose output\npytest -v\n\n# Run tests matching pattern\npytest -k \"test_prediction\"\n\n# Run only failed tests from last run\npytest --lf\n</code></pre>"},{"location":"development/contributing/#documentation","title":"Documentation","text":""},{"location":"development/contributing/#code-documentation","title":"Code Documentation","text":"<ul> <li>Every public function/class must have docstrings</li> <li>Use type hints for all function parameters and returns</li> <li>Include examples in docstrings for complex functions</li> <li>Document exceptions that can be raised</li> </ul>"},{"location":"development/contributing/#pull-request-process","title":"Pull Request Process","text":""},{"location":"development/contributing/#creating-a-pull-request","title":"Creating a Pull Request","text":"<ol> <li>Push your feature branch to your fork</li> <li>Open a pull request against the main repository</li> <li>Fill out the PR template with detailed information</li> <li>Link related issues using keywords (fixes #123)</li> <li>Request review from appropriate team members</li> </ol>"},{"location":"development/contributing/#pr-requirements","title":"PR Requirements","text":"<ul> <li>All tests must pass</li> <li>Code coverage must not decrease</li> <li>Documentation must be updated</li> <li>Code must follow style guidelines</li> <li>Commit messages must be descriptive</li> </ul>"},{"location":"development/contributing/#review-process","title":"Review Process","text":"<ol> <li>Automated checks run on all PRs</li> <li>Code review by at least one team member</li> <li>Testing in staging environment</li> <li>Approval required before merging</li> <li>Squash and merge to maintain clean history</li> </ol>"},{"location":"development/contributing/#adding-new-documentation","title":"Adding New Documentation","text":"<ol> <li>Create markdown files in the appropriate <code>docs_site/</code> subdirectory</li> <li>Update <code>mkdocs.yml</code> navigation if adding new pages</li> <li>Use consistent formatting with existing documentation</li> <li>Include code examples and practical usage</li> <li>Add diagrams using Mermaid when helpful</li> </ol>"},{"location":"development/contributing/#documentation-style","title":"Documentation Style","text":"<pre><code># Page Title\n\nBrief introduction paragraph explaining the purpose and scope.\n\n## Major Section\n\nDetailed explanation with examples.\n\n### Subsection\n\nMore specific information.\n\n```python\n# Code example with comments\ndef example_function():\n    \"\"\"Example with proper documentation.\"\"\"\n    return \"result\"\n</code></pre> <p>Important Note</p> <p>Use admonitions for important information.</p> <p>Warning</p> <p>Use warnings for potential issues.</p> <p>Pro Tip</p> <p>Use tips for helpful suggestions.</p> <pre><code>## Pull Request Process\n\n### Before Submitting\n\n1. **Ensure all tests pass**\n   ```bash\n   pytest\n   ```\n\n2. **Code formatting**\n   ```bash\n   black .\n   flake8 .\n   ```\n\n3. **Update documentation** if needed\n\n4. **Update changelog** in `CHANGELOG.md`\n\n### Pull Request Template\n\nWhen creating a pull request, include:\n\n```markdown\n## Description\nBrief description of changes made.\n\n## Type of Change\n- [ ] Bug fix (non-breaking change that fixes an issue)\n- [ ] New feature (non-breaking change that adds functionality)\n- [ ] Breaking change (fix or feature that causes existing functionality to change)\n- [ ] Documentation update\n\n## Testing\n- [ ] I have added tests that prove my fix is effective or that my feature works\n- [ ] New and existing unit tests pass locally with my changes\n- [ ] I have tested the changes in the dashboard interface\n\n## Checklist\n- [ ] My code follows the style guidelines of this project\n- [ ] I have performed a self-review of my own code\n- [ ] I have commented my code, particularly in hard-to-understand areas\n- [ ] I have made corresponding changes to the documentation\n- [ ] My changes generate no new warnings\n\n## Screenshots (if applicable)\nAdd screenshots to help explain your changes.\n</code></pre>"},{"location":"development/contributing/#review-process_1","title":"Review Process","text":"<ol> <li>Automated checks must pass (tests, linting, etc.)</li> <li>Code review by at least one maintainer</li> <li>Manual testing of significant changes</li> <li>Documentation review if docs are updated</li> <li>Merge after approval</li> </ol>"},{"location":"development/contributing/#code-of-conduct","title":"Code of Conduct","text":""},{"location":"development/contributing/#our-pledge","title":"Our Pledge","text":"<p>We are committed to providing a welcoming and inclusive environment for all contributors, regardless of experience level, gender, gender identity and expression, sexual orientation, disability, personal appearance, body size, race, ethnicity, age, religion, or nationality.</p>"},{"location":"development/contributing/#expected-behavior","title":"Expected Behavior","text":"<ul> <li>Be respectful and inclusive</li> <li>Be collaborative and helpful</li> <li>Be patient with newcomers</li> <li>Give constructive feedback</li> <li>Focus on what is best for the community</li> </ul>"},{"location":"development/contributing/#unacceptable-behavior","title":"Unacceptable Behavior","text":"<ul> <li>Harassment, discrimination, or exclusionary behavior</li> <li>Personal attacks or insults</li> <li>Trolling or inflammatory comments</li> <li>Publishing private information without permission</li> <li>Any other conduct that could reasonably be considered inappropriate</li> </ul>"},{"location":"development/contributing/#reporting-issues","title":"Reporting Issues","text":"<p>If you experience or witness unacceptable behavior, please contact the project maintainers at [contact information].</p>"},{"location":"development/contributing/#getting-help","title":"Getting Help","text":""},{"location":"development/contributing/#resources","title":"Resources","text":"<ul> <li>Documentation: This comprehensive guide</li> <li>Issues: GitHub Issues for bugs and feature requests</li> <li>Discussions: GitHub Discussions for questions and ideas</li> <li>Wiki: Additional technical notes and examples</li> </ul>"},{"location":"development/contributing/#communication-channels","title":"Communication Channels","text":"<ul> <li>GitHub Issues: For bug reports and feature requests</li> <li>GitHub Discussions: For questions, ideas, and general discussion</li> <li>Pull Request Reviews: For code-specific feedback</li> </ul>"},{"location":"development/contributing/#getting-started-issues","title":"Getting Started Issues","text":"<p>Look for issues labeled <code>good first issue</code> or <code>help wanted</code> if you're new to the project. These are typically:</p> <ul> <li>Documentation improvements</li> <li>Small bug fixes</li> <li>Test coverage improvements</li> <li>Code style cleanup</li> </ul>"},{"location":"development/contributing/#recognition","title":"Recognition","text":"<p>Contributors will be recognized in:</p> <ul> <li>CONTRIBUTORS.md file</li> <li>Release notes for significant contributions</li> <li>Documentation credits</li> </ul> <p>Thank you for contributing to the Steel Defect Prediction System! \ud83d\ude80</p> <p>Next: Changelog \u2192</p>"},{"location":"development/development-workflow/","title":"Development Workflow","text":"<p>Development process and workflow guidelines.</p>"},{"location":"development/development-workflow/#git-workflow","title":"Git Workflow","text":"<ul> <li>Feature branch model</li> <li>Pull request process</li> <li>Code review guidelines</li> </ul>"},{"location":"development/development-workflow/#development-environment","title":"Development Environment","text":"<ul> <li>Local setup</li> <li>Testing procedures</li> <li>Debugging tools</li> </ul>"},{"location":"development/development-workflow/#continuous-integration","title":"Continuous Integration","text":"<ul> <li>Automated testing</li> <li>Code quality checks</li> <li>Deployment pipeline</li> </ul>"},{"location":"development/testing-guidelines/","title":"Testing Guidelines","text":"<p>Testing standards and best practices.</p>"},{"location":"development/testing-guidelines/#test-types","title":"Test Types","text":"<ul> <li>Unit tests</li> <li>Integration tests</li> <li>End-to-end tests</li> </ul>"},{"location":"development/testing-guidelines/#testing-framework","title":"Testing Framework","text":"<ul> <li>pytest for Python tests</li> <li>Test coverage requirements</li> <li>Mocking strategies</li> </ul>"},{"location":"development/testing-guidelines/#quality-gates","title":"Quality Gates","text":"<ul> <li>Code coverage thresholds</li> <li>Performance benchmarks</li> <li>Security testing</li> </ul>"},{"location":"getting-started/first-prediction/","title":"First Prediction Tutorial","text":"<p>This tutorial walks you through making your first defect prediction with the Steel Defect Prediction System. You'll learn to load data, run models, and interpret results.</p>"},{"location":"getting-started/first-prediction/#prerequisites","title":"Prerequisites","text":"<ul> <li>Completed Quick Start setup</li> <li>System running and tested</li> <li>Basic understanding of steel casting processes</li> </ul>"},{"location":"getting-started/first-prediction/#tutorial-overview","title":"Tutorial Overview","text":"<p>We'll cover: 1. Loading sample data 2. Running a prediction 3. Understanding the output 4. Exploring the dashboard</p>"},{"location":"getting-started/first-prediction/#loading-sample-data","title":"Loading Sample Data","text":"<p>The system includes synthetic sample data that mimics real steel casting sensor readings.</p>"},{"location":"getting-started/first-prediction/#using-python","title":"Using Python","text":"<pre><code>from src.data.data_connectors import DataConnector\nimport pandas as pd\n\n# Initialize data connector\nconnector = DataConnector()\n\n# Load sample sensor data\nsample_data = connector.get_sample_data()\nprint(f\"Loaded {len(sample_data)} data points\")\n\n# View first few rows\nprint(sample_data.head())\n</code></pre> <p>Expected output: <pre><code>Loaded 1000 data points\n   timestamp  mold_temperature  mold_level  casting_speed  cooling_water_flow  superheat\n0 2024-01-01               1520      150.0            1.2               200.0       25.0\n1 2024-01-01               1522      149.8            1.2               201.2       24.8\n2 2024-01-01               1521      150.2            1.1               199.8       25.2\n</code></pre></p>"},{"location":"getting-started/first-prediction/#understanding-the-data-format","title":"Understanding the Data Format","text":"<p>The sample data includes these key parameters:</p> Parameter Unit Range Description <code>mold_temperature</code> \u00b0C 1500-1550 Steel temperature in mold <code>mold_level</code> mm 140-160 Steel level in mold <code>casting_speed</code> m/min 0.8-1.5 Speed of continuous casting <code>cooling_water_flow</code> L/min 180-220 Cooling water flow rate <code>superheat</code> \u00b0C 20-35 Temperature above liquidus"},{"location":"getting-started/first-prediction/#running-a-prediction","title":"Running a Prediction","text":""},{"location":"getting-started/first-prediction/#single-prediction","title":"Single Prediction","text":"<p>Make a prediction for current sensor readings:</p> <pre><code>from src.inference.prediction_engine import PredictionEngine\n\n# Initialize prediction engine\nengine = PredictionEngine()\n\n# Sample sensor readings\nsensor_data = {\n    \"mold_temperature\": 1525.0,\n    \"mold_level\": 152.5,\n    \"casting_speed\": 1.1,\n    \"cooling_water_flow\": 195.0,\n    \"superheat\": 27.0,\n    \"cast_id\": \"DEMO_CAST_001\",\n    \"timestamp\": \"2024-01-15T10:30:00Z\"\n}\n\n# Make prediction\nresult = engine.predict(sensor_data)\nprint(\"Prediction Result:\")\nprint(result)\n</code></pre>"},{"location":"getting-started/first-prediction/#batch-predictions","title":"Batch Predictions","text":"<p>Process multiple readings at once:</p> <pre><code># Load multiple readings\nreadings = connector.get_latest_readings(limit=10)\n\n# Make batch predictions\nbatch_results = engine.predict_batch(readings.to_dict('records'))\n\nprint(f\"Processed {len(batch_results)} predictions\")\nfor i, result in enumerate(batch_results[:3]):  # Show first 3\n    print(f\"Prediction {i+1}: {result['defect_probability']:.3f}\")\n</code></pre>"},{"location":"getting-started/first-prediction/#understanding-the-output","title":"Understanding the Output","text":""},{"location":"getting-started/first-prediction/#prediction-structure","title":"Prediction Structure","text":"<p>Each prediction returns a structured result:</p> <pre><code>{\n    \"prediction_id\": \"pred_abc123def456\",\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"cast_id\": \"DEMO_CAST_001\",\n    \"defect_probability\": 0.15,           # 0-1 scale (0=good, 1=defect)\n    \"confidence_score\": 0.89,             # Model confidence\n    \"model_predictions\": {                # Individual model results\n        \"baseline_xgboost\": {\n            \"probability\": 0.12,\n            \"confidence\": 0.87,\n            \"features_used\": 25\n        },\n        \"lstm_sequence\": {\n            \"probability\": 0.18,\n            \"confidence\": 0.91,\n            \"sequence_length\": 60\n        },\n        \"ensemble\": {\n            \"probability\": 0.15,\n            \"confidence\": 0.89,\n            \"weights\": {\"baseline\": 0.4, \"lstm\": 0.6}\n        }\n    },\n    \"alert_level\": \"low\",                 # low, medium, high\n    \"risk_factors\": [                     # Contributing factors\n        {\n            \"factor\": \"temperature_variance\",\n            \"impact\": 0.08,\n            \"description\": \"Temperature fluctuation detected\"\n        }\n    ]\n}\n</code></pre>"},{"location":"getting-started/first-prediction/#interpreting-defect-probability","title":"Interpreting Defect Probability","text":"Range Alert Level Interpretation Action 0.0 - 0.3 Low Good quality expected Continue normal operation 0.3 - 0.7 Medium Moderate risk Monitor closely 0.7 - 1.0 High High defect risk Consider intervention"},{"location":"getting-started/first-prediction/#understanding-confidence-scores","title":"Understanding Confidence Scores","text":"<ul> <li>High Confidence (&gt;0.8): Model is very certain about prediction</li> <li>Medium Confidence (0.6-0.8): Reasonable certainty</li> <li>Low Confidence (&lt;0.6): Model uncertainty, treat with caution</li> </ul>"},{"location":"getting-started/first-prediction/#exploring-the-dashboard","title":"Exploring the Dashboard","text":""},{"location":"getting-started/first-prediction/#launching-the-dashboard","title":"Launching the Dashboard","text":"<p>Start the interactive dashboard:</p> <pre><code>python scripts/run_dashboard.py\n</code></pre> <p>Open your browser to <code>http://localhost:8050</code></p>"},{"location":"getting-started/first-prediction/#dashboard-navigation","title":"Dashboard Navigation","text":"<ol> <li>Real-time Monitoring</li> <li>Live sensor readings</li> <li>Current predictions</li> <li> <p>Alert status</p> </li> <li> <p>Model Comparison</p> </li> <li>Performance metrics</li> <li>ROC curves</li> <li> <p>Feature importance</p> </li> <li> <p>Historical Analysis</p> </li> <li>Trend analysis</li> <li>Statistical summaries</li> <li>Pattern recognition</li> </ol>"},{"location":"getting-started/first-prediction/#making-dashboard-predictions","title":"Making Dashboard Predictions","text":"<ol> <li>Navigate to the Real-time Monitoring tab</li> <li>The dashboard automatically shows live predictions</li> <li>Observe the prediction probability gauge</li> <li>Check alert indicators in the top panel</li> </ol>"},{"location":"getting-started/first-prediction/#interactive-features","title":"Interactive Features","text":"<p>Try these dashboard features:</p> <ul> <li>Time Range Selection: Change the analysis period</li> <li>Model Toggle: Compare different model outputs</li> <li>Export Data: Download results as CSV</li> <li>Alert Configuration: Set custom thresholds</li> </ul>"},{"location":"getting-started/first-prediction/#advanced-usage","title":"Advanced Usage","text":""},{"location":"getting-started/first-prediction/#custom-sensor-data","title":"Custom Sensor Data","text":"<p>Create your own sensor readings:</p> <pre><code>custom_data = {\n    \"mold_temperature\": 1530.0,    # Higher temperature\n    \"mold_level\": 145.0,           # Lower level\n    \"casting_speed\": 1.4,          # Faster speed\n    \"cooling_water_flow\": 210.0,   # Higher flow\n    \"superheat\": 30.0,             # Higher superheat\n}\n\nprediction = engine.predict(custom_data)\nprint(f\"Defect probability: {prediction['defect_probability']:.3f}\")\nprint(f\"Alert level: {prediction['alert_level']}\")\n</code></pre>"},{"location":"getting-started/first-prediction/#analyzing-risk-factors","title":"Analyzing Risk Factors","text":"<p>Understand what drives the predictions:</p> <pre><code># Get detailed risk analysis\nprediction = engine.predict(sensor_data)\n\nprint(\"Risk Factors:\")\nfor factor in prediction['risk_factors']:\n    print(f\"- {factor['factor']}: {factor['impact']:.3f}\")\n    print(f\"  {factor['description']}\")\n</code></pre>"},{"location":"getting-started/first-prediction/#model-performance-comparison","title":"Model Performance Comparison","text":"<p>Compare how different models perform:</p> <pre><code>from src.visualization.components import ModelComparison\n\n# Load test data\ntest_data = connector.get_test_data()\n\n# Get predictions from all models\nresults = {}\nfor model_name in ['baseline_xgboost', 'lstm_sequence']:\n    model_results = engine.evaluate_model(model_name, test_data)\n    results[model_name] = model_results\n\n# Create comparison\ncomparison = ModelComparison()\ncomparison_chart = comparison.create_roc_curves(results)\ncomparison_chart.show()\n</code></pre>"},{"location":"getting-started/first-prediction/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/first-prediction/#common-issues","title":"Common Issues","text":"<p>Low Confidence Predictions</p> <p>If you see consistently low confidence scores: - Check data quality - Ensure all required sensors are working - Verify timestamp format</p> <p>Unexpected High Defect Probability</p> <p>For surprisingly high defect predictions: - Review sensor readings for outliers - Check if conditions are outside normal ranges - Consider recalibration if readings seem wrong</p>"},{"location":"getting-started/first-prediction/#data-quality-checks","title":"Data Quality Checks","text":"<p>Validate your sensor data:</p> <pre><code>from src.data.data_validation import DataValidator\n\nvalidator = DataValidator()\nquality_report = validator.validate(sensor_data)\n\nif quality_report['is_valid']:\n    print(\"\u2705 Data quality OK\")\nelse:\n    print(\"\u274c Data quality issues:\")\n    for issue in quality_report['issues']:\n        print(f\"- {issue}\")\n</code></pre>"},{"location":"getting-started/first-prediction/#getting-help","title":"Getting Help","text":"<p>If you encounter issues:</p> <ol> <li>Check the Development Setup Guide</li> <li>Review System Requirements</li> <li>Examine error logs in the <code>logs/</code> directory</li> <li>Open an issue on GitHub</li> </ol>"},{"location":"getting-started/first-prediction/#next-steps","title":"Next Steps","text":"<p>Now that you've made your first prediction:</p> <ul> <li>Learn More: Read the User Guide</li> <li>Integrate: Explore API Integration</li> <li>Customize: Try the Contributing Guide</li> <li>Contribute: Check the Contributing Guide</li> </ul> <p>Congratulations! \ud83c\udf89 You've successfully made your first steel defect prediction. The system is now ready for more advanced usage and integration into your casting operations.</p>"},{"location":"getting-started/quick-start/","title":"Quick Start Guide","text":"<p>Get up and running with the Steel Defect Prediction System in just 5 minutes!</p>"},{"location":"getting-started/quick-start/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.8 or higher</li> <li>Git</li> <li>At least 4GB RAM</li> <li>Linux, macOS, or Windows with WSL2</li> </ul>"},{"location":"getting-started/quick-start/#installation","title":"Installation","text":""},{"location":"getting-started/quick-start/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/dhar174/steel_defect_demo.git\ncd steel_defect_demo\n</code></pre>"},{"location":"getting-started/quick-start/#2-install-dependencies","title":"2. Install Dependencies","text":"<pre><code># Install core dependencies\npip install -r requirements.txt\n\n# Install the package in development mode\npip install -e .\n</code></pre>"},{"location":"getting-started/quick-start/#3-verify-installation","title":"3. Verify Installation","text":"<pre><code># Test the installation\npython demo_model_comparison.py\n</code></pre> <p>You should see output showing model comparison results and charts being generated.</p>"},{"location":"getting-started/quick-start/#your-first-prediction","title":"Your First Prediction","text":""},{"location":"getting-started/quick-start/#option-1-interactive-dashboard","title":"Option 1: Interactive Dashboard","text":"<p>Launch the interactive dashboard to explore the system:</p> <pre><code>python scripts/run_dashboard.py\n</code></pre> <p>Then open your browser to <code>http://localhost:8050</code> to access the dashboard.</p>"},{"location":"getting-started/quick-start/#option-2-command-line-demo","title":"Option 2: Command Line Demo","text":"<p>Run a quick prediction demo:</p> <pre><code># Run model comparison demo\npython demo_model_comparison.py\n\n# Run sensor monitoring demo  \npython demo_sensor_visualization.py\n\n# Run historical analysis demo\npython demo_historical_analysis.py\n</code></pre>"},{"location":"getting-started/quick-start/#understanding-the-output","title":"Understanding the Output","text":""},{"location":"getting-started/quick-start/#model-predictions","title":"Model Predictions","text":"<p>The system provides predictions in this format:</p> <pre><code>{\n    \"cast_id\": \"CAST_20250720_001\",\n    \"defect_probability\": 0.15,\n    \"confidence_score\": 0.89,\n    \"model_predictions\": {\n        \"baseline\": 0.12,\n        \"lstm\": 0.18\n    },\n    \"alert_level\": \"low\",\n    \"timestamp\": \"2025-07-20T22:18:46Z\"\n}\n</code></pre>"},{"location":"getting-started/quick-start/#dashboard-features","title":"Dashboard Features","text":"<p>The dashboard includes:</p> <ul> <li>Real-time Monitoring: Live sensor data and predictions</li> <li>Model Comparison: Side-by-side performance metrics</li> <li>Historical Analysis: Trends and pattern analysis</li> <li>Alert Management: Configure thresholds and notifications</li> </ul>"},{"location":"getting-started/quick-start/#next-steps","title":"Next Steps","text":"<p>Once you have the system running:</p> <ol> <li>Explore the Dashboard: Navigate through different monitoring views</li> <li>Review Architecture: Understand the system design</li> <li>Explore Dashboard: Use the dashboard overview</li> <li>Integration: Learn about API integration</li> </ol>"},{"location":"getting-started/quick-start/#sample-data","title":"Sample Data","text":"<p>The system includes synthetic sample data for testing:</p> <ul> <li>Sensor readings: Temperature, pressure, flow rates</li> <li>Cast parameters: Speed, superheat, mold level</li> <li>Quality outcomes: Defect classifications and probabilities</li> </ul>"},{"location":"getting-started/quick-start/#common-issues","title":"Common Issues","text":""},{"location":"getting-started/quick-start/#installation-problems","title":"Installation Problems","text":"<p>Module Import Errors</p> <p>If you encounter import errors, ensure you've installed the package in development mode: <pre><code>pip install -e .\n</code></pre></p> <p>Missing Dependencies</p> <p>Some demos require additional packages. Install documentation dependencies: <pre><code>pip install -r requirements-docs.txt\n</code></pre></p>"},{"location":"getting-started/quick-start/#performance-tips","title":"Performance Tips","text":"<ul> <li>Use at least 4GB RAM for optimal performance</li> <li>LSTM model training requires more memory than baseline models</li> <li>Dashboard responsiveness improves with faster internet for plot rendering</li> </ul>"},{"location":"getting-started/quick-start/#getting-help","title":"Getting Help","text":"<ul> <li>Check the Development Setup Guide</li> <li>Review System Requirements</li> <li>Browse the User Guide</li> <li>Open an issue for bugs</li> </ul> <p>Congratulations! \ud83c\udf89 You now have the Steel Defect Prediction System running. Continue to the Dashboard Overview to learn about all available features.</p>"},{"location":"getting-started/system-requirements/","title":"System Requirements","text":"<p>This page outlines the hardware and software requirements for running the Steel Defect Prediction System in different environments.</p>"},{"location":"getting-started/system-requirements/#minimum-requirements","title":"Minimum Requirements","text":""},{"location":"getting-started/system-requirements/#hardware","title":"Hardware","text":"Component Minimum Recommended Notes CPU 2 cores 4+ cores Multi-core improves model training performance RAM 4GB 8GB+ LSTM training requires more memory Storage 2GB 10GB+ Includes models, data, and logs Network 1 Mbps 10+ Mbps For dashboard and data streaming"},{"location":"getting-started/system-requirements/#software","title":"Software","text":"Requirement Version Purpose Python 3.8+ Core runtime (3.9-3.11 recommended) pip 20.0+ Package management Git 2.0+ Version control and installation"},{"location":"getting-started/system-requirements/#production-requirements","title":"Production Requirements","text":""},{"location":"getting-started/system-requirements/#hardware-production","title":"Hardware (Production)","text":"Component Minimum Recommended High-Performance CPU 4 cores 8+ cores 16+ cores RAM 8GB 16GB+ 32GB+ Storage 50GB SSD 100GB SSD 500GB+ NVMe Network 10 Mbps 100 Mbps 1 Gbps GPU None NVIDIA GPU Tesla/A100 for training"},{"location":"getting-started/system-requirements/#software-stack","title":"Software Stack","text":""},{"location":"getting-started/system-requirements/#operating-systems","title":"Operating Systems","text":"Linux (Recommended)macOSWindows <ul> <li>Ubuntu: 20.04 LTS, 22.04 LTS</li> <li>CentOS: 7, 8</li> <li>RHEL: 7, 8, 9</li> <li>Debian: 10, 11</li> </ul> <ul> <li>macOS: 10.15+ (Catalina or newer)</li> <li>Architecture: Intel x64 or Apple Silicon (M1/M2)</li> </ul> <ul> <li>Windows: 10, 11 </li> <li>WSL2: Required for full compatibility</li> <li>Docker Desktop: Recommended for containerization</li> </ul>"},{"location":"getting-started/system-requirements/#python-environment","title":"Python Environment","text":"<pre><code># Recommended Python version\nPython 3.9.7+\n\n# Virtual environment (recommended)\npython -m venv steel_defect_env\nsource steel_defect_env/bin/activate  # Linux/macOS\n# steel_defect_env\\Scripts\\activate   # Windows\n</code></pre>"},{"location":"getting-started/system-requirements/#development-environment","title":"Development Environment","text":""},{"location":"getting-started/system-requirements/#ide-support","title":"IDE Support","text":"IDE Support Level Notes VS Code \u2705 Excellent Recommended, includes .vscode config PyCharm \u2705 Excellent Professional or Community Jupyter \u2705 Good For notebooks and experimentation Vim/Neovim \u2705 Good With Python LSP"},{"location":"getting-started/system-requirements/#development-tools","title":"Development Tools","text":"<pre><code># Code formatting and linting\npip install black flake8 mypy\n\n# Testing framework\npip install pytest pytest-cov\n\n# Documentation\npip install -r requirements-docs.txt\n</code></pre>"},{"location":"getting-started/system-requirements/#browser-requirements","title":"Browser Requirements","text":""},{"location":"getting-started/system-requirements/#dashboard-access","title":"Dashboard Access","text":"Browser Version Support Level Chrome 90+ \u2705 Recommended Firefox 88+ \u2705 Full support Safari 14+ \u2705 Full support Edge 90+ \u2705 Full support"},{"location":"getting-started/system-requirements/#features-used","title":"Features Used","text":"<ul> <li>JavaScript: ES6+ features</li> <li>WebSockets: For real-time updates</li> <li>Local Storage: For user preferences</li> <li>Canvas/SVG: For interactive charts</li> </ul>"},{"location":"getting-started/system-requirements/#network-requirements","title":"Network Requirements","text":""},{"location":"getting-started/system-requirements/#ports","title":"Ports","text":"Port Protocol Purpose Required 8050 HTTP Dashboard interface Yes 8051 HTTP API endpoints Optional 5432 TCP PostgreSQL (if used) Optional 6379 TCP Redis (if used) Optional"},{"location":"getting-started/system-requirements/#firewall-configuration","title":"Firewall Configuration","text":"DevelopmentProduction <pre><code># Allow dashboard access\nsudo ufw allow 8050/tcp\n</code></pre> <pre><code># More restrictive rules\nsudo ufw allow from 10.0.0.0/8 to any port 8050\nsudo ufw allow from 172.16.0.0/12 to any port 8050\nsudo ufw allow from 192.168.0.0/16 to any port 8050\n</code></pre>"},{"location":"getting-started/system-requirements/#dependencies","title":"Dependencies","text":""},{"location":"getting-started/system-requirements/#core-dependencies","title":"Core Dependencies","text":"<pre><code># Data processing\npandas&gt;=1.5.0\nnumpy&gt;=1.23.0\npyarrow&gt;=10.0.0\n\n# Machine learning\nscikit-learn&gt;=1.1.0\nxgboost&gt;=1.7.0\ntorch&gt;=1.13.0\n\n# Visualization\nplotly&gt;=5.15.0\ndash&gt;=3.0.0\nmatplotlib&gt;=3.6.0\n</code></pre>"},{"location":"getting-started/system-requirements/#optional-dependencies","title":"Optional Dependencies","text":"<pre><code># GPU acceleration (CUDA)\ntorch[cuda]  # For NVIDIA GPUs\n\n# Database connectors\npsycopg2&gt;=2.9.0  # PostgreSQL\nredis&gt;=4.3.0     # Redis cache\n\n# Production monitoring\nprometheus-client&gt;=0.14.0\n</code></pre>"},{"location":"getting-started/system-requirements/#performance-benchmarks","title":"Performance Benchmarks","text":""},{"location":"getting-started/system-requirements/#model-training-time","title":"Model Training Time","text":"Model Type Dataset Size CPU (4 cores) GPU (CUDA) XGBoost 10K samples 30 seconds N/A LSTM 10K sequences 5 minutes 1 minute Ensemble 50K samples 15 minutes 3 minutes"},{"location":"getting-started/system-requirements/#memory-usage","title":"Memory Usage","text":"Component Baseline Peak Notes Dashboard 200MB 500MB Depends on data volume XGBoost Training 300MB 1GB Scales with features LSTM Training 500MB 2GB Scales with sequence length"},{"location":"getting-started/system-requirements/#cloud-deployment","title":"Cloud Deployment","text":""},{"location":"getting-started/system-requirements/#aws-requirements","title":"AWS Requirements","text":"<pre><code># Minimum EC2 instance\nInstance: t3.medium\nvCPUs: 2\nRAM: 4GB\nStorage: 20GB GP2\n\n# Recommended EC2 instance  \nInstance: c5.xlarge\nvCPUs: 4\nRAM: 8GB\nStorage: 50GB GP3\n</code></pre>"},{"location":"getting-started/system-requirements/#docker-requirements","title":"Docker Requirements","text":"<pre><code># Base requirements\nFROM python:3.9-slim\n\n# System packages\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    gcc \\\n    g++ \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Memory limits\n--memory=2g\n--memory-swap=4g\n</code></pre>"},{"location":"getting-started/system-requirements/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/system-requirements/#common-issues","title":"Common Issues","text":"<p>Memory Errors</p> <p>If you encounter out-of-memory errors: - Increase system RAM or swap - Reduce batch size for LSTM training - Use data streaming for large datasets</p> <p>Performance Issues</p> <p>For slow performance: - Check CPU usage and available cores - Monitor memory usage - Consider GPU acceleration for training</p> <p>Installation Failures</p> <p>For package installation issues: - Update pip: <code>pip install --upgrade pip</code> - Use virtual environment - Check Python version compatibility</p>"},{"location":"getting-started/system-requirements/#verification-commands","title":"Verification Commands","text":"<pre><code># Check Python version\npython --version\n\n# Verify installation\npython -c \"import steel_defect_demo; print('Installation OK')\"\n\n# Check memory and CPU\npython -c \"import psutil; print(f'RAM: {psutil.virtual_memory().total//1e9:.1f}GB')\"\npython -c \"import os; print(f'CPU cores: {os.cpu_count()}')\"\n\n# Test GPU (if available)\npython -c \"import torch; print(f'CUDA available: {torch.cuda.is_available()}')\"\n</code></pre> <p>Next: Development Setup \u2192</p>"},{"location":"installation/development-setup/","title":"Development Setup Guide","text":"<p>This guide walks you through setting up a complete development environment for the Steel Defect Prediction System.</p>"},{"location":"installation/development-setup/#quick-setup","title":"Quick Setup","text":"<p>For experienced developers who want to get started immediately:</p> <pre><code># Clone and setup\ngit clone https://github.com/dhar174/steel_defect_demo.git\ncd steel_defect_demo\npython -m venv venv &amp;&amp; source venv/bin/activate\npip install -e . &amp;&amp; pip install -r requirements-docs.txt\npython demo_model_comparison.py  # Verify installation\n</code></pre>"},{"location":"installation/development-setup/#detailed-setup-instructions","title":"Detailed Setup Instructions","text":""},{"location":"installation/development-setup/#1-system-prerequisites","title":"1. System Prerequisites","text":"<p>Ensure you have these installed:</p> <ul> <li>Python 3.8+ (3.9-3.11 recommended)</li> <li>Git for version control</li> <li>Virtual environment tool (venv, conda, virtualenv)</li> </ul>"},{"location":"installation/development-setup/#platform-specific-requirements","title":"Platform-Specific Requirements","text":"Linux (Ubuntu/Debian)macOSWindows <pre><code># Update system packages\nsudo apt update &amp;&amp; sudo apt upgrade -y\n\n# Install development tools\nsudo apt install -y python3 python3-pip python3-venv git build-essential\n\n# Install optional dependencies\nsudo apt install -y python3-dev libffi-dev libssl-dev\n</code></pre> <pre><code># Install Homebrew (if not installed)\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\n# Install Python and Git\nbrew install python git\n\n# Install development tools\nxcode-select --install\n</code></pre> <pre><code># Using Chocolatey package manager\n# Install Chocolatey first from https://chocolatey.org/install\n\nchoco install python git\n\n# Or download installers from:\n# Python: https://python.org/downloads/\n# Git: https://git-scm.com/download/win\n</code></pre>"},{"location":"installation/development-setup/#2-clone-repository","title":"2. Clone Repository","text":"<pre><code># Clone the repository\ngit clone https://github.com/dhar174/steel_defect_demo.git\ncd steel_defect_demo\n\n# Verify repository structure\nls -la\n</code></pre> <p>Expected structure: <pre><code>steel_defect_demo/\n\u251c\u2500\u2500 src/                    # Source code\n\u251c\u2500\u2500 tests/                  # Test suite\n\u251c\u2500\u2500 docs_site/             # Documentation\n\u251c\u2500\u2500 data/                  # Sample data\n\u251c\u2500\u2500 configs/               # Configuration files\n\u251c\u2500\u2500 requirements.txt       # Dependencies\n\u251c\u2500\u2500 setup.py              # Package setup\n\u2514\u2500\u2500 README.md             # Project overview\n</code></pre></p>"},{"location":"installation/development-setup/#3-virtual-environment-setup","title":"3. Virtual Environment Setup","text":"<p>Choose your preferred virtual environment tool:</p> venv (Recommended)condavirtualenv <pre><code># Create virtual environment\npython -m venv steel_defect_env\n\n# Activate virtual environment\n# Linux/macOS:\nsource steel_defect_env/bin/activate\n\n# Windows:\n# steel_defect_env\\Scripts\\activate\n\n# Verify activation\nwhich python  # Should point to venv\n</code></pre> <pre><code># Create conda environment\nconda create -n steel_defect_env python=3.9\n\n# Activate environment\nconda activate steel_defect_env\n\n# Verify activation\nconda info --envs\n</code></pre> <pre><code># Install virtualenv if needed\npip install virtualenv\n\n# Create virtual environment\nvirtualenv steel_defect_env\n\n# Activate environment\nsource steel_defect_env/bin/activate  # Linux/macOS\n# steel_defect_env\\Scripts\\activate   # Windows\n</code></pre>"},{"location":"installation/development-setup/#4-install-dependencies","title":"4. Install Dependencies","text":"<pre><code># Upgrade pip\npip install --upgrade pip\n\n# Install the package in development mode\npip install -e .\n\n# Install documentation dependencies\npip install -r requirements-docs.txt\n\n# Install development tools (optional but recommended)\npip install black flake8 pytest mypy pre-commit\n</code></pre>"},{"location":"installation/development-setup/#optional-gpu-support","title":"Optional: GPU Support","text":"<p>For LSTM model training with GPU acceleration:</p> <pre><code># CUDA 11.x\npip install torch torchvision --index-url https://download.pytorch.org/whl/cu118\n\n# CUDA 12.x\npip install torch torchvision --index-url https://download.pytorch.org/whl/cu121\n\n# Verify GPU support\npython -c \"import torch; print(f'CUDA available: {torch.cuda.is_available()}')\"\n</code></pre>"},{"location":"installation/development-setup/#5-verify-installation","title":"5. Verify Installation","text":"<p>Run these verification steps:</p> <pre><code># Test basic imports\npython -c \"import src; print('\u2705 Package imports successfully')\"\n\n# Run a simple demo\npython demo_model_comparison.py\n\n# Run basic tests\npython -m pytest tests/ -v --tb=short\n\n# Build documentation\nmkdocs build\n</code></pre> <p>Expected output indicates successful setup: <pre><code>\u2705 Package imports successfully\n\ud83d\ude80 ModelComparison Component Demo\n==================================================\n\u2705 All individual components demonstrated successfully!\n</code></pre></p>"},{"location":"installation/development-setup/#6-ide-configuration","title":"6. IDE Configuration","text":""},{"location":"installation/development-setup/#vs-code-setup","title":"VS Code Setup","text":"<p>Create <code>.vscode/settings.json</code>:</p> <pre><code>{\n    \"python.defaultInterpreterPath\": \"./steel_defect_env/bin/python\",\n    \"python.linting.enabled\": true,\n    \"python.linting.flake8Enabled\": true,\n    \"python.formatting.provider\": \"black\",\n    \"python.formatting.blackArgs\": [\"--line-length\", \"88\"],\n    \"python.testing.pytestEnabled\": true,\n    \"python.testing.pytestArgs\": [\"tests\"],\n    \"files.exclude\": {\n        \"**/__pycache__\": true,\n        \"**/*.pyc\": true,\n        \"steel_defect_env/\": true,\n        \"site/\": true\n    }\n}\n</code></pre> <p>Create <code>.vscode/launch.json</code> for debugging:</p> <pre><code>{\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"Run Dashboard\",\n            \"type\": \"python\",\n            \"request\": \"launch\",\n            \"program\": \"${workspaceFolder}/scripts/run_dashboard.py\",\n            \"console\": \"integratedTerminal\",\n            \"cwd\": \"${workspaceFolder}\"\n        },\n        {\n            \"name\": \"Run Demo\",\n            \"type\": \"python\",\n            \"request\": \"launch\",\n            \"program\": \"${workspaceFolder}/demo_model_comparison.py\",\n            \"console\": \"integratedTerminal\",\n            \"cwd\": \"${workspaceFolder}\"\n        }\n    ]\n}\n</code></pre>"},{"location":"installation/development-setup/#pycharm-setup","title":"PyCharm Setup","text":"<ol> <li>Open Project: File \u2192 Open \u2192 Select <code>steel_defect_demo</code> folder</li> <li>Configure Interpreter: Settings \u2192 Python Interpreter \u2192 Add \u2192 Existing Environment \u2192 Select <code>steel_defect_env/bin/python</code></li> <li>Enable Tools: Settings \u2192 Tools \u2192 Enable pytest, Black formatter</li> <li>Mark Source Root: Right-click <code>src</code> folder \u2192 Mark Directory As \u2192 Sources Root</li> </ol>"},{"location":"installation/development-setup/#7-development-tools-setup","title":"7. Development Tools Setup","text":""},{"location":"installation/development-setup/#pre-commit-hooks-recommended","title":"Pre-commit Hooks (Recommended)","text":"<pre><code># Install pre-commit\npip install pre-commit\n\n# Install git hooks\npre-commit install\n\n# Test hooks\npre-commit run --all-files\n</code></pre> <p>Create <code>.pre-commit-config.yaml</code>:</p> <pre><code>repos:\n  - repo: https://github.com/psf/black\n    rev: '22.10.0'\n    hooks:\n      - id: black\n        language_version: python3\n\n  - repo: https://github.com/pycqa/flake8\n    rev: '5.0.4'\n    hooks:\n      - id: flake8\n        args: ['--max-line-length=88', '--extend-ignore=E203,W503']\n\n  - repo: https://github.com/pre-commit/mirrors-mypy\n    rev: 'v0.991'\n    hooks:\n      - id: mypy\n        additional_dependencies: [types-all]\n</code></pre>"},{"location":"installation/development-setup/#code-quality-tools","title":"Code Quality Tools","text":"<pre><code># Format code\nblack .\n\n# Check code style\nflake8 .\n\n# Type checking\nmypy src/\n\n# Security analysis\npip install bandit\nbandit -r src/\n</code></pre>"},{"location":"installation/development-setup/#8-database-setup-optional","title":"8. Database Setup (Optional)","text":"<p>For advanced features requiring database:</p> <pre><code># Install database dependencies\npip install psycopg2-binary  # PostgreSQL\npip install redis            # Redis cache\n\n# Setup PostgreSQL (Ubuntu/Debian)\nsudo apt install postgresql postgresql-contrib\nsudo -u postgres createdb steel_defect_db\n\n# Setup Redis\nsudo apt install redis-server\nredis-cli ping  # Should return \"PONG\"\n</code></pre>"},{"location":"installation/development-setup/#development-workflow","title":"Development Workflow","text":""},{"location":"installation/development-setup/#daily-development","title":"Daily Development","text":"<pre><code># Activate environment\nsource steel_defect_env/bin/activate\n\n# Pull latest changes\ngit pull origin main\n\n# Install new dependencies (if any)\npip install -e .\n\n# Run tests before starting work\npytest tests/\n\n# Start development server\npython scripts/run_dashboard.py\n</code></pre>"},{"location":"installation/development-setup/#code-development-cycle","title":"Code Development Cycle","text":"<ol> <li> <p>Create Feature Branch <pre><code>git checkout -b feature/your-feature-name\n</code></pre></p> </li> <li> <p>Write Code and Tests <pre><code># Edit code in src/\n# Add tests in tests/\n</code></pre></p> </li> <li> <p>Test Changes <pre><code># Run tests\npytest tests/\n\n# Check code quality\nblack .\nflake8 .\n</code></pre></p> </li> <li> <p>Commit Changes <pre><code>git add .\ngit commit -m \"feat: add your feature description\"\n</code></pre></p> </li> <li> <p>Push and Create PR <pre><code>git push origin feature/your-feature-name\n# Create pull request on GitHub\n</code></pre></p> </li> </ol>"},{"location":"installation/development-setup/#documentation-development","title":"Documentation Development","text":"<pre><code># Start documentation server\nmkdocs serve\n\n# Edit documentation files in docs_site/\n# Changes automatically reload in browser\n\n# Build for production\nmkdocs build\n</code></pre>"},{"location":"installation/development-setup/#testing","title":"Testing","text":"<pre><code># Run all tests\npytest\n\n# Run specific test file\npytest tests/unit/test_models/test_baseline_model.py\n\n# Run with coverage\npytest --cov=src --cov-report=html\n\n# Run integration tests\npytest tests/integration/\n</code></pre>"},{"location":"installation/development-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"installation/development-setup/#common-issues","title":"Common Issues","text":"<p>Import Errors</p> <pre><code># If you get import errors, ensure package is installed in development mode\npip install -e .\n\n# Check Python path\npython -c \"import sys; print('\\n'.join(sys.path))\"\n</code></pre> <p>Permission Errors</p> <pre><code># Linux/macOS permission issues\nsudo chown -R $USER:$USER steel_defect_demo/\n\n# Windows permission issues\n# Run command prompt as administrator\n</code></pre> <p>Memory Issues</p> <pre><code># For large datasets or LSTM training\nexport PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512\n\n# Or reduce batch size in training configs\n</code></pre>"},{"location":"installation/development-setup/#environment-issues","title":"Environment Issues","text":"<pre><code># Reset virtual environment\ndeactivate\nrm -rf steel_defect_env/\npython -m venv steel_defect_env\nsource steel_defect_env/bin/activate\npip install -e .\n</code></pre>"},{"location":"installation/development-setup/#package-conflicts","title":"Package Conflicts","text":"<pre><code># Check installed packages\npip list\n\n# Check for conflicts\npip check\n\n# Create requirements.txt from current environment\npip freeze &gt; requirements-current.txt\n</code></pre>"},{"location":"installation/development-setup/#performance-optimization","title":"Performance Optimization","text":""},{"location":"installation/development-setup/#development-performance","title":"Development Performance","text":"<ul> <li>Use SSD storage for faster file operations</li> <li>Allocate sufficient RAM (8GB+ recommended)</li> <li>Enable GPU for LSTM training if available</li> <li>Use pytest-xdist for parallel test execution:   <pre><code>pip install pytest-xdist\npytest -n auto  # Run tests in parallel\n</code></pre></li> </ul>"},{"location":"installation/development-setup/#ide-performance","title":"IDE Performance","text":"<ul> <li>Exclude build directories from indexing</li> <li>Disable unnecessary plugins</li> <li>Use type hints for better IntelliSense</li> <li>Configure code completion for faster responses</li> </ul>"},{"location":"installation/development-setup/#next-steps","title":"Next Steps","text":"<p>Once your development environment is ready:</p> <ol> <li>Explore the Architecture: Review System Overview</li> <li>Understand the Dashboard: Read Dashboard Overview</li> <li>Learn the API: Check Dashboard Integration</li> <li>Start Contributing: See Contributing Guide</li> </ol> <p>Congratulations! \ud83c\udf89 Your development environment is now ready. You can start developing, testing, and contributing to the Steel Defect Prediction System.</p>"},{"location":"installation/docker-installation/","title":"Docker Installation","text":"<p>This guide covers installing and running the Steel Defect Prediction System using Docker containers.</p>"},{"location":"installation/docker-installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker Engine 20.10+ </li> <li>Docker Compose 2.0+</li> <li>8GB RAM minimum</li> <li>20GB free disk space</li> </ul>"},{"location":"installation/docker-installation/#quick-start-with-docker","title":"Quick Start with Docker","text":""},{"location":"installation/docker-installation/#1-pull-the-image","title":"1. Pull the Image","text":"<pre><code>docker pull ghcr.io/dhar174/steel-defect-prediction:latest\n</code></pre>"},{"location":"installation/docker-installation/#2-run-with-docker","title":"2. Run with Docker","text":"<pre><code># Basic run command\ndocker run -p 8000:8000 \\\n  -e DATABASE_URL=sqlite:///app/data/steel_defects.db \\\n  ghcr.io/dhar174/steel-defect-prediction:latest\n</code></pre>"},{"location":"installation/docker-installation/#3-access-the-application","title":"3. Access the Application","text":"<p>Open your browser to <code>http://localhost:8000</code></p>"},{"location":"installation/docker-installation/#docker-compose-setup","title":"Docker Compose Setup","text":""},{"location":"installation/docker-installation/#development-environment","title":"Development Environment","text":"<p>Create <code>docker-compose.yml</code>:</p> <pre><code>version: '3.8'\n\nservices:\n  app:\n    image: ghcr.io/dhar174/steel-defect-prediction:latest\n    ports:\n      - \"8000:8000\"\n    environment:\n      - DATABASE_URL=postgresql://postgres:password@db:5432/steel_defects\n      - REDIS_URL=redis://redis:6379/0\n    volumes:\n      - ./models:/app/models\n      - ./data:/app/data\n    depends_on:\n      - db\n      - redis\n\n  db:\n    image: postgres:13\n    environment:\n      - POSTGRES_DB=steel_defects\n      - POSTGRES_USER=postgres\n      - POSTGRES_PASSWORD=password\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n    ports:\n      - \"5432:5432\"\n\n  redis:\n    image: redis:6-alpine\n    ports:\n      - \"6379:6379\"\n\n  nginx:\n    image: nginx:alpine\n    ports:\n      - \"80:80\"\n    volumes:\n      - ./nginx.conf:/etc/nginx/nginx.conf\n    depends_on:\n      - app\n\nvolumes:\n  postgres_data:\n</code></pre>"},{"location":"installation/docker-installation/#start-the-stack","title":"Start the Stack","text":"<pre><code># Start all services\ndocker-compose up -d\n\n# View logs\ndocker-compose logs -f\n\n# Stop services\ndocker-compose down\n</code></pre>"},{"location":"installation/docker-installation/#custom-docker-build","title":"Custom Docker Build","text":""},{"location":"installation/docker-installation/#building-from-source","title":"Building from Source","text":"<pre><code># Clone repository\ngit clone https://github.com/dhar174/steel_defect_demo.git\ncd steel_defect_demo\n\n# Build the image\ndocker build -t steel-defect-prediction .\n\n# Run your custom build\ndocker run -p 8000:8000 steel-defect-prediction\n</code></pre>"},{"location":"installation/docker-installation/#dockerfile-overview","title":"Dockerfile Overview","text":"<pre><code>FROM python:3.9-slim\n\nWORKDIR /app\n\n# Install system dependencies\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    gcc \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Install Python dependencies\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy application code\nCOPY src/ ./src/\nCOPY configs/ ./configs/\n\n# Create data directories\nRUN mkdir -p /app/data /app/models /app/logs\n\n# Set permissions\nRUN useradd -m appuser &amp;&amp; chown -R appuser:appuser /app\nUSER appuser\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \\\n  CMD curl -f http://localhost:8000/health || exit 1\n\nEXPOSE 8000\n\nCMD [\"python\", \"-m\", \"uvicorn\", \"src.api.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre>"},{"location":"installation/docker-installation/#environment-configuration","title":"Environment Configuration","text":""},{"location":"installation/docker-installation/#environment-variables","title":"Environment Variables","text":"<p>Create <code>.env</code> file:</p> <pre><code># Database\nDATABASE_URL=postgresql://user:password@localhost:5432/steel_defects\nREDIS_URL=redis://localhost:6379/0\n\n# Application\nDEBUG=false\nLOG_LEVEL=INFO\nSECRET_KEY=your-secret-key\n\n# Model Configuration\nMODEL_PATH=/app/models/production_model.pth\nBATCH_SIZE=32\nPREDICTION_THRESHOLD=0.7\n\n# Monitoring\nENABLE_METRICS=true\nMETRICS_PORT=9090\n</code></pre>"},{"location":"installation/docker-installation/#configuration-files","title":"Configuration Files","text":"<p>Mount configuration files:</p> <pre><code>docker run -v $(pwd)/configs:/app/configs steel-defect-prediction\n</code></pre>"},{"location":"installation/docker-installation/#volume-management","title":"Volume Management","text":""},{"location":"installation/docker-installation/#persistent-data","title":"Persistent Data","text":"<pre><code># Create named volumes\ndocker volume create steel_models\ndocker volume create steel_data\n\n# Use in containers\ndocker run -v steel_models:/app/models \\\n           -v steel_data:/app/data \\\n           steel-defect-prediction\n</code></pre>"},{"location":"installation/docker-installation/#backup-volumes","title":"Backup Volumes","text":"<pre><code># Backup models\ndocker run --rm -v steel_models:/data -v $(pwd):/backup \\\n  alpine tar czf /backup/models_backup.tar.gz -C /data .\n\n# Restore models\ndocker run --rm -v steel_models:/data -v $(pwd):/backup \\\n  alpine tar xzf /backup/models_backup.tar.gz -C /data\n</code></pre>"},{"location":"installation/docker-installation/#networking","title":"Networking","text":""},{"location":"installation/docker-installation/#custom-networks","title":"Custom Networks","text":"<pre><code># Create custom network\ndocker network create steel-network\n\n# Run containers on custom network\ndocker run --network steel-network steel-defect-prediction\n</code></pre>"},{"location":"installation/docker-installation/#service-discovery","title":"Service Discovery","text":"<p>Use Docker Compose service names for internal communication:</p> <pre><code>services:\n  app:\n    environment:\n      - DATABASE_URL=postgresql://postgres:password@db:5432/steel_defects\n</code></pre>"},{"location":"installation/docker-installation/#security","title":"Security","text":""},{"location":"installation/docker-installation/#non-root-user","title":"Non-root User","text":"<pre><code>RUN useradd -m -u 1001 appuser\nUSER appuser\n</code></pre>"},{"location":"installation/docker-installation/#secrets-management","title":"Secrets Management","text":"<pre><code># Use Docker secrets\necho \"my-secret-key\" | docker secret create app_secret_key -\n\n# In compose file\nservices:\n  app:\n    secrets:\n      - app_secret_key\n</code></pre>"},{"location":"installation/docker-installation/#multi-stage-builds","title":"Multi-stage Builds","text":"<pre><code># Build stage\nFROM python:3.9 as builder\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install --user -r requirements.txt\n\n# Production stage\nFROM python:3.9-slim\nWORKDIR /app\nCOPY --from=builder /root/.local /root/.local\nCOPY src/ ./src/\nENV PATH=/root/.local/bin:$PATH\nCMD [\"python\", \"-m\", \"src.api.main\"]\n</code></pre>"},{"location":"installation/docker-installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"installation/docker-installation/#common-issues","title":"Common Issues","text":"<ol> <li>Port conflicts: Use different ports with <code>-p 8001:8000</code></li> <li>Permission errors: Check file ownership and permissions</li> <li>Memory issues: Increase Docker memory allocation</li> <li>Network issues: Verify container networking</li> </ol>"},{"location":"installation/docker-installation/#debugging","title":"Debugging","text":"<pre><code># Enter running container\ndocker exec -it &lt;container_id&gt; /bin/bash\n\n# View container logs\ndocker logs &lt;container_id&gt;\n\n# Inspect container\ndocker inspect &lt;container_id&gt;\n</code></pre>"},{"location":"installation/docker-installation/#performance-monitoring","title":"Performance Monitoring","text":"<pre><code># Container stats\ndocker stats\n\n# System resource usage\ndocker system df\ndocker system prune\n</code></pre>"},{"location":"installation/production-deployment/","title":"Production Deployment","text":"<p>This guide covers deploying the Steel Defect Prediction System in a production environment.</p>"},{"location":"installation/production-deployment/#prerequisites","title":"Prerequisites","text":"<ul> <li>Linux server with Docker support (Ubuntu 20.04+ recommended)</li> <li>Minimum 8GB RAM, 4 CPU cores</li> <li>50GB available disk space</li> <li>Network access for API endpoints</li> <li>SSL certificates for HTTPS</li> </ul>"},{"location":"installation/production-deployment/#deployment-options","title":"Deployment Options","text":""},{"location":"installation/production-deployment/#option-1-docker-compose-recommended","title":"Option 1: Docker Compose (Recommended)","text":"<pre><code># Clone the repository\ngit clone https://github.com/dhar174/steel_defect_demo.git\ncd steel_defect_demo\n\n# Copy production configuration\ncp configs/production.yml.example configs/production.yml\n\n# Edit configuration for your environment\nnano configs/production.yml\n\n# Deploy with Docker Compose\ndocker-compose -f docker-compose.prod.yml up -d\n</code></pre>"},{"location":"installation/production-deployment/#option-2-kubernetes","title":"Option 2: Kubernetes","text":"<pre><code># Apply Kubernetes manifests\nkubectl apply -f k8s/namespace.yml\nkubectl apply -f k8s/configmap.yml\nkubectl apply -f k8s/deployment.yml\nkubectl apply -f k8s/service.yml\nkubectl apply -f k8s/ingress.yml\n</code></pre>"},{"location":"installation/production-deployment/#configuration","title":"Configuration","text":""},{"location":"installation/production-deployment/#environment-variables","title":"Environment Variables","text":"<pre><code># Database Configuration\nDATABASE_URL=postgresql://user:password@localhost:5432/steel_defects\nREDIS_URL=redis://localhost:6379/0\n\n# API Configuration\nAPI_HOST=0.0.0.0\nAPI_PORT=8000\nSECRET_KEY=your-secret-key-here\n\n# Model Configuration\nMODEL_PATH=/app/models/production_model.pth\nPREDICTION_THRESHOLD=0.7\n\n# Monitoring\nENABLE_METRICS=true\nPROMETHEUS_PORT=9090\n</code></pre>"},{"location":"installation/production-deployment/#ssl-configuration","title":"SSL Configuration","text":"<pre><code>server {\n    listen 443 ssl;\n    server_name your-domain.com;\n\n    ssl_certificate /path/to/certificate.crt;\n    ssl_certificate_key /path/to/private.key;\n\n    location / {\n        proxy_pass http://localhost:8000;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n    }\n}\n</code></pre>"},{"location":"installation/production-deployment/#health-checks","title":"Health Checks","text":"<p>The system provides health check endpoints:</p> <ul> <li><code>/health</code> - Basic health status</li> <li><code>/health/detailed</code> - Detailed component status</li> <li><code>/metrics</code> - Prometheus metrics</li> </ul>"},{"location":"installation/production-deployment/#backup-strategy","title":"Backup Strategy","text":""},{"location":"installation/production-deployment/#database-backup","title":"Database Backup","text":"<pre><code># Daily backup script\n#!/bin/bash\npg_dump steel_defects &gt; backup_$(date +%Y%m%d).sql\naws s3 cp backup_$(date +%Y%m%d).sql s3://your-backup-bucket/\n</code></pre>"},{"location":"installation/production-deployment/#model-backup","title":"Model Backup","text":"<pre><code># Backup trained models\ntar -czf models_backup_$(date +%Y%m%d).tar.gz models/\naws s3 cp models_backup_$(date +%Y%m%d).tar.gz s3://your-model-bucket/\n</code></pre>"},{"location":"installation/production-deployment/#security-considerations","title":"Security Considerations","text":"<ul> <li>Use TLS 1.2+ for all communications</li> <li>Implement API rate limiting</li> <li>Enable authentication for admin endpoints</li> <li>Regular security updates</li> <li>Network segmentation</li> <li>Log monitoring and alerting</li> </ul>"},{"location":"installation/production-deployment/#performance-tuning","title":"Performance Tuning","text":""},{"location":"installation/production-deployment/#database-optimization","title":"Database Optimization","text":"<pre><code>-- Index optimization for frequent queries\nCREATE INDEX idx_sensor_data_timestamp ON sensor_data(timestamp);\nCREATE INDEX idx_predictions_cast_id ON predictions(cast_id);\n</code></pre>"},{"location":"installation/production-deployment/#model-serving-optimization","title":"Model Serving Optimization","text":"<pre><code># Batch prediction configuration\nBATCH_SIZE = 32\nMAX_BATCH_WAIT_TIME = 100  # milliseconds\nWORKER_THREADS = 4\n</code></pre>"},{"location":"installation/production-deployment/#monitoring-and-alerting","title":"Monitoring and Alerting","text":"<p>Set up monitoring for:</p> <ul> <li>System resource usage (CPU, memory, disk)</li> <li>Application metrics (response time, error rate)</li> <li>Model performance (prediction accuracy, drift)</li> <li>Database performance</li> <li>Alert thresholds</li> </ul>"},{"location":"installation/production-deployment/#troubleshooting","title":"Troubleshooting","text":""},{"location":"installation/production-deployment/#common-issues","title":"Common Issues","text":"<ol> <li>High memory usage: Increase container memory limits</li> <li>Slow predictions: Check model loading and GPU availability</li> <li>Database connection issues: Verify network connectivity and credentials</li> <li>SSL certificate errors: Verify certificate validity and configuration</li> </ol>"},{"location":"installation/production-deployment/#log-locations","title":"Log Locations","text":"<ul> <li>Application logs: <code>/var/log/steel-defect-prediction/app.log</code></li> <li>Database logs: <code>/var/log/postgresql/postgresql.log</code></li> <li>Nginx logs: <code>/var/log/nginx/access.log</code></li> </ul>"},{"location":"installation/production-deployment/#scaling","title":"Scaling","text":""},{"location":"installation/production-deployment/#horizontal-scaling","title":"Horizontal Scaling","text":"<pre><code># docker-compose.prod.yml\nservices:\n  api:\n    image: steel-defect-prediction:latest\n    deploy:\n      replicas: 3\n    environment:\n      - LOAD_BALANCER=nginx\n</code></pre>"},{"location":"installation/production-deployment/#auto-scaling","title":"Auto-scaling","text":"<p>Configure auto-scaling based on:</p> <ul> <li>CPU utilization &gt; 70%</li> <li>Memory utilization &gt; 80%</li> <li>Request queue length &gt; 100</li> </ul>"},{"location":"installation/troubleshooting/","title":"Installation Troubleshooting","text":"<p>This guide helps resolve common installation issues for the Steel Defect Prediction System.</p>"},{"location":"installation/troubleshooting/#common-installation-issues","title":"Common Installation Issues","text":""},{"location":"installation/troubleshooting/#python-dependencies","title":"Python Dependencies","text":""},{"location":"installation/troubleshooting/#issue-package-installation-fails","title":"Issue: Package installation fails","text":"<pre><code>ERROR: Could not install packages due to an EnvironmentError\n</code></pre> <p>Solutions:</p> <pre><code># Solution 1: Upgrade pip\npip install --upgrade pip\n\n# Solution 2: Use virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\npip install -r requirements.txt\n\n# Solution 3: Install with user flag\npip install --user -r requirements.txt\n</code></pre>"},{"location":"installation/troubleshooting/#issue-pytorch-installation-problems","title":"Issue: PyTorch installation problems","text":"<p>For CPU-only installation:</p> <pre><code>pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n</code></pre> <p>For GPU installation:</p> <pre><code># CUDA 11.8\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n\n# CUDA 12.1\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n</code></pre>"},{"location":"installation/troubleshooting/#issue-numpyscipy-compilation-errors","title":"Issue: NumPy/SciPy compilation errors","text":"<pre><code># Install system dependencies (Ubuntu/Debian)\nsudo apt-get update\nsudo apt-get install build-essential python3-dev\n\n# Install system dependencies (CentOS/RHEL)\nsudo yum groupinstall \"Development Tools\"\nsudo yum install python3-devel\n\n# Use conda instead\nconda install numpy scipy pandas scikit-learn\n</code></pre>"},{"location":"installation/troubleshooting/#database-issues","title":"Database Issues","text":""},{"location":"installation/troubleshooting/#issue-postgresql-connection-failed","title":"Issue: PostgreSQL connection failed","text":"<pre><code>psql: error: connection to server on socket \"/var/run/postgresql/.s.PGSQL.5432\" failed\n</code></pre> <p>Solutions:</p> <pre><code># Check if PostgreSQL is running\nsudo systemctl status postgresql\n\n# Start PostgreSQL\nsudo systemctl start postgresql\n\n# Check connection parameters\nexport DATABASE_URL=\"postgresql://username:password@localhost:5432/steel_defects\"\n\n# Test connection\npsql $DATABASE_URL -c \"SELECT version();\"\n</code></pre>"},{"location":"installation/troubleshooting/#issue-database-does-not-exist","title":"Issue: Database does not exist","text":"<pre><code>-- Create database\nCREATE DATABASE steel_defects;\n\n-- Create user\nCREATE USER steel_user WITH PASSWORD 'your_password';\nGRANT ALL PRIVILEGES ON DATABASE steel_defects TO steel_user;\n</code></pre>"},{"location":"installation/troubleshooting/#issue-permission-denied-for-database","title":"Issue: Permission denied for database","text":"<pre><code>-- Grant permissions\nGRANT ALL PRIVILEGES ON DATABASE steel_defects TO steel_user;\nGRANT ALL ON SCHEMA public TO steel_user;\n</code></pre>"},{"location":"installation/troubleshooting/#docker-issues","title":"Docker Issues","text":""},{"location":"installation/troubleshooting/#issue-docker-daemon-not-running","title":"Issue: Docker daemon not running","text":"<pre><code># Linux\nsudo systemctl start docker\nsudo systemctl enable docker\n\n# Add user to docker group\nsudo usermod -aG docker $USER\n</code></pre>"},{"location":"installation/troubleshooting/#issue-permission-denied-for-docker","title":"Issue: Permission denied for Docker","text":"<pre><code># Fix Docker permissions\nsudo chmod 666 /var/run/docker.sock\n\n# Or restart Docker service\nsudo systemctl restart docker\n</code></pre>"},{"location":"installation/troubleshooting/#issue-out-of-disk-space","title":"Issue: Out of disk space","text":"<pre><code># Clean up Docker\ndocker system prune -a\n\n# Remove unused volumes\ndocker volume prune\n\n# Check disk usage\ndocker system df\n</code></pre>"},{"location":"installation/troubleshooting/#memory-and-performance-issues","title":"Memory and Performance Issues","text":""},{"location":"installation/troubleshooting/#issue-out-of-memory-during-model-training","title":"Issue: Out of memory during model training","text":"<p>Solutions:</p> <pre><code># Reduce batch size\nBATCH_SIZE = 16  # Instead of 32 or 64\n\n# Enable gradient checkpointing\nmodel.gradient_checkpointing_enable()\n\n# Use mixed precision training\nfrom torch.cuda.amp import autocast\nwith autocast():\n    outputs = model(inputs)\n</code></pre>"},{"location":"installation/troubleshooting/#issue-slow-model-inference","title":"Issue: Slow model inference","text":"<pre><code># Optimize model for inference\nmodel.eval()\ntorch.set_grad_enabled(False)\n\n# Use torchscript\nscripted_model = torch.jit.script(model)\n\n# Use ONNX for deployment\ntorch.onnx.export(model, dummy_input, \"model.onnx\")\n</code></pre>"},{"location":"installation/troubleshooting/#import-and-path-issues","title":"Import and Path Issues","text":""},{"location":"installation/troubleshooting/#issue-modulenotfounderror","title":"Issue: ModuleNotFoundError","text":"<pre><code># Add project root to Python path\nexport PYTHONPATH=\"${PYTHONPATH}:/path/to/steel_defect_demo\"\n\n# Or in Python\nimport sys\nsys.path.append('/path/to/steel_defect_demo')\n</code></pre>"},{"location":"installation/troubleshooting/#issue-relative-import-errors","title":"Issue: Relative import errors","text":"<pre><code># Use absolute imports\nfrom src.models.lstm_model import LSTMModel\n# Instead of: from ..models.lstm_model import LSTMModel\n</code></pre>"},{"location":"installation/troubleshooting/#configuration-issues","title":"Configuration Issues","text":""},{"location":"installation/troubleshooting/#issue-configuration-file-not-found","title":"Issue: Configuration file not found","text":"<pre><code># Verify config file exists\nls -la configs/\n\n# Copy from template\ncp configs/config.yml.example configs/config.yml\n\n# Set environment variable\nexport CONFIG_PATH=/path/to/configs/config.yml\n</code></pre>"},{"location":"installation/troubleshooting/#issue-invalid-configuration-format","title":"Issue: Invalid configuration format","text":"<pre><code># Validate YAML syntax\npython -c \"import yaml; yaml.safe_load(open('configs/config.yml'))\"\n\n# Check for common YAML errors\nyamllint configs/config.yml\n</code></pre>"},{"location":"installation/troubleshooting/#network-and-api-issues","title":"Network and API Issues","text":""},{"location":"installation/troubleshooting/#issue-port-already-in-use","title":"Issue: Port already in use","text":"<pre><code># Find process using port\nlsof -i :8000\n\n# Kill process\nkill -9 &lt;PID&gt;\n\n# Use different port\nuvicorn src.api.main:app --port 8001\n</code></pre>"},{"location":"installation/troubleshooting/#issue-api-not-accessible","title":"Issue: API not accessible","text":"<pre><code># Check if service is running\ncurl http://localhost:8000/health\n\n# Check firewall\nsudo ufw status\nsudo ufw allow 8000\n\n# Check binding address\nuvicorn src.api.main:app --host 0.0.0.0 --port 8000\n</code></pre>"},{"location":"installation/troubleshooting/#model-and-data-issues","title":"Model and Data Issues","text":""},{"location":"installation/troubleshooting/#issue-model-file-not-found","title":"Issue: Model file not found","text":"<pre><code># Check model path\nls -la models/\n\n# Download pre-trained model\nwget https://github.com/dhar174/steel_defect_demo/releases/download/v1.0/model.pth\n</code></pre>"},{"location":"installation/troubleshooting/#issue-incompatible-model-format","title":"Issue: Incompatible model format","text":"<pre><code># Check PyTorch version compatibility\nimport torch\nprint(torch.__version__)\n\n# Load with map_location for CPU\nmodel = torch.load('model.pth', map_location='cpu')\n</code></pre>"},{"location":"installation/troubleshooting/#issue-data-preprocessing-errors","title":"Issue: Data preprocessing errors","text":"<pre><code># Check data format\nimport pandas as pd\ndata = pd.read_csv('data/sensor_data.csv')\nprint(data.dtypes)\nprint(data.isnull().sum())\n\n# Handle missing values\ndata = data.dropna()\n# or\ndata = data.fillna(data.mean())\n</code></pre>"},{"location":"installation/troubleshooting/#system-requirements-verification","title":"System Requirements Verification","text":""},{"location":"installation/troubleshooting/#check-python-version","title":"Check Python Version","text":"<pre><code>python --version  # Should be 3.8+\n</code></pre>"},{"location":"installation/troubleshooting/#check-system-resources","title":"Check System Resources","text":"<pre><code># Memory\nfree -h\n\n# Disk space\ndf -h\n\n# CPU info\nlscpu\n</code></pre>"},{"location":"installation/troubleshooting/#check-gpu-if-using","title":"Check GPU (if using)","text":"<pre><code># NVIDIA GPU\nnvidia-smi\n\n# In Python\nimport torch\nprint(torch.cuda.is_available())\nprint(torch.cuda.device_count())\n</code></pre>"},{"location":"installation/troubleshooting/#environment-validation-script","title":"Environment Validation Script","text":"<p>Create <code>validate_environment.py</code>:</p> <pre><code>#!/usr/bin/env python3\nimport sys\nimport subprocess\nimport importlib\n\ndef check_python_version():\n    if sys.version_info &lt; (3, 8):\n        print(\"\u274c Python 3.8+ required\")\n        return False\n    print(f\"\u2705 Python {sys.version}\")\n    return True\n\ndef check_packages():\n    required_packages = [\n        'torch', 'pandas', 'numpy', 'scikit-learn',\n        'fastapi', 'uvicorn', 'sqlalchemy', 'psycopg2'\n    ]\n\n    for package in required_packages:\n        try:\n            importlib.import_module(package)\n            print(f\"\u2705 {package}\")\n        except ImportError:\n            print(f\"\u274c {package} not found\")\n            return False\n    return True\n\ndef check_database():\n    try:\n        import psycopg2\n        # Test connection logic here\n        print(\"\u2705 Database connection\")\n        return True\n    except Exception as e:\n        print(f\"\u274c Database: {e}\")\n        return False\n\nif __name__ == \"__main__\":\n    checks = [\n        check_python_version(),\n        check_packages(),\n        check_database()\n    ]\n\n    if all(checks):\n        print(\"\\n\ud83c\udf89 Environment validation passed!\")\n    else:\n        print(\"\\n\u274c Environment validation failed!\")\n        sys.exit(1)\n</code></pre> <p>Run validation:</p> <pre><code>python validate_environment.py\n</code></pre>"},{"location":"installation/troubleshooting/#getting-help","title":"Getting Help","text":""},{"location":"installation/troubleshooting/#log-files","title":"Log Files","text":"<p>Check application logs:</p> <pre><code># Application logs\ntail -f logs/application.log\n\n# System logs\njournalctl -u steel-defect-prediction\n\n# Docker logs\ndocker logs &lt;container_name&gt;\n</code></pre>"},{"location":"installation/troubleshooting/#debug-mode","title":"Debug Mode","text":"<p>Enable debug logging:</p> <pre><code>export LOG_LEVEL=DEBUG\npython -m src.api.main\n</code></pre>"},{"location":"installation/troubleshooting/#community-support","title":"Community Support","text":"<ul> <li>GitHub Issues: Report bugs and issues</li> <li>Discussions: Ask questions and get help</li> <li>Documentation: Full documentation</li> </ul>"},{"location":"installation/troubleshooting/#professional-support","title":"Professional Support","text":"<p>For enterprise support and consulting:</p> <ul> <li>Email: support@steel-defect-prediction.com</li> <li>Documentation: Enterprise Support</li> <li>Training: Custom training programs available</li> </ul>"},{"location":"operations/backup-recovery/","title":"Backup &amp; Recovery","text":"<p>Data backup and disaster recovery procedures.</p>"},{"location":"operations/backup-recovery/#backup-strategy","title":"Backup Strategy","text":"<ul> <li>Daily database backups</li> <li>Model versioning</li> <li>Configuration management</li> </ul>"},{"location":"operations/backup-recovery/#recovery-procedures","title":"Recovery Procedures","text":"<ul> <li>Point-in-time recovery</li> <li>System restoration</li> <li>Business continuity plans</li> </ul>"},{"location":"operations/incident-response/","title":"Incident Response","text":"<p>Procedures for handling system incidents and outages.</p>"},{"location":"operations/incident-response/#incident-classification","title":"Incident Classification","text":"<ul> <li>Severity levels</li> <li>Response times</li> <li>Escalation paths</li> </ul>"},{"location":"operations/incident-response/#response-procedures","title":"Response Procedures","text":"<ul> <li>Initial assessment</li> <li>Containment strategies</li> <li>Resolution steps</li> </ul>"},{"location":"operations/maintenance/","title":"Maintenance","text":"<p>System maintenance procedures and best practices.</p>"},{"location":"operations/maintenance/#scheduled-maintenance","title":"Scheduled Maintenance","text":"<ul> <li>Weekly system updates</li> <li>Monthly security patches</li> <li>Quarterly performance reviews</li> </ul>"},{"location":"operations/maintenance/#preventive-maintenance","title":"Preventive Maintenance","text":"<ul> <li>Database optimization</li> <li>Log rotation</li> <li>Model retraining</li> </ul>"},{"location":"operations/maintenance/#emergency-procedures","title":"Emergency Procedures","text":"<ul> <li>Incident response</li> <li>System recovery</li> <li>Data restoration</li> </ul>"},{"location":"operations/monitoring/","title":"Monitoring","text":"<p>System monitoring and observability for production operations.</p>"},{"location":"operations/monitoring/#metrics-collection","title":"Metrics Collection","text":"<ul> <li>Application performance metrics</li> <li>System resource monitoring</li> <li>Business KPIs tracking</li> </ul>"},{"location":"operations/monitoring/#alerting","title":"Alerting","text":"<ul> <li>Real-time alert generation</li> <li>Escalation procedures</li> <li>Notification channels</li> </ul>"},{"location":"operations/monitoring/#dashboards","title":"Dashboards","text":"<ul> <li>Grafana dashboards</li> <li>Real-time status displays</li> <li>Historical trend analysis</li> </ul>"},{"location":"operations/performance-tuning/","title":"Performance Tuning","text":"<p>System performance optimization guidelines.</p>"},{"location":"operations/performance-tuning/#database-optimization","title":"Database Optimization","text":"<ul> <li>Query optimization</li> <li>Index management</li> <li>Connection pooling</li> </ul>"},{"location":"operations/performance-tuning/#application-tuning","title":"Application Tuning","text":"<ul> <li>Memory management</li> <li>CPU optimization</li> <li>Network optimization</li> </ul>"},{"location":"releases/changelog/","title":"Changelog","text":"<p>All notable changes to the Steel Defect Prediction System will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"releases/changelog/#unreleased","title":"[Unreleased]","text":""},{"location":"releases/changelog/#added","title":"Added","text":"<ul> <li>Comprehensive documentation system with MkDocs</li> <li>Interactive API documentation</li> <li>Architecture diagrams with Mermaid</li> <li>Contributing guidelines for developers</li> </ul>"},{"location":"releases/changelog/#changed","title":"Changed","text":"<ul> <li>Enhanced documentation structure</li> <li>Improved code organization</li> </ul>"},{"location":"releases/changelog/#fixed","title":"Fixed","text":"<ul> <li>Documentation build warnings</li> <li>Missing dependency specifications</li> </ul>"},{"location":"releases/changelog/#010-2024-01-20","title":"[0.1.0] - 2024-01-20","text":""},{"location":"releases/changelog/#added_1","title":"Added","text":"<ul> <li>Initial Release \ud83c\udf89</li> <li>Complete steel casting defect prediction system</li> <li>Machine Learning Models:</li> <li>XGBoost baseline model with feature engineering</li> <li>LSTM deep learning model for sequence analysis</li> <li>Ensemble modeling combining multiple approaches</li> <li>Interactive Dashboard:</li> <li>Real-time monitoring interface</li> <li>Model performance comparison</li> <li>Historical data analysis</li> <li>Alert management system</li> <li>Data Pipeline:</li> <li>Synthetic data generation for testing</li> <li>Data quality assessment tools</li> <li>Feature engineering pipeline</li> <li>Data validation and preprocessing</li> <li>Visualization Components:</li> <li>Real-time sensor monitoring</li> <li>Prediction display with confidence intervals</li> <li>Model comparison charts (ROC, PR curves)</li> <li>Feature importance visualization</li> <li>Alert management interface</li> <li>Analysis Tools:</li> <li>Statistical analysis capabilities</li> <li>Correlation analysis</li> <li>Historical trend analysis</li> <li>Performance monitoring</li> <li>Integration Features:</li> <li>Modular component architecture</li> <li>Python API for programmatic access</li> <li>Dashboard callback system</li> <li>Configurable alert thresholds</li> </ul>"},{"location":"releases/changelog/#technical-specifications","title":"Technical Specifications","text":"<ul> <li>Language: Python 3.8+</li> <li>ML Framework: XGBoost, PyTorch, scikit-learn</li> <li>Web Framework: Dash (Plotly) with Bootstrap</li> <li>Data Processing: pandas, NumPy, PyArrow</li> <li>Visualization: Plotly, matplotlib, seaborn</li> <li>Testing: pytest with comprehensive test suite</li> </ul>"},{"location":"releases/changelog/#key-features","title":"Key Features","text":"<ul> <li>Real-time Prediction: Sub-second inference on streaming data</li> <li>Multi-model Ensemble: Combines baseline and deep learning approaches</li> <li>Interactive Dashboard: Responsive web interface for monitoring</li> <li>Comprehensive Analytics: Statistical analysis and trend detection</li> <li>Modular Architecture: Reusable components for easy integration</li> <li>Quality Monitoring: Built-in data quality assessment</li> <li>Alert System: Configurable thresholds and notifications</li> </ul>"},{"location":"releases/changelog/#demo-components","title":"Demo Components","text":"<ul> <li>Model comparison demonstrations</li> <li>Sensor monitoring examples</li> <li>Historical analysis workflows</li> <li>Alert management scenarios</li> <li>Integration examples</li> </ul>"},{"location":"releases/changelog/#documentation","title":"Documentation","text":"<ul> <li>User guides and tutorials</li> <li>API documentation</li> <li>Installation instructions</li> <li>Development guidelines</li> <li>Architecture documentation</li> </ul>"},{"location":"releases/changelog/#version-history-summary","title":"Version History Summary","text":"Version Release Date Key Features 0.1.0 2024-01-20 Initial release with ML models, dashboard, and analytics"},{"location":"releases/changelog/#upgrade-guide","title":"Upgrade Guide","text":""},{"location":"releases/changelog/#from-development-to-010","title":"From Development to 0.1.0","text":"<p>This is the initial release. No upgrade procedures needed.</p>"},{"location":"releases/changelog/#future-upgrades","title":"Future Upgrades","text":"<p>Migration guides will be provided for future versions that introduce breaking changes.</p>"},{"location":"releases/changelog/#breaking-changes","title":"Breaking Changes","text":""},{"location":"releases/changelog/#010","title":"0.1.0","text":"<ul> <li>No breaking changes (initial release)</li> </ul>"},{"location":"releases/changelog/#security-updates","title":"Security Updates","text":""},{"location":"releases/changelog/#010_1","title":"0.1.0","text":"<ul> <li>Initial security implementation</li> <li>Input validation for all user data</li> <li>Safe handling of file operations</li> <li>Configurable access controls</li> </ul>"},{"location":"releases/changelog/#performance-improvements","title":"Performance Improvements","text":""},{"location":"releases/changelog/#010_2","title":"0.1.0","text":"<ul> <li>Optimized model inference pipeline</li> <li>Efficient data processing with vectorized operations</li> <li>Cached model loading for faster startup</li> <li>Responsive dashboard with lazy loading</li> </ul>"},{"location":"releases/changelog/#bug-fixes","title":"Bug Fixes","text":""},{"location":"releases/changelog/#010_3","title":"0.1.0","text":"<ul> <li>No bug fixes (initial release)</li> </ul>"},{"location":"releases/changelog/#deprecated-features","title":"Deprecated Features","text":""},{"location":"releases/changelog/#010_4","title":"0.1.0","text":"<ul> <li>No deprecated features (initial release)</li> </ul>"},{"location":"releases/changelog/#known-issues","title":"Known Issues","text":""},{"location":"releases/changelog/#010_5","title":"0.1.0","text":"<ul> <li>Dashboard may require manual refresh in some browsers</li> <li>Large datasets (&gt;100k samples) may impact performance</li> <li>LSTM training requires significant memory for long sequences</li> </ul>"},{"location":"releases/changelog/#planned-features","title":"Planned Features","text":""},{"location":"releases/changelog/#future-releases","title":"Future Releases","text":"<ul> <li>Enhanced Models:</li> <li>Transformer-based sequence models</li> <li>AutoML for automatic model selection</li> <li> <p>Continuous learning capabilities</p> </li> <li> <p>Advanced Analytics:</p> </li> <li>Anomaly detection algorithms</li> <li>Predictive maintenance features</li> <li> <p>Advanced statistical analysis</p> </li> <li> <p>Integration Improvements:</p> </li> <li>REST API endpoints</li> <li>Database connectors for production systems</li> <li> <p>Real-time streaming data support</p> </li> <li> <p>User Experience:</p> </li> <li>Mobile-responsive dashboard</li> <li>Custom dashboard creation</li> <li> <p>Advanced visualization options</p> </li> <li> <p>Production Features:</p> </li> <li>Model versioning and rollback</li> <li>A/B testing framework</li> <li>Advanced monitoring and logging</li> </ul>"},{"location":"releases/changelog/#contributing","title":"Contributing","text":"<p>See Contributing Guide for information on how to contribute to this project.</p>"},{"location":"releases/changelog/#support","title":"Support","text":"<ul> <li>Documentation: Browse this comprehensive guide</li> <li>Issues: GitHub Issues</li> <li>Discussions: GitHub Discussions</li> </ul> <p>For detailed technical changes, see the Git commit history.</p> <ul> <li>Initial documentation site structure</li> <li>Markdownlint compliance for all documentation files</li> <li>Comprehensive user guide for dashboard interface</li> </ul>"},{"location":"releases/changelog/#changed_1","title":"Changed","text":"<ul> <li>Improved code organization and documentation standards</li> <li>Enhanced error handling in prediction pipeline</li> </ul>"},{"location":"releases/changelog/#fixed_1","title":"Fixed","text":"<ul> <li>Resolved markdownlint formatting issues in documentation</li> <li>Fixed compatibility issues with latest dependencies</li> </ul>"},{"location":"releases/changelog/#100-2024-07-22","title":"[1.0.0] - 2024-07-22","text":""},{"location":"releases/changelog/#features-added","title":"Features Added","text":"<ul> <li>LSTM-based defect prediction model</li> <li>Baseline statistical model for comparison</li> <li>Real-time dashboard interface</li> <li>Alert management system</li> <li>Historical data analysis capabilities</li> <li>Sensor data visualization components</li> <li>Integration with continuous casting equipment</li> <li>Comprehensive test suite</li> <li>API documentation</li> <li>User guides and technical documentation</li> </ul>"},{"location":"releases/changelog/#core-features","title":"Core Features","text":"<ul> <li>Machine Learning Models</li> <li>LSTM neural network for time-series prediction</li> <li>Gradient boosting baseline model</li> <li> <p>Model comparison and evaluation tools</p> </li> <li> <p>Dashboard Interface</p> </li> <li>Real-time monitoring displays</li> <li>Interactive charts and visualizations</li> <li>Alert status and management</li> <li> <p>Historical trend analysis</p> </li> <li> <p>Data Processing</p> </li> <li>Automated data quality assessment</li> <li>Feature engineering pipeline</li> <li>Real-time data ingestion</li> <li> <p>Statistical analysis tools</p> </li> <li> <p>System Integration</p> </li> <li>PLC connectivity for industrial systems</li> <li>REST API for external integrations</li> <li>Configurable alert thresholds</li> <li>Export capabilities for reports</li> </ul>"},{"location":"releases/changelog/#technical-specifications_1","title":"Technical Specifications","text":"<ul> <li>Python 3.8+ compatibility</li> <li>PyTorch for deep learning models</li> <li>Streamlit for dashboard interface</li> <li>Pandas for data manipulation</li> <li>Comprehensive logging and monitoring</li> </ul>"},{"location":"releases/changelog/#090-2024-07-15","title":"[0.9.0] - 2024-07-15","text":""},{"location":"releases/changelog/#initial-development","title":"Initial Development","text":"<ul> <li>Initial project structure</li> <li>Basic model training scripts</li> <li>Data preprocessing utilities</li> <li>Initial dashboard prototype</li> </ul>"},{"location":"releases/changelog/#improvements","title":"Improvements","text":"<ul> <li>Refactored code organization</li> <li>Improved data loading performance</li> </ul>"},{"location":"releases/changelog/#010-2024-07-01","title":"[0.1.0] - 2024-07-01","text":""},{"location":"releases/changelog/#project-initialization","title":"Project Initialization","text":"<ul> <li>Project initialization</li> <li>Basic documentation</li> <li>Initial development environment setup</li> </ul>"},{"location":"releases/compatibility/","title":"Compatibility","text":"<p>System compatibility and version support information.</p>"},{"location":"releases/compatibility/#supported-versions","title":"Supported Versions","text":"<ul> <li>Python 3.8+</li> <li>PostgreSQL 12+</li> <li>Redis 6+</li> </ul>"},{"location":"releases/compatibility/#browser-compatibility","title":"Browser Compatibility","text":"<ul> <li>Chrome 90+</li> <li>Firefox 88+</li> <li>Safari 14+</li> </ul>"},{"location":"releases/compatibility/#api-compatibility","title":"API Compatibility","text":"<ul> <li>REST API versioning</li> <li>Backward compatibility</li> <li>Deprecation timeline</li> </ul>"},{"location":"releases/migration-guides/","title":"Migration Guides","text":"<p>Guidelines for migrating between system versions.</p>"},{"location":"releases/migration-guides/#version-20-to-21","title":"Version 2.0 to 2.1","text":"<ul> <li>Database schema changes</li> <li>API updates</li> <li>Configuration changes</li> </ul>"},{"location":"releases/migration-guides/#migration-checklist","title":"Migration Checklist","text":"<ul> <li>Backup procedures</li> <li>Testing requirements</li> <li>Rollback plans</li> </ul>"},{"location":"releases/migration-guides/#common-issues","title":"Common Issues","text":"<ul> <li>Compatibility problems</li> <li>Performance considerations</li> <li>Data migration steps</li> </ul>"},{"location":"tutorials/advanced-features/","title":"Advanced Features","text":"<p>Advanced functionality and customization options.</p>"},{"location":"tutorials/advanced-features/#custom-models","title":"Custom Models","text":"<ul> <li>Training new models</li> <li>Model comparison</li> <li>Performance tuning</li> </ul>"},{"location":"tutorials/advanced-features/#integration-apis","title":"Integration APIs","text":"<ul> <li>REST API usage</li> <li>WebSocket connections</li> <li>Batch processing</li> </ul>"},{"location":"tutorials/advanced-features/#advanced-analytics","title":"Advanced Analytics","text":"<ul> <li>Historical analysis</li> <li>Trend detection</li> <li>Root cause analysis</li> </ul>"},{"location":"tutorials/basic-usage/","title":"Basic Usage","text":"<p>Getting started with the Steel Defect Prediction System.</p>"},{"location":"tutorials/basic-usage/#first-steps","title":"First Steps","text":"<ol> <li>System login</li> <li>Dashboard overview</li> <li>Making predictions</li> <li>Viewing results</li> </ol>"},{"location":"tutorials/basic-usage/#common-tasks","title":"Common Tasks","text":"<ul> <li>Monitoring production lines</li> <li>Reviewing alerts</li> <li>Generating reports</li> </ul>"},{"location":"tutorials/basic-usage/#best-practices","title":"Best Practices","text":"<ul> <li>Data quality guidelines</li> <li>Interpretation of results</li> <li>When to take action</li> </ul>"},{"location":"tutorials/customization/","title":"Customization","text":"<p>Customizing the system for specific needs.</p>"},{"location":"tutorials/customization/#dashboard-customization","title":"Dashboard Customization","text":"<ul> <li>Widget configuration</li> <li>Layout management</li> <li>Custom visualizations</li> </ul>"},{"location":"tutorials/customization/#alert-customization","title":"Alert Customization","text":"<ul> <li>Custom rules</li> <li>Notification preferences</li> <li>Escalation procedures</li> </ul>"},{"location":"tutorials/customization/#reporting-customization","title":"Reporting Customization","text":"<ul> <li>Report templates</li> <li>Scheduled reports</li> <li>Export formats</li> </ul>"},{"location":"tutorials/integration-examples/","title":"Integration Examples","text":"<p>Examples of integrating with external systems.</p>"},{"location":"tutorials/integration-examples/#scada-integration","title":"SCADA Integration","text":"<ul> <li>Data collection setup</li> <li>Alert forwarding</li> <li>Process control integration</li> </ul>"},{"location":"tutorials/integration-examples/#erp-integration","title":"ERP Integration","text":"<ul> <li>Production planning</li> <li>Quality reporting</li> <li>Cost analysis</li> </ul>"},{"location":"tutorials/integration-examples/#third-party-systems","title":"Third-party Systems","text":"<ul> <li>Notification services</li> <li>Monitoring platforms</li> <li>Data warehouses</li> </ul>"},{"location":"user-guide/alert-management/","title":"Alert Management","text":"<p>The Alert Management system provides comprehensive monitoring and notification capabilities for the Steel Defect Prediction System, ensuring timely response to critical conditions.</p>"},{"location":"user-guide/alert-management/#overview","title":"Overview","text":"<p>Alert management features include:</p> <ul> <li>Real-time defect probability alerts</li> <li>Process parameter threshold monitoring</li> <li>Multi-channel notification system</li> <li>Alert escalation and acknowledgment</li> <li>Historical alert tracking and analysis</li> </ul>"},{"location":"user-guide/alert-management/#alert-types","title":"Alert Types","text":""},{"location":"user-guide/alert-management/#defect-probability-alerts","title":"Defect Probability Alerts","text":"<p>Critical Alert: Defect probability &gt; 80% <pre><code>{\n    \"alert_id\": \"CRIT-001\",\n    \"type\": \"defect_probability\",\n    \"level\": \"critical\",\n    \"probability\": 0.85,\n    \"threshold\": 0.80,\n    \"message\": \"High defect probability detected in casting line 1\"\n}\n</code></pre></p> <p>Warning Alert: Defect probability 60-80% <pre><code>{\n    \"alert_id\": \"WARN-002\", \n    \"type\": \"defect_probability\",\n    \"level\": \"warning\",\n    \"probability\": 0.72,\n    \"threshold\": 0.60,\n    \"message\": \"Elevated defect risk in casting line 1\"\n}\n</code></pre></p>"},{"location":"user-guide/alert-management/#process-parameter-alerts","title":"Process Parameter Alerts","text":"<p>Temperature Deviation <pre><code>{\n    \"alert_id\": \"TEMP-003\",\n    \"type\": \"temperature_deviation\", \n    \"level\": \"warning\",\n    \"current_value\": 1580.5,\n    \"target_value\": 1525.0,\n    \"deviation\": 55.5,\n    \"message\": \"Mold temperature exceeds target by 55\u00b0C\"\n}\n</code></pre></p> <p>Flow Rate Alert <pre><code>{\n    \"alert_id\": \"FLOW-004\",\n    \"type\": \"flow_rate\",\n    \"level\": \"critical\",\n    \"current_value\": 150.2,\n    \"min_threshold\": 180.0,\n    \"message\": \"Cooling water flow below minimum threshold\"\n}\n</code></pre></p>"},{"location":"user-guide/alert-management/#alert-configuration","title":"Alert Configuration","text":""},{"location":"user-guide/alert-management/#setting-alert-rules","title":"Setting Alert Rules","text":"<pre><code>from src.alerts.alert_manager import AlertManager\n\n# Initialize alert manager\nalert_manager = AlertManager()\n\n# Configure defect probability alerts\nalert_manager.add_rule({\n    'name': 'high_defect_probability',\n    'condition': 'defect_probability &gt; 0.8',\n    'level': 'critical',\n    'cooldown': 300,  # 5 minutes\n    'notifications': ['email', 'sms', 'dashboard']\n})\n\n# Configure process parameter alerts\nalert_manager.add_rule({\n    'name': 'temperature_deviation',\n    'condition': 'abs(mold_temperature - target_temperature) &gt; 50',\n    'level': 'warning', \n    'cooldown': 600,  # 10 minutes\n    'notifications': ['email', 'dashboard']\n})\n</code></pre>"},{"location":"user-guide/alert-management/#threshold-management","title":"Threshold Management","text":"<pre><code># alerts.yml configuration\nalert_thresholds:\n  defect_probability:\n    warning: 0.6\n    critical: 0.8\n\n  mold_temperature:\n    min_warning: 1480\n    max_warning: 1570\n    min_critical: 1450\n    max_critical: 1600\n\n  casting_speed:\n    min_warning: 0.8\n    max_warning: 1.4\n    min_critical: 0.6\n    max_critical: 1.6\n\n  cooling_water_flow:\n    min_warning: 180\n    min_critical: 160\n</code></pre>"},{"location":"user-guide/alert-management/#notification-channels","title":"Notification Channels","text":""},{"location":"user-guide/alert-management/#email-notifications","title":"Email Notifications","text":"<pre><code># Email configuration\nemail_config = {\n    'smtp_server': 'smtp.company.com',\n    'smtp_port': 587,\n    'username': 'alerts@company.com',\n    'password': '${EMAIL_PASSWORD}',\n    'recipients': {\n        'critical': ['supervisor@company.com', 'manager@company.com'],\n        'warning': ['operator@company.com', 'technician@company.com'],\n        'info': ['operator@company.com']\n    }\n}\n\n# Send email alert\nfrom src.alerts.email_notifier import EmailNotifier\n\nnotifier = EmailNotifier(email_config)\nnotifier.send_alert({\n    'level': 'critical',\n    'subject': 'Critical Defect Alert - Line 1',\n    'message': 'High defect probability detected. Immediate attention required.',\n    'data': sensor_data\n})\n</code></pre>"},{"location":"user-guide/alert-management/#sms-notifications","title":"SMS Notifications","text":"<pre><code># SMS configuration using Twilio\nsms_config = {\n    'account_sid': '${TWILIO_ACCOUNT_SID}',\n    'auth_token': '${TWILIO_AUTH_TOKEN}',\n    'from_number': '+1234567890',\n    'recipients': {\n        'critical': ['+1987654321', '+1456789012'],\n        'warning': ['+1987654321']\n    }\n}\n\n# Send SMS alert\nfrom src.alerts.sms_notifier import SMSNotifier\n\nsms_notifier = SMSNotifier(sms_config)\nsms_notifier.send_alert({\n    'level': 'critical',\n    'message': 'URGENT: Critical defect alert on Line 1. Defect probability: 85%'\n})\n</code></pre>"},{"location":"user-guide/alert-management/#dashboard-notifications","title":"Dashboard Notifications","text":"<pre><code>// Real-time dashboard alerts\nconst alertSocket = new WebSocket('ws://localhost:8000/alerts');\n\nalertSocket.onmessage = function(event) {\n    const alert = JSON.parse(event.data);\n    displayAlert(alert);\n};\n\nfunction displayAlert(alert) {\n    const alertElement = document.createElement('div');\n    alertElement.className = `alert alert-${alert.level}`;\n    alertElement.innerHTML = `\n        &lt;strong&gt;${alert.level.toUpperCase()}&lt;/strong&gt;\n        &lt;p&gt;${alert.message}&lt;/p&gt;\n        &lt;span class=\"timestamp\"&gt;${alert.timestamp}&lt;/span&gt;\n        &lt;button onclick=\"acknowledgeAlert('${alert.id}')\"&gt;Acknowledge&lt;/button&gt;\n    `;\n\n    document.getElementById('alerts-container').appendChild(alertElement);\n}\n</code></pre>"},{"location":"user-guide/alert-management/#alert-escalation","title":"Alert Escalation","text":""},{"location":"user-guide/alert-management/#escalation-rules","title":"Escalation Rules","text":"<pre><code># Define escalation chain\nescalation_config = {\n    'levels': [\n        {\n            'name': 'operator',\n            'timeout': 300,  # 5 minutes\n            'notifications': ['dashboard', 'email']\n        },\n        {\n            'name': 'supervisor', \n            'timeout': 600,  # 10 minutes\n            'notifications': ['email', 'sms']\n        },\n        {\n            'name': 'manager',\n            'timeout': 1200,  # 20 minutes\n            'notifications': ['email', 'sms', 'phone_call']\n        }\n    ]\n}\n\n# Implement escalation\nfrom src.alerts.escalation_manager import EscalationManager\n\nescalation_manager = EscalationManager(escalation_config)\nescalation_manager.start_escalation(alert_id='CRIT-001')\n</code></pre>"},{"location":"user-guide/alert-management/#auto-escalation-logic","title":"Auto-escalation Logic","text":"<pre><code>class AlertEscalator:\n    def __init__(self, escalation_rules):\n        self.rules = escalation_rules\n        self.active_escalations = {}\n\n    def escalate_alert(self, alert):\n        escalation_id = self.start_escalation(alert)\n\n        # Schedule escalation steps\n        for level in self.rules['levels']:\n            threading.Timer(\n                level['timeout'],\n                self.escalate_to_level,\n                args=[escalation_id, level]\n            ).start()\n\n    def escalate_to_level(self, escalation_id, level):\n        if not self.is_acknowledged(escalation_id):\n            self.send_notifications(level['notifications'])\n            logging.info(f\"Escalated alert {escalation_id} to {level['name']}\")\n</code></pre>"},{"location":"user-guide/alert-management/#alert-dashboard","title":"Alert Dashboard","text":""},{"location":"user-guide/alert-management/#alert-status-overview","title":"Alert Status Overview","text":"<pre><code># Get current alert status\nfrom src.alerts.alert_dashboard import AlertDashboard\n\ndashboard = AlertDashboard()\nstatus = dashboard.get_alert_status()\n\nprint(f\"Active alerts: {status['active_count']}\")\nprint(f\"Critical alerts: {status['critical_count']}\")\nprint(f\"Acknowledged alerts: {status['acknowledged_count']}\")\nprint(f\"Average response time: {status['avg_response_time']} minutes\")\n</code></pre>"},{"location":"user-guide/alert-management/#alert-history","title":"Alert History","text":"<pre><code># Query alert history\nalert_history = dashboard.get_alert_history(\n    start_date='2024-01-01',\n    end_date='2024-01-31',\n    levels=['critical', 'warning'],\n    acknowledged=True\n)\n\n# Generate alert statistics\nstats = dashboard.generate_alert_statistics(alert_history)\nprint(f\"Total alerts: {stats['total_alerts']}\")\nprint(f\"Most common alert type: {stats['most_common_type']}\")\nprint(f\"Average response time: {stats['avg_response_time']}\")\n</code></pre>"},{"location":"user-guide/alert-management/#alert-acknowledgment","title":"Alert Acknowledgment","text":""},{"location":"user-guide/alert-management/#manual-acknowledgment","title":"Manual Acknowledgment","text":"<pre><code># Acknowledge alert via API\nimport requests\n\nresponse = requests.post(\n    'http://localhost:8000/alerts/acknowledge',\n    json={\n        'alert_id': 'CRIT-001',\n        'acknowledged_by': 'operator_1',\n        'acknowledgment_note': 'Investigated and taking corrective action'\n    }\n)\n</code></pre>"},{"location":"user-guide/alert-management/#auto-acknowledgment-rules","title":"Auto-acknowledgment Rules","text":"<pre><code># Configure auto-acknowledgment\nauto_ack_rules = {\n    'defect_probability_resolved': {\n        'condition': 'defect_probability &lt; 0.5',\n        'delay': 60  # Wait 1 minute before auto-ack\n    },\n    'temperature_normalized': {\n        'condition': 'abs(mold_temperature - target_temperature) &lt; 10',\n        'delay': 120  # Wait 2 minutes before auto-ack\n    }\n}\n\n# Apply auto-acknowledgment\nfrom src.alerts.auto_acknowledger import AutoAcknowledger\n\nauto_ack = AutoAcknowledger(auto_ack_rules)\nauto_ack.check_for_resolution(current_sensor_data)\n</code></pre>"},{"location":"user-guide/alert-management/#alert-analytics","title":"Alert Analytics","text":""},{"location":"user-guide/alert-management/#alert-frequency-analysis","title":"Alert Frequency Analysis","text":"<pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Analyze alert patterns\nalert_df = pd.DataFrame(alert_history)\nalert_df['timestamp'] = pd.to_datetime(alert_df['timestamp'])\n\n# Alert frequency by hour\nhourly_alerts = alert_df.groupby(alert_df['timestamp'].dt.hour).size()\n\nplt.figure(figsize=(12, 6))\nplt.bar(hourly_alerts.index, hourly_alerts.values)\nplt.xlabel('Hour of Day')\nplt.ylabel('Alert Count')\nplt.title('Alert Frequency by Hour')\nplt.show()\n</code></pre>"},{"location":"user-guide/alert-management/#response-time-analysis","title":"Response Time Analysis","text":"<pre><code># Calculate response times\nalert_df['response_time'] = (\n    pd.to_datetime(alert_df['acknowledged_at']) - \n    pd.to_datetime(alert_df['created_at'])\n).dt.total_seconds() / 60  # Convert to minutes\n\n# Response time by alert level\nresponse_by_level = alert_df.groupby('level')['response_time'].agg([\n    'mean', 'median', 'std'\n])\n\nprint(\"Response Time Statistics (minutes):\")\nprint(response_by_level)\n</code></pre>"},{"location":"user-guide/alert-management/#integration-examples","title":"Integration Examples","text":""},{"location":"user-guide/alert-management/#scada-integration","title":"SCADA Integration","text":"<pre><code># Send alerts to SCADA system\nfrom src.integrations.scada_alerts import SCADAAlertSender\n\nscada_alerts = SCADAAlertSender(\n    host='scada.plant.com',\n    port=502\n)\n\n# Send alert to SCADA alarm system\nscada_alerts.send_alarm({\n    'alarm_id': 'ALM_001',\n    'description': 'High defect probability',\n    'severity': 'HIGH',\n    'area': 'Casting_Line_1'\n})\n</code></pre>"},{"location":"user-guide/alert-management/#third-party-systems","title":"Third-party Systems","text":"<pre><code># Send alerts to external monitoring systems\nwebhook_config = {\n    'url': 'https://monitoring.company.com/webhooks/alerts',\n    'headers': {\n        'Authorization': 'Bearer ${API_TOKEN}',\n        'Content-Type': 'application/json'\n    }\n}\n\n# Send webhook notification\nimport requests\n\ndef send_webhook_alert(alert_data):\n    response = requests.post(\n        webhook_config['url'],\n        json=alert_data,\n        headers=webhook_config['headers']\n    )\n    return response.status_code == 200\n</code></pre>"},{"location":"user-guide/alert-management/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/alert-management/#common-issues","title":"Common Issues","text":"<ol> <li>Alerts not firing: Check threshold configuration and sensor data flow</li> <li>Notification failures: Verify SMTP/SMS credentials and network connectivity</li> <li>False alarms: Adjust thresholds and add filtering conditions</li> <li>Missing escalations: Check escalation timer configuration</li> </ol>"},{"location":"user-guide/alert-management/#debug-tools","title":"Debug Tools","text":"<pre><code># Enable alert debugging\nimport logging\nlogging.getLogger('alerts').setLevel(logging.DEBUG)\n\n# Test alert configuration\nfrom src.alerts.tester import AlertTester\n\ntester = AlertTester()\ntest_results = tester.test_all_rules(test_data)\n\nfor rule, result in test_results.items():\n    print(f\"{rule}: {'PASS' if result['success'] else 'FAIL'}\")\n</code></pre> <p>This alert management system ensures prompt response to critical conditions and maintains operational safety in your steel casting operations.</p>"},{"location":"user-guide/dashboard-overview/","title":"Dashboard Overview","text":"<p>The Steel Defect Prediction System dashboard provides a comprehensive real-time monitoring interface for steel casting operations. This guide walks you through all major features and components.</p>"},{"location":"user-guide/dashboard-overview/#dashboard-access","title":"Dashboard Access","text":"<p>The dashboard is accessible at <code>http://localhost:8050</code> when running locally, or at your configured production URL.</p> <pre><code># Start the dashboard\npython scripts/run_dashboard.py\n</code></pre>"},{"location":"user-guide/dashboard-overview/#main-interface-layout","title":"Main Interface Layout","text":"<p>The dashboard is organized into several key sections:</p>"},{"location":"user-guide/dashboard-overview/#navigation-bar","title":"Navigation Bar","text":"<p>The top navigation provides access to all major dashboard sections:</p> <ul> <li>Real-time Monitoring: Live sensor data and predictions</li> <li>Model Comparison: Performance analysis between different models</li> <li>Historical Analysis: Trends and pattern analysis over time</li> <li>Alert Management: Configure and manage alert thresholds</li> <li>System Status: Monitor system health and performance</li> </ul>"},{"location":"user-guide/dashboard-overview/#main-content-area","title":"Main Content Area","text":"<p>The central area displays the selected dashboard view with interactive charts, tables, and controls.</p>"},{"location":"user-guide/dashboard-overview/#side-panel-when-applicable","title":"Side Panel (when applicable)","text":"<p>Some views include a side panel with: - Filter controls - Configuration options - Additional metrics - Quick actions</p>"},{"location":"user-guide/dashboard-overview/#key-features","title":"Key Features","text":""},{"location":"user-guide/dashboard-overview/#1-real-time-monitoring","title":"1. Real-time Monitoring","text":"<p>The real-time monitoring view provides:</p>"},{"location":"user-guide/dashboard-overview/#live-sensor-readings","title":"Live Sensor Readings","text":"<ul> <li>Temperature: Mold temperature readings</li> <li>Pressure: Casting pressure metrics</li> <li>Flow Rates: Cooling water and steel flow</li> <li>Speed: Casting speed monitoring</li> </ul>"},{"location":"user-guide/dashboard-overview/#prediction-display","title":"Prediction Display","text":"<ul> <li>Defect Probability: Real-time defect likelihood (0-1 scale)</li> <li>Confidence Score: Model confidence in predictions</li> <li>Alert Level: Visual indicators (Green/Yellow/Red)</li> <li>Trend Indicators: Directional arrows showing trends</li> </ul>"},{"location":"user-guide/dashboard-overview/#key-metrics-cards","title":"Key Metrics Cards","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Current Defect  \u2502 \u2502 Avg Confidence  \u2502 \u2502 Active Alerts   \u2502\n\u2502 Probability     \u2502 \u2502                 \u2502 \u2502                 \u2502\n\u2502                 \u2502 \u2502                 \u2502 \u2502                 \u2502\n\u2502     0.15        \u2502 \u2502     0.89        \u2502 \u2502       2         \u2502\n\u2502                 \u2502 \u2502                 \u2502 \u2502                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"user-guide/dashboard-overview/#2-model-comparison","title":"2. Model Comparison","text":""},{"location":"user-guide/dashboard-overview/#2-model-comparison_1","title":"2. Model Comparison","text":"<p>Compare performance between different ML models:</p>"},{"location":"user-guide/dashboard-overview/#performance-metrics","title":"Performance Metrics","text":"<ul> <li>Accuracy: Overall prediction accuracy</li> <li>Precision: True positive rate</li> <li>Recall: Sensitivity measure</li> <li>F1-Score: Harmonic mean of precision and recall</li> <li>AUC-ROC: Area under ROC curve</li> </ul>"},{"location":"user-guide/dashboard-overview/#visualization-charts","title":"Visualization Charts","text":"<ul> <li>ROC Curves: Model discrimination ability</li> <li>Precision-Recall Curves: Performance trade-offs</li> <li>Feature Importance: Variable significance</li> <li>Confusion Matrix: Classification accuracy breakdown</li> </ul>"},{"location":"user-guide/dashboard-overview/#side-by-side-comparison","title":"Side-by-side Comparison","text":"<pre><code>Model Performance Comparison\n                    XGBoost    LSTM     Ensemble\nAccuracy            0.87       0.89     0.91\nPrecision           0.84       0.88     0.90\nRecall              0.82       0.86     0.89\nF1-Score            0.83       0.87     0.89\nTraining Time       2.3 min    8.7 min  11.2 min\n</code></pre>"},{"location":"user-guide/dashboard-overview/#3-historical-analysis","title":"3. Historical Analysis","text":""},{"location":"user-guide/dashboard-overview/#3-historical-analysis_1","title":"3. Historical Analysis","text":"<p>Analyze trends and patterns over time:</p>"},{"location":"user-guide/dashboard-overview/#time-series-charts","title":"Time Series Charts","text":"<ul> <li>Defect Rate Trends: Historical defect rates</li> <li>Sensor Pattern Analysis: Long-term sensor behavior</li> <li>Model Performance: Accuracy trends over time</li> <li>Process Stability: Variance and consistency metrics</li> </ul>"},{"location":"user-guide/dashboard-overview/#interactive-features","title":"Interactive Features","text":"<ul> <li>Date Range Selection: Choose analysis period</li> <li>Zoom and Pan: Detailed chart exploration</li> <li>Data Export: Download analysis results</li> <li>Statistical Summaries: Automatic trend analysis</li> </ul>"},{"location":"user-guide/dashboard-overview/#4-alert-management","title":"4. Alert Management","text":""},{"location":"user-guide/dashboard-overview/#4-alert-management_1","title":"4. Alert Management","text":"<p>Configure and manage the alerting system:</p>"},{"location":"user-guide/dashboard-overview/#alert-configuration","title":"Alert Configuration","text":"<ul> <li>Threshold Settings: Defect probability limits</li> <li>Notification Methods: Email, SMS, dashboard</li> <li>Escalation Rules: Multi-level alert hierarchy</li> <li>Time-based Rules: Different thresholds by shift/time</li> </ul>"},{"location":"user-guide/dashboard-overview/#active-alerts-dashboard","title":"Active Alerts Dashboard","text":"<pre><code>Current Alerts\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 \ud83d\udd34 HIGH: Defect probability 0.85 (Threshold: 0.8)      \u2502\n\u2502 \ud83d\udfe1 MED:  Temperature variance above normal              \u2502\n\u2502 \ud83d\udfe1 MED:  Model confidence below 0.7                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"user-guide/dashboard-overview/#interactive-controls","title":"Interactive Controls","text":""},{"location":"user-guide/dashboard-overview/#time-range-selector","title":"Time Range Selector","text":"<p>Most views include time range controls:</p> <pre><code>[Last Hour] [Last 4 Hours] [Last Day] [Custom Range]\n</code></pre>"},{"location":"user-guide/dashboard-overview/#refresh-controls","title":"Refresh Controls","text":"<pre><code>Auto-refresh: [ON/OFF]  Interval: [5s] [15s] [30s] [1m]\n</code></pre>"},{"location":"user-guide/dashboard-overview/#export-options","title":"Export Options","text":"<pre><code>[Export CSV] [Export PNG] [Generate Report]\n</code></pre>"},{"location":"user-guide/dashboard-overview/#dashboard-configuration","title":"Dashboard Configuration","text":""},{"location":"user-guide/dashboard-overview/#user-preferences","title":"User Preferences","text":"<p>Access user preferences via the settings menu:</p> <ul> <li>Display Options: Chart types, color schemes</li> <li>Refresh Rates: Auto-update intervals</li> <li>Alert Preferences: Notification settings</li> <li>Dashboard Layout: Customize panel arrangement</li> </ul>"},{"location":"user-guide/dashboard-overview/#theme-options","title":"Theme Options","text":"<p>The dashboard supports multiple themes:</p> Light ThemeDark ThemeHigh Contrast <p>Clean, professional appearance suitable for well-lit environments.</p> <p>Reduced eye strain for low-light monitoring environments.</p> <p>Enhanced visibility for accessibility requirements.</p>"},{"location":"user-guide/dashboard-overview/#mobile-responsiveness","title":"Mobile Responsiveness","text":"<p>The dashboard is optimized for various screen sizes:</p>"},{"location":"user-guide/dashboard-overview/#desktop-1200px","title":"Desktop (&gt;1200px)","text":"<ul> <li>Full feature set</li> <li>Multi-panel layout</li> <li>Detailed charts and tables</li> </ul>"},{"location":"user-guide/dashboard-overview/#tablet-768px-1200px","title":"Tablet (768px - 1200px)","text":"<ul> <li>Responsive layout</li> <li>Simplified navigation</li> <li>Touch-friendly controls</li> </ul>"},{"location":"user-guide/dashboard-overview/#mobile-768px","title":"Mobile (&lt; 768px)","text":"<ul> <li>Essential features only</li> <li>Vertical layout</li> <li>Large touch targets</li> </ul>"},{"location":"user-guide/dashboard-overview/#performance-optimization","title":"Performance Optimization","text":""},{"location":"user-guide/dashboard-overview/#data-loading","title":"Data Loading","text":"<p>The dashboard implements several performance optimizations:</p> <ul> <li>Lazy Loading: Charts load only when visible</li> <li>Data Caching: Recent data cached locally</li> <li>Progressive Loading: Large datasets load incrementally</li> <li>WebSocket Updates: Real-time data via WebSockets</li> </ul>"},{"location":"user-guide/dashboard-overview/#browser-requirements","title":"Browser Requirements","text":"<p>For optimal performance: - RAM: 2GB+ available memory - Network: Stable internet connection - Browser: Modern browser with JavaScript enabled</p>"},{"location":"user-guide/dashboard-overview/#keyboard-shortcuts","title":"Keyboard Shortcuts","text":"Shortcut Action <code>R</code> Refresh current view <code>F</code> Toggle fullscreen <code>H</code> Show/hide help <code>Space</code> Pause/resume auto-refresh <code>Esc</code> Close modals"},{"location":"user-guide/dashboard-overview/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/dashboard-overview/#common-issues","title":"Common Issues","text":"<p>Dashboard Not Loading</p> <ul> <li>Check that the dashboard service is running</li> <li>Verify port 8050 is not blocked by firewall</li> <li>Clear browser cache and cookies</li> </ul> <p>Slow Performance</p> <ul> <li>Reduce auto-refresh frequency</li> <li>Clear browser cache</li> <li>Check network connectivity</li> <li>Restart dashboard service</li> </ul> <p>Data Not Updating</p> <ul> <li>Check data source connections</li> <li>Verify auto-refresh is enabled</li> <li>Check for JavaScript errors in browser console</li> </ul>"},{"location":"user-guide/dashboard-overview/#browser-console","title":"Browser Console","text":"<p>Access browser developer tools (F12) to check for errors:</p> <pre><code>// Check WebSocket connection\nconsole.log(window.WebSocket);\n\n// Check for JavaScript errors\nconsole.log('Dashboard loaded successfully');\n</code></pre>"},{"location":"user-guide/dashboard-overview/#getting-help","title":"Getting Help","text":"<ul> <li>Tooltips: Hover over charts and controls for help</li> <li>Help Menu: Click the <code>?</code> icon for context-sensitive help</li> <li>Documentation: This guide and API Reference</li> <li>Support: GitHub Issues</li> </ul>"},{"location":"user-guide/dashboard-overview/#next-api-reference","title":"Next: API Reference \u2192","text":""},{"location":"user-guide/dashboard-overview/#introduction","title":"Introduction","text":"<p>The Steel Defect Detection Dashboard provides a comprehensive interface for monitoring continuous steel casting processes and predicting quality defects in real-time. This guide covers all aspects of using the dashboard effectively.</p>"},{"location":"user-guide/dashboard-overview/#getting-started","title":"Getting Started","text":""},{"location":"user-guide/dashboard-overview/#accessing-the-dashboard","title":"Accessing the Dashboard","text":"<p>The dashboard is accessible through a web browser at the configured URL. Default local access is typically available at:</p> <pre><code>http://localhost:8501\n</code></pre>"},{"location":"user-guide/dashboard-overview/#authentication","title":"Authentication","text":"<p>Currently, the dashboard operates in demonstration mode without authentication requirements. In production deployments, appropriate access controls should be implemented.</p>"},{"location":"user-guide/dashboard-overview/#main-interface-components","title":"Main Interface Components","text":""},{"location":"user-guide/dashboard-overview/#navigation-menu","title":"Navigation Menu","text":"<p>The dashboard features a sidebar navigation with the following sections:</p> <ul> <li>Home: Overview and system status</li> <li>Real-time Monitoring: Live sensor data and predictions</li> <li>Historical Analysis: Past performance and trends</li> <li>Alert Management: Active alerts and notification settings</li> <li>Model Performance: ML model metrics and evaluation</li> <li>Configuration: System settings and parameters</li> </ul>"},{"location":"user-guide/dashboard-overview/#status-indicators","title":"Status Indicators","text":"<p>Color-coded status indicators provide quick visual feedback:</p> <ul> <li>Green: Normal operation, no issues detected</li> <li>Yellow: Warning condition, attention recommended</li> <li>Red: Alert condition, immediate action required</li> <li>Gray: No data or system offline</li> </ul>"},{"location":"user-guide/dashboard-overview/#real-time-monitoring","title":"Real-time Monitoring","text":""},{"location":"user-guide/dashboard-overview/#live-data-display","title":"Live Data Display","text":"<p>The monitoring interface shows real-time sensor data including:</p> <ul> <li>Temperature readings from multiple casting zones</li> <li>Pressure measurements throughout the process</li> <li>Flow rates for cooling water and molten steel</li> <li>Chemical composition data when available</li> </ul>"},{"location":"user-guide/dashboard-overview/#prediction-results","title":"Prediction Results","text":"<p>ML model predictions are displayed with:</p> <ul> <li>Defect probability scores for different defect types</li> <li>Confidence intervals for prediction reliability</li> <li>Risk assessments based on current process conditions</li> <li>Trend indicators showing prediction changes over time</li> </ul>"},{"location":"user-guide/dashboard-overview/#interactive-charts","title":"Interactive Charts","text":"<p>Charts and visualizations provide detailed insights:</p> <ul> <li>Time series plots for sensor data trends</li> <li>Correlation matrices showing parameter relationships</li> <li>Distribution plots for quality metrics</li> <li>Prediction timelines with historical context</li> </ul>"},{"location":"user-guide/dashboard-overview/#alert-management","title":"Alert Management","text":""},{"location":"user-guide/dashboard-overview/#alert-types","title":"Alert Types","text":"<p>The system monitors for several types of quality issues:</p> <ul> <li>Surface cracks: Longitudinal and transverse defects</li> <li>Internal defects: Inclusions and porosity</li> <li>Dimensional variations: Thickness and width deviations</li> <li>Chemical composition: Out-of-specification conditions</li> </ul>"},{"location":"user-guide/dashboard-overview/#alert-configuration_1","title":"Alert Configuration","text":"<p>Users can configure alert parameters:</p> <ul> <li>Threshold values for different defect probabilities</li> <li>Notification methods (dashboard, email, SMS)</li> <li>Escalation rules for critical conditions</li> <li>Acknowledgment requirements for alert resolution</li> </ul>"},{"location":"user-guide/dashboard-overview/#alert-history","title":"Alert History","text":"<p>The alert history section provides:</p> <ul> <li>Chronological log of all alert events</li> <li>Resolution tracking and response times</li> <li>Performance metrics for alert accuracy</li> <li>Export capabilities for reporting</li> </ul>"},{"location":"user-guide/dashboard-overview/#historical-analysis","title":"Historical Analysis","text":""},{"location":"user-guide/dashboard-overview/#data-exploration","title":"Data Exploration","text":"<p>Historical analysis tools include:</p> <ul> <li>Date range selection for specific time periods</li> <li>Filter options by shift, product type, or conditions</li> <li>Statistical summaries of process performance</li> <li>Trend analysis with regression and forecasting</li> </ul>"},{"location":"user-guide/dashboard-overview/#performance-metrics_1","title":"Performance Metrics","text":"<p>Key performance indicators (KPIs) tracked:</p> <ul> <li>Defect detection rate and false positive percentages</li> <li>Process efficiency and throughput metrics</li> <li>Quality scores and customer satisfaction data</li> <li>Cost impact analysis for defect prevention</li> </ul>"},{"location":"user-guide/dashboard-overview/#reporting-features","title":"Reporting Features","text":"<p>Generate comprehensive reports with:</p> <ul> <li>Executive summaries for management review</li> <li>Technical details for process engineers</li> <li>Trend analysis with recommendations</li> <li>Export formats (PDF, Excel, CSV)</li> </ul>"},{"location":"user-guide/dashboard-overview/#model-performance","title":"Model Performance","text":""},{"location":"user-guide/dashboard-overview/#model-metrics","title":"Model Metrics","text":"<p>Monitor ML model performance through:</p> <ul> <li>Accuracy scores and confusion matrices</li> <li>Precision and recall for different defect types</li> <li>ROC curves and AUC measurements</li> <li>Feature importance rankings</li> </ul>"},{"location":"user-guide/dashboard-overview/#model-comparison","title":"Model Comparison","text":"<p>Compare different model approaches:</p> <ul> <li>LSTM vs baseline model performance</li> <li>Training progress and validation curves</li> <li>Hyperparameter optimization results</li> <li>Ensemble model performance</li> </ul>"},{"location":"user-guide/dashboard-overview/#configuration-settings","title":"Configuration Settings","text":""},{"location":"user-guide/dashboard-overview/#system-parameters","title":"System Parameters","text":"<p>Configurable system settings include:</p> <ul> <li>Data ingestion frequency and sources</li> <li>Model prediction intervals and thresholds</li> <li>Display preferences and dashboard layout</li> <li>User access controls and permissions</li> </ul>"},{"location":"user-guide/dashboard-overview/#data-sources","title":"Data Sources","text":"<p>Configure data input connections:</p> <ul> <li>PLC interfaces for real-time sensor data</li> <li>Database connections for historical information</li> <li>File imports for batch processing</li> <li>API endpoints for external systems</li> </ul>"},{"location":"user-guide/dashboard-overview/#troubleshooting_1","title":"Troubleshooting","text":""},{"location":"user-guide/dashboard-overview/#common-issues_1","title":"Common Issues","text":"<p>Frequently encountered problems and solutions:</p> <ul> <li>Data connectivity: Check network and sensor connections</li> <li>Slow performance: Review data volume and processing load</li> <li>Prediction accuracy: Verify model training and data quality</li> <li>Display issues: Clear browser cache and check compatibility</li> </ul>"},{"location":"user-guide/dashboard-overview/#support-resources","title":"Support Resources","text":"<p>Additional help and support:</p> <ul> <li>User manual with detailed instructions</li> <li>Technical documentation for advanced configuration</li> <li>Contact information for system administrators</li> <li>Training materials and video tutorials</li> </ul>"},{"location":"user-guide/dashboard-overview/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/dashboard-overview/#monitoring-guidelines","title":"Monitoring Guidelines","text":"<p>Recommended practices for effective monitoring:</p> <ul> <li>Regular review of alert thresholds and accuracy</li> <li>Shift handover procedures using dashboard data</li> <li>Trend analysis for predictive maintenance</li> <li>Quality improvement based on historical patterns</li> </ul>"},{"location":"user-guide/dashboard-overview/#data-management","title":"Data Management","text":"<p>Maintain data quality through:</p> <ul> <li>Regular calibration of sensors and instruments</li> <li>Data validation checks and error correction</li> <li>Backup procedures for critical information</li> <li>Archive management for long-term storage</li> </ul>"},{"location":"user-guide/dashboard-overview/#conclusion","title":"Conclusion","text":"<p>The Steel Defect Detection Dashboard provides powerful tools for monitoring and improving continuous casting quality. Regular use of all features will maximize the benefits of predictive defect detection and help maintain optimal process performance.</p> <p>For additional support or questions about specific features, consult the technical documentation or contact the system development team.</p>"},{"location":"user-guide/historical-analysis/","title":"Historical Analysis","text":"<p>The Historical Analysis module provides comprehensive tools for analyzing past casting operations, identifying patterns, and improving future predictions based on historical data trends.</p>"},{"location":"user-guide/historical-analysis/#overview","title":"Overview","text":"<p>Historical analysis capabilities include:</p> <ul> <li>Trend analysis of defect patterns over time</li> <li>Process parameter correlation analysis</li> <li>Seasonal and cyclical pattern detection</li> <li>Root cause analysis of defect occurrences</li> <li>Performance benchmarking and reporting</li> </ul>"},{"location":"user-guide/historical-analysis/#accessing-historical-data","title":"Accessing Historical Data","text":""},{"location":"user-guide/historical-analysis/#data-sources","title":"Data Sources","text":"<p>Historical data is collected from multiple sources:</p> <pre><code>from src.analysis.historical_analyzer import HistoricalAnalyzer\n\n# Initialize analyzer with data sources\nanalyzer = HistoricalAnalyzer(\n    data_sources=[\n        'sensor_data',\n        'quality_inspections',\n        'production_logs',\n        'maintenance_records'\n    ],\n    date_range=('2023-01-01', '2024-01-01')\n)\n</code></pre>"},{"location":"user-guide/historical-analysis/#data-loading","title":"Data Loading","text":"<pre><code># Load historical dataset\nhistorical_data = analyzer.load_data(\n    table='production_history',\n    filters={\n        'steel_grade': ['304L', '316L', '410'],\n        'shift': ['morning', 'afternoon', 'night'],\n        'quality_status': ['pass', 'fail', 'rework']\n    }\n)\n\nprint(f\"Loaded {len(historical_data)} records\")\nprint(f\"Date range: {historical_data['timestamp'].min()} to {historical_data['timestamp'].max()}\")\n</code></pre>"},{"location":"user-guide/historical-analysis/#trend-analysis","title":"Trend Analysis","text":""},{"location":"user-guide/historical-analysis/#defect-rate-trends","title":"Defect Rate Trends","text":"<pre><code># Analyze defect rate trends over time\ndefect_trends = analyzer.analyze_defect_trends(\n    groupby='month',\n    metrics=['defect_rate', 'severity_level', 'defect_type']\n)\n\n# Visualize trends\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(12, 6))\nsns.lineplot(data=defect_trends, x='month', y='defect_rate')\nplt.title('Monthly Defect Rate Trends')\nplt.ylabel('Defect Rate (%)')\nplt.show()\n</code></pre>"},{"location":"user-guide/historical-analysis/#process-parameter-trends","title":"Process Parameter Trends","text":"<pre><code># Analyze key process parameters over time\nparameter_trends = analyzer.analyze_parameter_trends(\n    parameters=[\n        'mold_temperature',\n        'casting_speed',\n        'cooling_water_flow',\n        'steel_composition'\n    ],\n    aggregation='daily'\n)\n\n# Multi-parameter trend visualization\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\nparameters = ['mold_temperature', 'casting_speed', 'cooling_water_flow', 'steel_composition']\n\nfor i, param in enumerate(parameters):\n    ax = axes[i//2, i%2]\n    sns.lineplot(data=parameter_trends, x='date', y=param, ax=ax)\n    ax.set_title(f'{param.replace(\"_\", \" \").title()} Trend')\n    ax.tick_params(axis='x', rotation=45)\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"user-guide/historical-analysis/#correlation-analysis","title":"Correlation Analysis","text":""},{"location":"user-guide/historical-analysis/#parameter-correlation","title":"Parameter Correlation","text":"<pre><code># Calculate correlation between process parameters and defect occurrence\ncorrelation_matrix = analyzer.calculate_correlations(\n    target='defect_probability',\n    features=[\n        'mold_temperature',\n        'casting_speed',\n        'cooling_water_flow',\n        'oxygen_content',\n        'carbon_content'\n    ]\n)\n\n# Visualize correlation matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\nplt.title('Process Parameter Correlations with Defect Probability')\nplt.show()\n</code></pre>"},{"location":"user-guide/historical-analysis/#cross-correlation-analysis","title":"Cross-correlation Analysis","text":"<pre><code># Time-lagged correlation analysis\ncross_correlations = analyzer.cross_correlation_analysis(\n    primary_signal='mold_temperature',\n    secondary_signal='defect_rate',\n    max_lag=24  # hours\n)\n\n# Plot cross-correlation\nplt.figure(figsize=(10, 6))\nplt.plot(cross_correlations['lag'], cross_correlations['correlation'])\nplt.axhline(y=0, color='k', linestyle='--', alpha=0.5)\nplt.xlabel('Lag (hours)')\nplt.ylabel('Cross-correlation')\nplt.title('Cross-correlation: Mold Temperature vs Defect Rate')\nplt.grid(True, alpha=0.3)\nplt.show()\n</code></pre>"},{"location":"user-guide/historical-analysis/#pattern-detection","title":"Pattern Detection","text":""},{"location":"user-guide/historical-analysis/#seasonal-patterns","title":"Seasonal Patterns","text":"<pre><code>from src.analysis.pattern_detector import SeasonalPatternDetector\n\n# Detect seasonal patterns in defect occurrence\nseasonal_detector = SeasonalPatternDetector()\nseasonal_patterns = seasonal_detector.detect_patterns(\n    data=historical_data,\n    target='defect_rate',\n    periods=['hourly', 'daily', 'weekly', 'monthly']\n)\n\n# Visualize seasonal patterns\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\nperiods = ['hourly', 'daily', 'weekly', 'monthly']\n\nfor i, period in enumerate(periods):\n    ax = axes[i//2, i%2]\n    pattern_data = seasonal_patterns[period]\n    ax.plot(pattern_data['time'], pattern_data['average_defect_rate'])\n    ax.set_title(f'{period.title()} Defect Rate Pattern')\n    ax.set_ylabel('Average Defect Rate (%)')\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"user-guide/historical-analysis/#anomaly-detection","title":"Anomaly Detection","text":"<pre><code>from src.analysis.anomaly_detector import HistoricalAnomalyDetector\n\n# Detect historical anomalies\nanomaly_detector = HistoricalAnomalyDetector(\n    method='isolation_forest',\n    contamination=0.1  # 10% expected anomalies\n)\n\nanomalies = anomaly_detector.detect_anomalies(\n    data=historical_data,\n    features=['mold_temperature', 'casting_speed', 'cooling_water_flow']\n)\n\n# Visualize anomalies\nplt.figure(figsize=(12, 8))\nplt.scatter(historical_data['timestamp'], historical_data['defect_rate'], \n           c='blue', alpha=0.6, label='Normal')\nplt.scatter(anomalies['timestamp'], anomalies['defect_rate'], \n           c='red', alpha=0.8, label='Anomalies')\nplt.xlabel('Time')\nplt.ylabel('Defect Rate (%)')\nplt.title('Historical Anomalies in Defect Rate')\nplt.legend()\nplt.xticks(rotation=45)\nplt.show()\n</code></pre>"},{"location":"user-guide/historical-analysis/#root-cause-analysis","title":"Root Cause Analysis","text":""},{"location":"user-guide/historical-analysis/#statistical-analysis","title":"Statistical Analysis","text":"<pre><code>from src.analysis.root_cause_analyzer import RootCauseAnalyzer\n\n# Perform root cause analysis for high defect periods\nrca_analyzer = RootCauseAnalyzer()\n\n# Identify periods with high defect rates\nhigh_defect_periods = historical_data[historical_data['defect_rate'] &gt; 15]\n\n# Analyze contributing factors\nroot_causes = rca_analyzer.analyze_factors(\n    high_defect_data=high_defect_periods,\n    normal_data=historical_data[historical_data['defect_rate'] &lt;= 5],\n    factors=[\n        'mold_temperature',\n        'casting_speed',\n        'steel_grade',\n        'shift',\n        'operator_id',\n        'maintenance_status'\n    ]\n)\n\n# Display top contributing factors\nprint(\"Top Contributing Factors to High Defect Rates:\")\nfor factor, importance in root_causes.items():\n    print(f\"  {factor}: {importance:.3f}\")\n</code></pre>"},{"location":"user-guide/historical-analysis/#decision-tree-analysis","title":"Decision Tree Analysis","text":"<pre><code>from sklearn.tree import DecisionTreeClassifier, plot_tree\n\n# Build decision tree for defect prediction\nfeatures = ['mold_temperature', 'casting_speed', 'cooling_water_flow', \n           'oxygen_content', 'carbon_content']\n\nX = historical_data[features]\ny = (historical_data['defect_rate'] &gt; 10).astype(int)  # Binary classification\n\ndt_model = DecisionTreeClassifier(max_depth=5, random_state=42)\ndt_model.fit(X, y)\n\n# Visualize decision tree\nplt.figure(figsize=(20, 10))\nplot_tree(dt_model, feature_names=features, class_names=['Normal', 'High Defect'],\n          filled=True, fontsize=10)\nplt.title('Decision Tree for Defect Prediction')\nplt.show()\n</code></pre>"},{"location":"user-guide/historical-analysis/#time-series-analysis","title":"Time Series Analysis","text":""},{"location":"user-guide/historical-analysis/#trend-decomposition","title":"Trend Decomposition","text":"<pre><code>from statsmodels.tsa.seasonal import seasonal_decompose\n\n# Decompose time series into trend, seasonal, and residual components\ndefect_ts = historical_data.set_index('timestamp')['defect_rate'].resample('D').mean()\n\ndecomposition = seasonal_decompose(defect_ts, model='additive', period=7)\n\n# Plot decomposition\nfig, axes = plt.subplots(4, 1, figsize=(12, 10))\ndecomposition.observed.plot(ax=axes[0], title='Original')\ndecomposition.trend.plot(ax=axes[1], title='Trend')\ndecomposition.seasonal.plot(ax=axes[2], title='Seasonal')\ndecomposition.resid.plot(ax=axes[3], title='Residual')\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"user-guide/historical-analysis/#forecast-analysis","title":"Forecast Analysis","text":"<pre><code>from statsmodels.tsa.arima.model import ARIMA\n\n# ARIMA forecasting for defect rates\nmodel = ARIMA(defect_ts, order=(2, 1, 2))\nfitted_model = model.fit()\n\n# Generate forecast\nforecast = fitted_model.forecast(steps=30)  # 30 days ahead\nforecast_index = pd.date_range(start=defect_ts.index[-1] + pd.Timedelta(days=1), \n                              periods=30, freq='D')\n\n# Plot historical data and forecast\nplt.figure(figsize=(12, 6))\nplt.plot(defect_ts.index[-90:], defect_ts[-90:], label='Historical', color='blue')\nplt.plot(forecast_index, forecast, label='Forecast', color='red', linestyle='--')\nplt.fill_between(forecast_index, \n                forecast - 1.96*np.sqrt(fitted_model.forecast(steps=30, return_conf_int=True)[1][:, 1]),\n                forecast + 1.96*np.sqrt(fitted_model.forecast(steps=30, return_conf_int=True)[1][:, 1]),\n                alpha=0.3, color='red')\nplt.xlabel('Date')\nplt.ylabel('Defect Rate (%)')\nplt.title('Defect Rate Forecast')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n</code></pre>"},{"location":"user-guide/historical-analysis/#performance-analysis","title":"Performance Analysis","text":""},{"location":"user-guide/historical-analysis/#production-efficiency","title":"Production Efficiency","text":"<pre><code># Analyze production efficiency metrics\nefficiency_metrics = analyzer.calculate_efficiency_metrics(\n    metrics=[\n        'overall_equipment_effectiveness',\n        'first_pass_yield',\n        'defect_rate',\n        'production_rate',\n        'downtime_percentage'\n    ],\n    groupby=['month', 'steel_grade', 'shift']\n)\n\n# Efficiency trend analysis\nplt.figure(figsize=(12, 8))\nfor steel_grade in efficiency_metrics['steel_grade'].unique():\n    grade_data = efficiency_metrics[efficiency_metrics['steel_grade'] == steel_grade]\n    plt.plot(grade_data['month'], grade_data['overall_equipment_effectiveness'], \n            label=steel_grade, marker='o')\n\nplt.xlabel('Month')\nplt.ylabel('Overall Equipment Effectiveness (%)')\nplt.title('OEE Trends by Steel Grade')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n</code></pre>"},{"location":"user-guide/historical-analysis/#quality-benchmarking","title":"Quality Benchmarking","text":"<pre><code># Benchmark against industry standards or internal targets\nbenchmarks = {\n    'defect_rate_target': 5.0,  # Target: &lt; 5%\n    'first_pass_yield_target': 95.0,  # Target: &gt; 95%\n    'oee_target': 85.0  # Target: &gt; 85%\n}\n\nperformance_vs_benchmark = analyzer.benchmark_performance(\n    data=historical_data,\n    benchmarks=benchmarks,\n    groupby='month'\n)\n\n# Visualize performance vs benchmarks\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\nmetrics = ['defect_rate', 'first_pass_yield', 'oee']\n\nfor i, metric in enumerate(metrics):\n    ax = axes[i]\n    ax.plot(performance_vs_benchmark['month'], \n           performance_vs_benchmark[metric], \n           label='Actual', marker='o')\n    ax.axhline(y=benchmarks[f'{metric}_target'], \n              color='red', linestyle='--', label='Target')\n    ax.set_title(f'{metric.replace(\"_\", \" \").title()}')\n    ax.set_ylabel('Value')\n    ax.legend()\n    ax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"user-guide/historical-analysis/#report-generation","title":"Report Generation","text":""},{"location":"user-guide/historical-analysis/#automated-reports","title":"Automated Reports","text":"<pre><code>from src.reporting.historical_reporter import HistoricalReporter\n\n# Generate comprehensive historical analysis report\nreporter = HistoricalReporter()\nreport = reporter.generate_report(\n    data=historical_data,\n    analysis_period='2023-01-01 to 2023-12-31',\n    include_sections=[\n        'executive_summary',\n        'trend_analysis',\n        'correlation_analysis',\n        'pattern_detection',\n        'root_cause_analysis',\n        'recommendations'\n    ]\n)\n\n# Save report\nreporter.save_report(report, 'reports/historical_analysis_2023.html')\n</code></pre>"},{"location":"user-guide/historical-analysis/#custom-analysis-templates","title":"Custom Analysis Templates","text":"<pre><code># Create custom analysis template\ntemplate = {\n    'title': 'Monthly Quality Review',\n    'sections': [\n        {\n            'name': 'Defect Rate Summary',\n            'type': 'metric_summary',\n            'metrics': ['defect_rate', 'severity_distribution']\n        },\n        {\n            'name': 'Process Parameter Analysis',\n            'type': 'correlation_matrix',\n            'parameters': ['mold_temperature', 'casting_speed']\n        },\n        {\n            'name': 'Trend Charts',\n            'type': 'time_series_plots',\n            'variables': ['defect_rate', 'production_volume']\n        }\n    ]\n}\n\n# Generate report from template\ncustom_report = reporter.generate_from_template(template, historical_data)\n</code></pre> <p>This historical analysis framework provides deep insights into your steel casting operations, enabling data-driven improvements and proactive quality management.</p>"},{"location":"user-guide/model-comparison/","title":"Model Comparison","text":"<p>The Steel Defect Prediction System supports multiple machine learning models, allowing you to compare their performance and choose the best model for your specific casting conditions.</p>"},{"location":"user-guide/model-comparison/#available-models","title":"Available Models","text":""},{"location":"user-guide/model-comparison/#1-lstm-neural-network","title":"1. LSTM Neural Network","text":"<p>Best for: Time-series prediction with temporal dependencies</p> <pre><code>from src.models.lstm_model import LSTMModel\n\n# Load LSTM model\nlstm_model = LSTMModel(\n    input_size=10,\n    hidden_size=64,\n    num_layers=2,\n    output_size=1\n)\n</code></pre> <p>Advantages: - Captures temporal patterns in sensor data - Good for sequential defect prediction - Handles variable-length sequences</p> <p>Performance: - Accuracy: 89.5% - Precision: 87.2% - Recall: 91.8% - F1-Score: 89.4%</p>"},{"location":"user-guide/model-comparison/#2-random-forest","title":"2. Random Forest","text":"<p>Best for: Feature importance analysis and interpretability</p> <pre><code>from src.models.random_forest_model import RandomForestModel\n\n# Load Random Forest model\nrf_model = RandomForestModel(\n    n_estimators=100,\n    max_depth=10,\n    random_state=42\n)\n</code></pre> <p>Advantages: - Fast training and inference - Feature importance ranking - Robust to outliers - No overfitting tendency</p> <p>Performance: - Accuracy: 85.3% - Precision: 84.1% - Recall: 86.7% - F1-Score: 85.4%</p>"},{"location":"user-guide/model-comparison/#3-gradient-boosting","title":"3. Gradient Boosting","text":"<p>Best for: High accuracy with tabular data</p> <pre><code>from src.models.gradient_boosting_model import GradientBoostingModel\n\n# Load Gradient Boosting model\ngb_model = GradientBoostingModel(\n    n_estimators=200,\n    learning_rate=0.1,\n    max_depth=6\n)\n</code></pre> <p>Advantages: - High prediction accuracy - Good generalization - Handles missing values - Feature interaction capture</p> <p>Performance: - Accuracy: 91.2% - Precision: 90.8% - Recall: 91.6% - F1-Score: 91.2%</p>"},{"location":"user-guide/model-comparison/#model-comparison-dashboard","title":"Model Comparison Dashboard","text":""},{"location":"user-guide/model-comparison/#access-comparison-view","title":"Access Comparison View","text":"<p>Navigate to the model comparison dashboard:</p> <pre><code>http://localhost:8000/models/comparison\n</code></pre>"},{"location":"user-guide/model-comparison/#performance-metrics","title":"Performance Metrics","text":"<p>The dashboard displays comprehensive metrics for each model:</p>"},{"location":"user-guide/model-comparison/#classification-metrics","title":"Classification Metrics","text":"<ul> <li>Accuracy: Overall correct predictions</li> <li>Precision: True positives / (True positives + False positives)</li> <li>Recall: True positives / (True positives + False negatives)</li> <li>F1-Score: Harmonic mean of precision and recall</li> <li>AUC-ROC: Area under ROC curve</li> </ul>"},{"location":"user-guide/model-comparison/#operational-metrics","title":"Operational Metrics","text":"<ul> <li>Inference Time: Average prediction time</li> <li>Memory Usage: Model memory footprint</li> <li>Training Time: Time to train the model</li> <li>Model Size: File size of saved model</li> </ul>"},{"location":"user-guide/model-comparison/#model-selection-criteria","title":"Model Selection Criteria","text":""},{"location":"user-guide/model-comparison/#for-real-time-applications","title":"For Real-time Applications","text":"<pre><code># Prioritize inference speed\nmodel_ranking = {\n    'random_forest': {'speed': 9, 'accuracy': 7, 'memory': 8},\n    'gradient_boosting': {'speed': 7, 'accuracy': 9, 'memory': 6},\n    'lstm': {'speed': 5, 'accuracy': 8, 'memory': 4}\n}\n</code></pre>"},{"location":"user-guide/model-comparison/#for-high-accuracy-requirements","title":"For High Accuracy Requirements","text":"<pre><code># Prioritize prediction accuracy\nmodel_ranking = {\n    'gradient_boosting': {'accuracy': 9, 'stability': 8, 'interpretability': 7},\n    'lstm': {'accuracy': 8, 'stability': 7, 'interpretability': 5},\n    'random_forest': {'accuracy': 7, 'stability': 9, 'interpretability': 9}\n}\n</code></pre>"},{"location":"user-guide/model-comparison/#running-model-comparisons","title":"Running Model Comparisons","text":""},{"location":"user-guide/model-comparison/#automated-comparison","title":"Automated Comparison","text":"<pre><code>from src.evaluation.model_comparator import ModelComparator\n\n# Initialize comparator\ncomparator = ModelComparator(\n    models=['lstm', 'random_forest', 'gradient_boosting'],\n    test_data_path='data/test_dataset.csv'\n)\n\n# Run comparison\nresults = comparator.compare_models()\n\n# Display results\ncomparator.generate_report(output_path='reports/model_comparison.html')\n</code></pre>"},{"location":"user-guide/model-comparison/#custom-evaluation","title":"Custom Evaluation","text":"<pre><code>from src.evaluation.custom_evaluator import CustomEvaluator\n\n# Define custom metrics\ncustom_metrics = {\n    'defect_detection_rate': lambda y_true, y_pred: custom_defect_rate(y_true, y_pred),\n    'false_alarm_rate': lambda y_true, y_pred: custom_false_alarm_rate(y_true, y_pred),\n    'cost_savings': lambda y_true, y_pred: calculate_cost_savings(y_true, y_pred)\n}\n\nevaluator = CustomEvaluator(custom_metrics)\nresults = evaluator.evaluate_all_models(test_data)\n</code></pre>"},{"location":"user-guide/model-comparison/#model-ensemble","title":"Model Ensemble","text":""},{"location":"user-guide/model-comparison/#ensemble-configuration","title":"Ensemble Configuration","text":"<p>Combine multiple models for improved performance:</p> <pre><code>from src.models.ensemble_model import EnsembleModel\n\n# Create ensemble\nensemble = EnsembleModel(\n    models=[lstm_model, rf_model, gb_model],\n    weights=[0.4, 0.3, 0.3],  # Model weights\n    method='weighted_average'  # or 'voting', 'stacking'\n)\n\n# Make predictions\nprediction = ensemble.predict(sensor_data)\n</code></pre>"},{"location":"user-guide/model-comparison/#voting-ensemble","title":"Voting Ensemble","text":"<pre><code># Majority voting ensemble\nvoting_ensemble = EnsembleModel(\n    models=[lstm_model, rf_model, gb_model],\n    method='majority_voting',\n    threshold=0.5\n)\n</code></pre>"},{"location":"user-guide/model-comparison/#stacking-ensemble","title":"Stacking Ensemble","text":"<pre><code># Stacking with meta-learner\nstacking_ensemble = EnsembleModel(\n    base_models=[lstm_model, rf_model, gb_model],\n    meta_model=LogisticRegression(),\n    method='stacking'\n)\n</code></pre>"},{"location":"user-guide/model-comparison/#performance-analysis","title":"Performance Analysis","text":""},{"location":"user-guide/model-comparison/#cross-validation-results","title":"Cross-Validation Results","text":"<pre><code>from sklearn.model_selection import cross_val_score\n\n# 5-fold cross-validation\nmodels = {\n    'LSTM': lstm_model,\n    'Random Forest': rf_model,\n    'Gradient Boosting': gb_model\n}\n\ncv_results = {}\nfor name, model in models.items():\n    scores = cross_val_score(model, X, y, cv=5, scoring='f1')\n    cv_results[name] = {\n        'mean': scores.mean(),\n        'std': scores.std(),\n        'scores': scores.tolist()\n    }\n</code></pre>"},{"location":"user-guide/model-comparison/#learning-curves","title":"Learning Curves","text":"<pre><code>import matplotlib.pyplot as plt\nfrom sklearn.model_selection import learning_curve\n\n# Generate learning curves\ntrain_sizes, train_scores, val_scores = learning_curve(\n    model, X, y, cv=5, train_sizes=np.linspace(0.1, 1.0, 10)\n)\n\n# Plot learning curves\nplt.figure(figsize=(10, 6))\nplt.plot(train_sizes, train_scores.mean(axis=1), label='Training Score')\nplt.plot(train_sizes, val_scores.mean(axis=1), label='Validation Score')\nplt.xlabel('Training Set Size')\nplt.ylabel('F1 Score')\nplt.legend()\nplt.show()\n</code></pre>"},{"location":"user-guide/model-comparison/#feature-importance-comparison","title":"Feature Importance Comparison","text":"<pre><code># Compare feature importance across models\nfeature_importance = {}\n\n# Random Forest importance\nfeature_importance['random_forest'] = rf_model.feature_importances_\n\n# Gradient Boosting importance\nfeature_importance['gradient_boosting'] = gb_model.feature_importances_\n\n# LSTM attention weights (if available)\nfeature_importance['lstm'] = lstm_model.get_attention_weights()\n\n# Visualize feature importance\nimport pandas as pd\nimport seaborn as sns\n\nimportance_df = pd.DataFrame(feature_importance, index=feature_names)\nplt.figure(figsize=(12, 8))\nsns.heatmap(importance_df, annot=True, cmap='viridis')\nplt.title('Feature Importance Comparison')\nplt.show()\n</code></pre>"},{"location":"user-guide/model-comparison/#model-selection-wizard","title":"Model Selection Wizard","text":""},{"location":"user-guide/model-comparison/#interactive-selection-tool","title":"Interactive Selection Tool","text":"<pre><code>from src.tools.model_selector import ModelSelector\n\n# Launch interactive selector\nselector = ModelSelector()\nselector.launch_wizard()\n\n# Answer questions about your requirements\n# - Prediction speed requirements\n# - Accuracy requirements\n# - Interpretability needs\n# - Resource constraints\n\n# Get recommendation\nrecommended_model = selector.get_recommendation()\nprint(f\"Recommended model: {recommended_model}\")\n</code></pre>"},{"location":"user-guide/model-comparison/#automated-selection","title":"Automated Selection","text":"<pre><code># Automated model selection based on data characteristics\nfrom src.tools.auto_selector import AutoModelSelector\n\nauto_selector = AutoModelSelector()\nbest_model = auto_selector.select_best_model(\n    X_train, y_train, X_val, y_val,\n    constraints={\n        'max_inference_time': 100,  # milliseconds\n        'max_memory_usage': 512,    # MB\n        'min_accuracy': 0.85\n    }\n)\n</code></pre>"},{"location":"user-guide/model-comparison/#production-deployment","title":"Production Deployment","text":""},{"location":"user-guide/model-comparison/#ab-testing","title":"A/B Testing","text":"<pre><code>from src.deployment.ab_testing import ABTestManager\n\n# Set up A/B test\nab_test = ABTestManager()\nab_test.setup_test(\n    model_a='gradient_boosting_v1',\n    model_b='lstm_v2',\n    traffic_split=0.5  # 50/50 split\n)\n\n# Monitor test results\nresults = ab_test.get_results()\nprint(f\"Model A accuracy: {results['model_a']['accuracy']}\")\nprint(f\"Model B accuracy: {results['model_b']['accuracy']}\")\n</code></pre>"},{"location":"user-guide/model-comparison/#gradual-rollout","title":"Gradual Rollout","text":"<pre><code># Gradually increase traffic to new model\nrollout_schedule = [\n    {'model': 'new_model', 'percentage': 10, 'duration': '1 day'},\n    {'model': 'new_model', 'percentage': 25, 'duration': '2 days'},\n    {'model': 'new_model', 'percentage': 50, 'duration': '3 days'},\n    {'model': 'new_model', 'percentage': 100, 'duration': 'ongoing'}\n]\n\nab_test.gradual_rollout(rollout_schedule)\n</code></pre>"},{"location":"user-guide/model-comparison/#model-monitoring","title":"Model Monitoring","text":""},{"location":"user-guide/model-comparison/#performance-drift-detection","title":"Performance Drift Detection","text":"<pre><code>from src.monitoring.model_monitor import ModelMonitor\n\n# Monitor model performance over time\nmonitor = ModelMonitor(model_name='production_model')\n\n# Track prediction quality\nmonitor.log_prediction(y_true, y_pred, timestamp)\n\n# Check for performance drift\ndrift_detected = monitor.detect_drift(\n    window_size=1000,\n    threshold=0.05  # 5% accuracy drop\n)\n\nif drift_detected:\n    print(\"Model performance drift detected - consider retraining\")\n</code></pre>"},{"location":"user-guide/model-comparison/#data-drift-detection","title":"Data Drift Detection","text":"<pre><code>from src.monitoring.data_drift import DataDriftDetector\n\n# Monitor input data distribution\ndrift_detector = DataDriftDetector(reference_data=X_train)\n\n# Check for data drift\ndrift_score = drift_detector.detect_drift(new_data=X_recent)\n\nif drift_score &gt; 0.1:\n    print(f\"Data drift detected (score: {drift_score:.3f})\")\n    print(\"Consider updating model with recent data\")\n</code></pre> <p>This comprehensive model comparison framework helps you select and maintain the optimal model for your steel defect prediction needs.</p>"},{"location":"user-guide/real-time-monitoring/","title":"Real-time Monitoring","text":"<p>The Steel Defect Prediction System provides comprehensive real-time monitoring capabilities for continuous steel casting operations.</p>"},{"location":"user-guide/real-time-monitoring/#overview","title":"Overview","text":"<p>Real-time monitoring allows operators to:</p> <ul> <li>Track live sensor data streams</li> <li>Monitor prediction confidence levels</li> <li>Detect anomalies in real-time</li> <li>Receive immediate alerts for potential defects</li> <li>Visualize process parameters and trends</li> </ul>"},{"location":"user-guide/real-time-monitoring/#dashboard-features","title":"Dashboard Features","text":""},{"location":"user-guide/real-time-monitoring/#live-data-stream","title":"Live Data Stream","text":"<p>The monitoring dashboard displays real-time data from multiple sensors:</p> <pre><code># Example sensor data structure\nsensor_data = {\n    \"timestamp\": \"2024-01-15T10:30:00Z\",\n    \"mold_temperature\": 1525.4,\n    \"casting_speed\": 1.12,\n    \"cooling_water_flow\": 195.8,\n    \"oxygen_content\": 0.025,\n    \"steel_grade\": \"304L\"\n}\n</code></pre>"},{"location":"user-guide/real-time-monitoring/#real-time-metrics","title":"Real-time Metrics","text":"<p>Key metrics displayed in real-time:</p> <ul> <li>Defect Probability: Current prediction confidence (0-100%)</li> <li>Process Stability: Variance in key parameters</li> <li>Quality Index: Overall process quality score</li> <li>Alert Status: Current system alerts and warnings</li> </ul>"},{"location":"user-guide/real-time-monitoring/#visual-indicators","title":"Visual Indicators","text":""},{"location":"user-guide/real-time-monitoring/#status-indicators","title":"Status Indicators","text":"<ul> <li>\ud83d\udfe2 Green: Normal operation (defect probability &lt; 30%)</li> <li>\ud83d\udfe1 Yellow: Caution zone (defect probability 30-70%)</li> <li>\ud83d\udd34 Red: High risk (defect probability &gt; 70%)</li> </ul>"},{"location":"user-guide/real-time-monitoring/#trend-charts","title":"Trend Charts","text":"<p>Real-time charts show:</p> <ul> <li>Temperature trends over time</li> <li>Casting speed variations</li> <li>Cooling system performance</li> <li>Prediction confidence levels</li> </ul>"},{"location":"user-guide/real-time-monitoring/#setting-up-real-time-monitoring","title":"Setting Up Real-time Monitoring","text":""},{"location":"user-guide/real-time-monitoring/#1-configure-data-sources","title":"1. Configure Data Sources","text":"<pre><code># config/monitoring.yml\ndata_sources:\n  primary_sensors:\n    - mold_temperature\n    - casting_speed\n    - cooling_water_flow\n  secondary_sensors:\n    - oxygen_content\n    - steel_grade\n    - tundish_temperature\n\nupdate_frequency: 1  # seconds\nbuffer_size: 1000   # data points\n</code></pre>"},{"location":"user-guide/real-time-monitoring/#2-start-monitoring-service","title":"2. Start Monitoring Service","text":"<pre><code># Start the monitoring service\npython -m src.monitoring.real_time_monitor\n\n# Or with Docker\ndocker run -d --name steel-monitor \\\n  -p 8001:8001 \\\n  steel-defect-prediction:latest \\\n  python -m src.monitoring.real_time_monitor\n</code></pre>"},{"location":"user-guide/real-time-monitoring/#3-access-monitoring-dashboard","title":"3. Access Monitoring Dashboard","text":"<p>Navigate to <code>http://localhost:8001/monitoring</code> to access the real-time dashboard.</p>"},{"location":"user-guide/real-time-monitoring/#monitoring-components","title":"Monitoring Components","text":""},{"location":"user-guide/real-time-monitoring/#data-acquisition","title":"Data Acquisition","text":"<pre><code>from src.monitoring.data_collector import RealTimeCollector\n\n# Initialize collector\ncollector = RealTimeCollector(\n    sensors=['mold_temp', 'casting_speed', 'cooling_flow'],\n    update_interval=1.0  # seconds\n)\n\n# Start data collection\ncollector.start()\n\n# Get latest data\nlatest_data = collector.get_latest()\n</code></pre>"},{"location":"user-guide/real-time-monitoring/#prediction-engine","title":"Prediction Engine","text":"<pre><code>from src.inference.real_time_predictor import RealTimePredictor\n\n# Initialize predictor\npredictor = RealTimePredictor(\n    model_path='models/production_model.pth',\n    threshold=0.7\n)\n\n# Process incoming data\nprediction = predictor.predict(sensor_data)\nprint(f\"Defect probability: {prediction['probability']:.3f}\")\nprint(f\"Confidence: {prediction['confidence']:.3f}\")\n</code></pre>"},{"location":"user-guide/real-time-monitoring/#alert-system","title":"Alert System","text":"<pre><code>from src.monitoring.alert_manager import AlertManager\n\n# Configure alerts\nalert_manager = AlertManager(\n    rules=[\n        {\n            'name': 'high_defect_risk',\n            'condition': 'defect_probability &gt; 0.8',\n            'severity': 'critical',\n            'notification': ['email', 'sms']\n        },\n        {\n            'name': 'temperature_anomaly',\n            'condition': 'abs(mold_temperature - target_temp) &gt; 50',\n            'severity': 'warning',\n            'notification': ['dashboard']\n        }\n    ]\n)\n\n# Process alerts\nalert_manager.evaluate(sensor_data, prediction)\n</code></pre>"},{"location":"user-guide/real-time-monitoring/#configuration-options","title":"Configuration Options","text":""},{"location":"user-guide/real-time-monitoring/#update-frequency","title":"Update Frequency","text":"<p>Control how often data is refreshed:</p> <pre><code># High frequency for critical operations\nMONITOR_UPDATE_INTERVAL = 0.5  # 500ms\n\n# Standard frequency for normal operations\nMONITOR_UPDATE_INTERVAL = 1.0  # 1 second\n\n# Low frequency for overview monitoring\nMONITOR_UPDATE_INTERVAL = 5.0  # 5 seconds\n</code></pre>"},{"location":"user-guide/real-time-monitoring/#data-retention","title":"Data Retention","text":"<p>Configure how long data is kept in memory:</p> <pre><code># Monitoring configuration\nREALTIME_BUFFER_SIZE = 3600    # 1 hour of data at 1Hz\nHISTORY_RETENTION_DAYS = 7     # Keep 7 days of detailed history\nARCHIVE_RETENTION_MONTHS = 12  # Keep 12 months of summary data\n</code></pre>"},{"location":"user-guide/real-time-monitoring/#display-preferences","title":"Display Preferences","text":"<p>Customize dashboard appearance:</p> <pre><code>// Dashboard configuration\nconst dashboardConfig = {\n    refreshRate: 1000,           // Refresh every second\n    chartTimeWindow: 300,        // Show last 5 minutes\n    alertTimeout: 30000,         // Alert timeout: 30 seconds\n    theme: 'dark',              // 'light' or 'dark'\n    showPredictionBands: true,   // Show confidence intervals\n    enableSounds: true          // Audio alerts\n};\n</code></pre>"},{"location":"user-guide/real-time-monitoring/#alert-configuration","title":"Alert Configuration","text":""},{"location":"user-guide/real-time-monitoring/#alert-levels","title":"Alert Levels","text":"<p>Configure different alert severity levels:</p> <pre><code>alert_levels:\n  info:\n    color: blue\n    sound: false\n    auto_dismiss: true\n    timeout: 10\n\n  warning:\n    color: orange\n    sound: true\n    auto_dismiss: false\n    timeout: 30\n\n  critical:\n    color: red\n    sound: true\n    auto_dismiss: false\n    requires_acknowledgment: true\n</code></pre>"},{"location":"user-guide/real-time-monitoring/#notification-channels","title":"Notification Channels","text":"<p>Set up multiple notification channels:</p> <pre><code>notifications:\n  email:\n    enabled: true\n    smtp_server: smtp.company.com\n    recipients:\n      - operator@company.com\n      - supervisor@company.com\n\n  sms:\n    enabled: true\n    provider: twilio\n    numbers:\n      - \"+1234567890\"\n\n  webhook:\n    enabled: true\n    url: https://api.company.com/alerts\n    headers:\n      Authorization: \"Bearer ${API_TOKEN}\"\n</code></pre>"},{"location":"user-guide/real-time-monitoring/#performance-optimization","title":"Performance Optimization","text":""},{"location":"user-guide/real-time-monitoring/#efficient-data-handling","title":"Efficient Data Handling","text":"<pre><code># Use efficient data structures\nimport collections\nimport numpy as np\n\nclass CircularBuffer:\n    def __init__(self, size):\n        self.buffer = collections.deque(maxlen=size)\n\n    def add(self, item):\n        self.buffer.append(item)\n\n    def get_array(self):\n        return np.array(self.buffer)\n\n# Batch processing for efficiency\ndef process_sensor_batch(sensor_batch):\n    \"\"\"Process multiple sensor readings at once\"\"\"\n    predictions = model.predict_batch(sensor_batch)\n    return predictions\n</code></pre>"},{"location":"user-guide/real-time-monitoring/#memory-management","title":"Memory Management","text":"<pre><code># Limit memory usage\nMAX_MEMORY_MB = 512\n\n# Monitor memory usage\nimport psutil\nimport gc\n\ndef check_memory():\n    process = psutil.Process()\n    memory_mb = process.memory_info().rss / 1024 / 1024\n\n    if memory_mb &gt; MAX_MEMORY_MB:\n        gc.collect()  # Force garbage collection\n\n    return memory_mb\n</code></pre>"},{"location":"user-guide/real-time-monitoring/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/real-time-monitoring/#common-issues","title":"Common Issues","text":"<ol> <li>Data lag: Check network connection and sensor communication</li> <li>High CPU usage: Reduce update frequency or optimize prediction pipeline</li> <li>Memory leaks: Monitor buffer sizes and implement proper cleanup</li> <li>Missing alerts: Verify alert configuration and notification settings</li> </ol>"},{"location":"user-guide/real-time-monitoring/#debugging-tools","title":"Debugging Tools","text":"<pre><code># Enable debug logging\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\n\n# Monitor performance\nfrom src.monitoring.performance_monitor import PerformanceMonitor\n\nperf_monitor = PerformanceMonitor()\nperf_monitor.start()\n\n# Check metrics\nmetrics = perf_monitor.get_metrics()\nprint(f\"Average processing time: {metrics['avg_processing_time']:.3f}s\")\nprint(f\"Predictions per second: {metrics['predictions_per_second']:.1f}\")\n</code></pre>"},{"location":"user-guide/real-time-monitoring/#system-status","title":"System Status","text":"<p>Check real-time monitoring system status:</p> <pre><code># Check service status\nsystemctl status steel-defect-monitor\n\n# View service logs\njournalctl -u steel-defect-monitor -f\n\n# Check resource usage\nhtop\n</code></pre>"},{"location":"user-guide/real-time-monitoring/#integration-examples","title":"Integration Examples","text":""},{"location":"user-guide/real-time-monitoring/#scada-integration","title":"SCADA Integration","text":"<pre><code># Connect to SCADA system\nfrom src.integrations.scada_connector import SCADAConnector\n\nscada = SCADAConnector(\n    host=\"scada.plant.com\",\n    port=502,\n    unit_id=1\n)\n\n# Read sensor values\nsensor_values = scada.read_sensors([\n    'mold_temp_tag',\n    'casting_speed_tag',\n    'cooling_flow_tag'\n])\n</code></pre>"},{"location":"user-guide/real-time-monitoring/#plc-integration","title":"PLC Integration","text":"<pre><code># Connect to PLC\nfrom src.integrations.plc_connector import PLCConnector\n\nplc = PLCConnector(\n    ip_address=\"192.168.1.100\",\n    rack=0,\n    slot=1\n)\n\n# Read process data\nprocess_data = plc.read_data_block(\n    db_number=1,\n    start_address=0,\n    size=100\n)\n</code></pre> <p>This real-time monitoring system provides comprehensive visibility into your steel casting operations, enabling proactive quality management and immediate response to potential defects.</p>"},{"location":"user-guide/user-preferences/","title":"User Preferences","text":"<p>The User Preferences system allows operators and administrators to customize their experience with the Steel Defect Prediction System according to their roles, responsibilities, and workflow needs.</p>"},{"location":"user-guide/user-preferences/#overview","title":"Overview","text":"<p>User preferences cover:</p> <ul> <li>Dashboard layout and widget configuration</li> <li>Alert notification settings</li> <li>Data visualization preferences</li> <li>Report generation templates</li> <li>Language and localization settings</li> <li>Theme and accessibility options</li> </ul>"},{"location":"user-guide/user-preferences/#dashboard-customization","title":"Dashboard Customization","text":""},{"location":"user-guide/user-preferences/#widget-configuration","title":"Widget Configuration","text":"<pre><code># Configure dashboard widgets\ndashboard_config = {\n    'user_id': 'operator_001',\n    'layout': 'grid',\n    'widgets': [\n        {\n            'type': 'defect_probability_gauge',\n            'position': {'row': 1, 'col': 1, 'span': 2},\n            'settings': {\n                'thresholds': {'warning': 0.6, 'critical': 0.8},\n                'update_interval': 1  # seconds\n            }\n        },\n        {\n            'type': 'process_parameters_chart',\n            'position': {'row': 1, 'col': 3, 'span': 4}, \n            'settings': {\n                'parameters': ['mold_temperature', 'casting_speed'],\n                'time_window': 300,  # 5 minutes\n                'chart_type': 'line'\n            }\n        },\n        {\n            'type': 'alert_panel',\n            'position': {'row': 2, 'col': 1, 'span': 3},\n            'settings': {\n                'show_levels': ['critical', 'warning'],\n                'max_alerts': 10\n            }\n        }\n    ]\n}\n</code></pre>"},{"location":"user-guide/user-preferences/#layout-templates","title":"Layout Templates","text":"<pre><code># Predefined layout templates\nlayout_templates = {\n    'operator_view': {\n        'description': 'Focused on real-time monitoring',\n        'widgets': ['defect_gauge', 'process_chart', 'alert_panel']\n    },\n    'supervisor_view': {\n        'description': 'Overview with analytics',\n        'widgets': ['summary_stats', 'trend_analysis', 'performance_metrics']\n    },\n    'maintenance_view': {\n        'description': 'Equipment status focus',\n        'widgets': ['equipment_status', 'maintenance_alerts', 'diagnostic_charts']\n    }\n}\n\n# Apply template\nfrom src.preferences.dashboard_manager import DashboardManager\n\ndashboard_mgr = DashboardManager()\ndashboard_mgr.apply_template('operator_view', user_id='operator_001')\n</code></pre>"},{"location":"user-guide/user-preferences/#notification-preferences","title":"Notification Preferences","text":""},{"location":"user-guide/user-preferences/#alert-notification-settings","title":"Alert Notification Settings","text":"<pre><code># Configure personal alert preferences\nalert_preferences = {\n    'user_id': 'supervisor_002',\n    'channels': {\n        'critical': ['email', 'sms', 'dashboard'],\n        'warning': ['email', 'dashboard'],\n        'info': ['dashboard']\n    },\n    'quiet_hours': {\n        'enabled': True,\n        'start_time': '22:00',\n        'end_time': '06:00',\n        'emergency_override': True  # Critical alerts still come through\n    },\n    'escalation_preferences': {\n        'response_timeout': 600,  # 10 minutes\n        'escalate_to': 'manager@company.com'\n    }\n}\n</code></pre>"},{"location":"user-guide/user-preferences/#custom-alert-rules","title":"Custom Alert Rules","text":"<pre><code># User-specific alert conditions\ncustom_alerts = {\n    'user_id': 'quality_engineer_003',\n    'custom_rules': [\n        {\n            'name': 'quality_concern',\n            'condition': 'defect_probability &gt; 0.5 AND steel_grade == \"premium\"',\n            'notification': 'immediate',\n            'description': 'Quality concern for premium steel grades'\n        },\n        {\n            'name': 'shift_handover_summary', \n            'condition': 'time == \"end_of_shift\"',\n            'notification': 'email',\n            'description': 'Daily summary report'\n        }\n    ]\n}\n</code></pre>"},{"location":"user-guide/user-preferences/#data-visualization-preferences","title":"Data Visualization Preferences","text":""},{"location":"user-guide/user-preferences/#chart-preferences","title":"Chart Preferences","text":"<pre><code># Visualization preferences\nviz_preferences = {\n    'user_id': 'analyst_004',\n    'chart_settings': {\n        'default_time_range': '24h',\n        'color_scheme': 'steel_industry',  # Custom color palette\n        'show_confidence_intervals': True,\n        'animation_enabled': False,  # For better performance\n        'grid_lines': True\n    },\n    'data_preferences': {\n        'decimal_places': 2,\n        'units': 'metric',  # or 'imperial'\n        'aggregation_method': 'mean',  # or 'median', 'max'\n        'missing_data_handling': 'interpolate'  # or 'skip', 'zero'\n    }\n}\n</code></pre>"},{"location":"user-guide/user-preferences/#custom-metrics","title":"Custom Metrics","text":"<pre><code># Define user-specific metrics\ncustom_metrics = {\n    'user_id': 'process_engineer_005',\n    'metrics': [\n        {\n            'name': 'efficiency_index',\n            'formula': '(production_rate * quality_score) / energy_consumption',\n            'display_name': 'Process Efficiency Index',\n            'unit': 'kg/kWh',\n            'target_value': 15.0\n        },\n        {\n            'name': 'cost_per_ton',\n            'formula': '(energy_cost + material_cost + labor_cost) / production_volume',\n            'display_name': 'Cost per Ton',\n            'unit': '$/ton',\n            'target_value': 850.0\n        }\n    ]\n}\n</code></pre>"},{"location":"user-guide/user-preferences/#report-templates","title":"Report Templates","text":""},{"location":"user-guide/user-preferences/#custom-report-configuration","title":"Custom Report Configuration","text":"<pre><code># Personal report templates\nreport_templates = {\n    'user_id': 'manager_006',\n    'templates': [\n        {\n            'name': 'daily_summary',\n            'schedule': 'daily_8am',\n            'sections': [\n                'production_summary',\n                'quality_metrics', \n                'alert_summary',\n                'efficiency_trends'\n            ],\n            'format': 'pdf',\n            'email_to': ['manager_006@company.com']\n        },\n        {\n            'name': 'weekly_analysis',\n            'schedule': 'monday_9am', \n            'sections': [\n                'weekly_trends',\n                'comparative_analysis',\n                'improvement_recommendations'\n            ],\n            'format': 'html',\n            'include_charts': True\n        }\n    ]\n}\n</code></pre>"},{"location":"user-guide/user-preferences/#report-filters","title":"Report Filters","text":"<pre><code># Custom data filters for reports\nreport_filters = {\n    'user_id': 'quality_manager_007',\n    'default_filters': {\n        'steel_grades': ['304L', '316L'],  # Only premium grades\n        'shifts': ['day', 'afternoon'],    # Exclude night shift\n        'production_lines': [1, 2],        # Lines 1 and 2 only\n        'exclude_maintenance_periods': True\n    },\n    'advanced_filters': {\n        'statistical_outliers': 'remove',\n        'data_quality_threshold': 0.95,   # 95% data completeness required\n        'seasonal_adjustment': True\n    }\n}\n</code></pre>"},{"location":"user-guide/user-preferences/#accessibility-and-localization","title":"Accessibility and Localization","text":""},{"location":"user-guide/user-preferences/#accessibility-settings","title":"Accessibility Settings","text":"<pre><code># Accessibility preferences\naccessibility_settings = {\n    'user_id': 'operator_008',\n    'visual': {\n        'high_contrast': True,\n        'font_size_multiplier': 1.2,\n        'color_blind_friendly': True,\n        'color_palette': 'deuteranopia_safe'\n    },\n    'audio': {\n        'alert_sounds': True,\n        'sound_volume': 0.8,\n        'speech_alerts': False\n    },\n    'interaction': {\n        'keyboard_navigation': True,\n        'mouse_sensitivity': 'low',\n        'double_click_delay': 500  # milliseconds\n    }\n}\n</code></pre>"},{"location":"user-guide/user-preferences/#language-and-localization","title":"Language and Localization","text":"<pre><code># Language preferences\nlocalization_settings = {\n    'user_id': 'operator_009',\n    'language': 'es',  # Spanish\n    'region': 'MX',    # Mexico\n    'timezone': 'America/Mexico_City',\n    'date_format': 'DD/MM/YYYY',\n    'time_format': '24h',\n    'number_format': {\n        'decimal_separator': ',',\n        'thousands_separator': '.',\n        'currency_symbol': '$'\n    }\n}\n</code></pre>"},{"location":"user-guide/user-preferences/#theme-and-ui-preferences","title":"Theme and UI Preferences","text":""},{"location":"user-guide/user-preferences/#theme-configuration","title":"Theme Configuration","text":"<pre><code># UI theme preferences\ntheme_preferences = {\n    'user_id': 'night_operator_010',\n    'theme': {\n        'mode': 'dark',  # 'light', 'dark', 'auto'\n        'primary_color': '#1976d2',\n        'accent_color': '#ff5722',\n        'background_type': 'solid',  # 'solid', 'gradient'\n        'sidebar_collapsed': False,\n        'compact_mode': True\n    },\n    'animations': {\n        'enabled': True,\n        'speed': 'normal',  # 'slow', 'normal', 'fast'\n        'transitions': True\n    }\n}\n</code></pre>"},{"location":"user-guide/user-preferences/#custom-css","title":"Custom CSS","text":"<pre><code>/* User-specific CSS overrides */\n.user-custom-010 {\n    --primary-color: #2196f3;\n    --warning-color: #ff9800; \n    --danger-color: #f44336;\n    --chart-background: #263238;\n    --text-primary: #ffffff;\n    --text-secondary: #b0bec5;\n}\n\n.user-custom-010 .dashboard-widget {\n    border-radius: 8px;\n    box-shadow: 0 2px 8px rgba(0,0,0,0.3);\n}\n\n.user-custom-010 .alert-critical {\n    animation: pulse 2s infinite;\n}\n</code></pre>"},{"location":"user-guide/user-preferences/#preferences-management","title":"Preferences Management","text":""},{"location":"user-guide/user-preferences/#save-and-load-preferences","title":"Save and Load Preferences","text":"<pre><code>from src.preferences.preference_manager import PreferenceManager\n\n# Initialize preference manager\npref_manager = PreferenceManager()\n\n# Save user preferences\npref_manager.save_preferences(\n    user_id='operator_001',\n    preferences={\n        'dashboard': dashboard_config,\n        'alerts': alert_preferences,\n        'visualization': viz_preferences,\n        'theme': theme_preferences\n    }\n)\n\n# Load user preferences\nuser_prefs = pref_manager.load_preferences('operator_001')\n\n# Apply preferences to session\npref_manager.apply_preferences(user_prefs)\n</code></pre>"},{"location":"user-guide/user-preferences/#preference-inheritance","title":"Preference Inheritance","text":"<pre><code># Role-based preference inheritance\nrole_hierarchy = {\n    'operator': {\n        'inherits_from': 'base_user',\n        'default_preferences': 'operator_defaults.json'\n    },\n    'supervisor': {\n        'inherits_from': 'operator',\n        'additional_permissions': ['modify_thresholds', 'view_analytics']\n    },\n    'manager': {\n        'inherits_from': 'supervisor', \n        'additional_permissions': ['system_admin', 'user_management']\n    }\n}\n\n# Apply role-based preferences\npref_manager.apply_role_preferences(user_id='new_operator', role='operator')\n</code></pre>"},{"location":"user-guide/user-preferences/#backup-and-sync","title":"Backup and Sync","text":""},{"location":"user-guide/user-preferences/#preference-backup","title":"Preference Backup","text":"<pre><code># Backup user preferences\nbackup_data = pref_manager.export_preferences(\n    user_id='operator_001',\n    include_personal_data=False  # Exclude sensitive information\n)\n\n# Save backup\nwith open('user_preferences_backup.json', 'w') as f:\n    json.dump(backup_data, f, indent=2)\n</code></pre>"},{"location":"user-guide/user-preferences/#cross-device-sync","title":"Cross-device Sync","text":"<pre><code># Sync preferences across devices\nsync_config = {\n    'user_id': 'mobile_operator_011',\n    'devices': ['desktop_workstation', 'tablet_001', 'mobile_phone'],\n    'sync_settings': {\n        'dashboard_layout': True,\n        'alert_preferences': True,\n        'theme_preferences': True,\n        'device_specific_settings': False  # Don't sync device-specific settings\n    }\n}\n\n# Perform sync\npref_manager.sync_across_devices(sync_config)\n</code></pre>"},{"location":"user-guide/user-preferences/#api-endpoints","title":"API Endpoints","text":""},{"location":"user-guide/user-preferences/#rest-api-for-preferences","title":"REST API for Preferences","text":"<pre><code># Get user preferences\nGET /api/v1/users/{user_id}/preferences\n\n# Update specific preference section\nPATCH /api/v1/users/{user_id}/preferences/dashboard\n\n# Reset to defaults\nPOST /api/v1/users/{user_id}/preferences/reset\n\n# Export preferences\nGET /api/v1/users/{user_id}/preferences/export\n\n# Import preferences\nPOST /api/v1/users/{user_id}/preferences/import\n</code></pre>"},{"location":"user-guide/user-preferences/#example-api-usage","title":"Example API Usage","text":"<pre><code>import requests\n\n# Update dashboard preferences\nresponse = requests.patch(\n    'http://localhost:8000/api/v1/users/operator_001/preferences/dashboard',\n    json={\n        'layout': 'compact',\n        'auto_refresh': True,\n        'refresh_interval': 5\n    },\n    headers={'Authorization': 'Bearer ${ACCESS_TOKEN}'}\n)\n\nif response.status_code == 200:\n    print(\"Preferences updated successfully\")\n</code></pre> <p>This comprehensive preference system ensures that each user can tailor the Steel Defect Prediction System to their specific needs and workflow requirements.</p>"}]}