{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steel Casting Sensor Correlation Analysis Demo\n",
    "\n",
    "This notebook demonstrates the correlation analysis capabilities for steel casting sensor data, including:\n",
    "\n",
    "1. **Cross-Sensor Correlation Heatmaps** - Visualize correlations between all sensor pairs\n",
    "2. **Defect-Specific Correlations** - Compare correlation patterns in good vs defective casts\n",
    "3. **Time-Lagged Correlations** - Analyze delayed relationships between sensors\n",
    "4. **Feature Importance Indicators** - Identify which sensor combinations are most predictive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from pathlib import Path\n",
    "\n",
    "# Import our modules\n",
    "from src.data.data_generator import SteelCastingDataGenerator\n",
    "from src.features.correlation_analyzer import SensorCorrelationAnalyzer\n",
    "from src.visualization.plotting_utils import PlottingUtils\n",
    "\n",
    "# Configure plotly for notebook display\n",
    "pio.renderers.default = \"notebook\"\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Sample Data\n",
    "\n",
    "First, let's generate some sample steel casting data with both good and defective casts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data generator\n",
    "generator = SteelCastingDataGenerator('../configs/data_generation.yaml')\n",
    "\n",
    "# Generate 10 sample casts for demonstration\n",
    "cast_data_list = []\n",
    "print(\"Generating sample casts...\")\n",
    "\n",
    "for i in range(10):\n",
    "    cast_id = f\"demo_cast_{i+1:03d}\"\n",
    "    time_series, metadata = generator.generate_cast_sequence(cast_id)\n",
    "    cast_data_list.append((time_series, metadata))\n",
    "    \n",
    "    status = \"DEFECTIVE\" if metadata['defect_label'] else \"GOOD\"\n",
    "    print(f\"Cast {cast_id}: {status} - Triggers: {metadata['defect_trigger_events']}\")\n",
    "\n",
    "print(f\"\\nGenerated {len(cast_data_list)} casts for analysis\")\n",
    "print(f\"Data shape per cast: {cast_data_list[0][0].shape}\")\n",
    "print(f\"Sensor columns: {cast_data_list[0][0].columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Analysis Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize correlation analyzer and plotting utilities\n",
    "analyzer = SensorCorrelationAnalyzer()\n",
    "plotter = PlottingUtils()\n",
    "\n",
    "print(f\"Analyzing sensors: {analyzer.sensor_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cross-Sensor Correlation Heatmaps\n",
    "\n",
    "Let's start by analyzing the overall correlations between sensors using data from a sample cast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the first cast as an example\n",
    "sample_cast_data = cast_data_list[0][0]\n",
    "sample_metadata = cast_data_list[0][1]\n",
    "\n",
    "print(f\"Analyzing cast: {sample_metadata['cast_id']}\")\n",
    "print(f\"Status: {'DEFECTIVE' if sample_metadata['defect_label'] else 'GOOD'}\")\n",
    "print(f\"Duration: {sample_metadata['duration_minutes']} minutes\")\n",
    "\n",
    "# Compute correlation matrix\n",
    "correlation_matrix = analyzer.compute_cross_sensor_correlations(sample_cast_data)\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(correlation_matrix.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation heatmap\n",
    "fig_heatmap = plotter.plot_correlation_heatmap(\n",
    "    sample_cast_data,\n",
    "    title=f\"Sensor Correlations - {sample_metadata['cast_id']}\"\n",
    ")\n",
    "fig_heatmap.show()\n",
    "\n",
    "# Identify strongest positive and negative correlations\n",
    "# Remove diagonal (self-correlations)\n",
    "corr_values = correlation_matrix.values\n",
    "np.fill_diagonal(corr_values, np.nan)\n",
    "\n",
    "# Find max and min correlations\n",
    "max_corr_idx = np.nanargmax(corr_values)\n",
    "min_corr_idx = np.nanargmin(corr_values)\n",
    "\n",
    "max_row, max_col = divmod(max_corr_idx, corr_values.shape[1])\n",
    "min_row, min_col = divmod(min_corr_idx, corr_values.shape[1])\n",
    "\n",
    "max_sensors = (correlation_matrix.index[max_row], correlation_matrix.columns[max_col])\n",
    "min_sensors = (correlation_matrix.index[min_row], correlation_matrix.columns[min_col])\n",
    "\n",
    "print(f\"\\nStrongest positive correlation: {max_sensors[0]} ↔ {max_sensors[1]} ({corr_values[max_row, max_col]:.3f})\")\n",
    "print(f\"Strongest negative correlation: {min_sensors[0]} ↔ {min_sensors[1]} ({corr_values[min_row, min_col]:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Defect-Specific Correlation Analysis\n",
    "\n",
    "Now let's compare correlation patterns between good and defective casts to identify differences that might indicate defect precursors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze defect-specific correlations\n",
    "defect_analysis = analyzer.compute_defect_specific_correlations(cast_data_list)\n",
    "\n",
    "print(\"Defect-specific correlation analysis:\")\n",
    "for key in defect_analysis.keys():\n",
    "    print(f\"- {key}: {defect_analysis[key].shape}\")\n",
    "\n",
    "# Count good vs defective casts\n",
    "good_count = sum(1 for _, metadata in cast_data_list if metadata['defect_label'] == 0)\n",
    "defect_count = sum(1 for _, metadata in cast_data_list if metadata['defect_label'] == 1)\n",
    "print(f\"\\nDataset composition: {good_count} good casts, {defect_count} defective casts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison visualization\n",
    "fig_comparison = plotter.plot_defect_correlation_comparison(\n",
    "    defect_analysis['good_casts'],\n",
    "    defect_analysis['defect_casts'],\n",
    "    defect_analysis['difference']\n",
    ")\n",
    "fig_comparison.show()\n",
    "\n",
    "# Identify largest differences\n",
    "diff_matrix = defect_analysis['difference']\n",
    "diff_values = diff_matrix.values\n",
    "np.fill_diagonal(diff_values, 0)  # Remove diagonal\n",
    "\n",
    "# Find largest positive and negative differences\n",
    "max_diff_idx = np.argmax(np.abs(diff_values))\n",
    "max_diff_row, max_diff_col = divmod(max_diff_idx, diff_values.shape[1])\n",
    "max_diff_value = diff_values[max_diff_row, max_diff_col]\n",
    "max_diff_sensors = (diff_matrix.index[max_diff_row], diff_matrix.columns[max_diff_col])\n",
    "\n",
    "print(f\"\\nLargest correlation difference between good and defective casts:\")\n",
    "print(f\"{max_diff_sensors[0]} ↔ {max_diff_sensors[1]}: {max_diff_value:.3f}\")\n",
    "print(f\"(Positive = stronger correlation in defective casts)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Time-Lagged Correlation Analysis\n",
    "\n",
    "Let's analyze delayed relationships between sensors to identify leading indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute time-lagged correlations for key sensor\n",
    "lagged_correlations = analyzer.compute_time_lagged_correlations(\n",
    "    sample_cast_data,\n",
    "    max_lag=60,  # 60 seconds max lag\n",
    "    target_sensor='mold_temperature'  # Use mold temperature as target\n",
    ")\n",
    "\n",
    "print(f\"Time-lagged correlation analysis for mold_temperature:\")\n",
    "for pair, lag_data in lagged_correlations.items():\n",
    "    # Find lag with maximum absolute correlation\n",
    "    max_corr_idx = lag_data['correlation'].abs().idxmax()\n",
    "    max_lag = lag_data.loc[max_corr_idx, 'lag']\n",
    "    max_corr = lag_data.loc[max_corr_idx, 'correlation']\n",
    "    \n",
    "    print(f\"  {pair}: Max correlation {max_corr:.3f} at lag {max_lag}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize time-lagged correlations\n",
    "fig_lagged = plotter.plot_time_lagged_correlations(\n",
    "    lagged_correlations\n",
    ")\n",
    "fig_lagged.show()\n",
    "\n",
    "# Analyze specific pair in detail\n",
    "pair_to_analyze = list(lagged_correlations.keys())[0]\n",
    "lag_data = lagged_correlations[pair_to_analyze]\n",
    "\n",
    "print(f\"\\nDetailed analysis for {pair_to_analyze}:\")\n",
    "print(f\"Correlation at lag 0: {lag_data[lag_data['lag'] == 0]['correlation'].iloc[0]:.3f}\")\n",
    "\n",
    "# Find optimal positive and negative lags\n",
    "positive_lags = lag_data[lag_data['lag'] > 0]\n",
    "negative_lags = lag_data[lag_data['lag'] < 0]\n",
    "\n",
    "if not positive_lags.empty:\n",
    "    best_positive = positive_lags.loc[positive_lags['correlation'].abs().idxmax()]\n",
    "    print(f\"Best positive lag: {best_positive['lag']}s (correlation: {best_positive['correlation']:.3f})\")\n",
    "\n",
    "if not negative_lags.empty:\n",
    "    best_negative = negative_lags.loc[negative_lags['correlation'].abs().idxmax()]\n",
    "    print(f\"Best negative lag: {best_negative['lag']}s (correlation: {best_negative['correlation']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance for Defect Prediction\n",
    "\n",
    "Let's identify which sensor combinations are most predictive of defects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify predictive sensor combinations\n",
    "importance_df = analyzer.identify_predictive_sensor_combinations(\n",
    "    cast_data_list,\n",
    "    top_k=15\n",
    ")\n",
    "\n",
    "print(\"Top predictive features for defect detection:\")\n",
    "print(importance_df.to_string(index=False))\n",
    "\n",
    "# Categorize features\n",
    "statistical_features = importance_df[importance_df['feature'].str.contains('_mean|_std|_min|_max')]\n",
    "correlation_features = importance_df[importance_df['feature'].str.contains('corr_')]\n",
    "\n",
    "print(f\"\\nFeature breakdown:\")\n",
    "print(f\"Statistical features: {len(statistical_features)}\")\n",
    "print(f\"Correlation features: {len(correlation_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "fig_importance = plotter.plot_feature_importance_ranking(\n",
    "    importance_df,\n",
    "    title=\"Sensor Feature Importance for Defect Prediction\"\n",
    ")\n",
    "fig_importance.show()\n",
    "\n",
    "# Analyze top correlation features\n",
    "top_corr_features = correlation_features.head(5)\n",
    "if not top_corr_features.empty:\n",
    "    print(\"\\nTop correlation-based predictive features:\")\n",
    "    for _, row in top_corr_features.iterrows():\n",
    "        feature_name = row['feature']\n",
    "        importance = row['importance']\n",
    "        # Extract sensor names from correlation feature\n",
    "        sensors = feature_name.replace('corr_', '').split('_')\n",
    "        if len(sensors) >= 2:\n",
    "            print(f\"  {sensors[0]} ↔ {sensors[1]}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Rolling Correlation Analysis\n",
    "\n",
    "Let's analyze how correlations change over time during a cast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute rolling correlations for the sample cast\n",
    "rolling_correlations = analyzer.compute_rolling_correlations(\n",
    "    sample_cast_data,\n",
    "    window_size=300,  # 5-minute rolling window\n",
    "    sensor_pair=('casting_speed', 'mold_temperature')\n",
    ")\n",
    "\n",
    "print(f\"Rolling correlation analysis:\")\n",
    "print(f\"Window size: 300 seconds (5 minutes)\")\n",
    "print(f\"Data shape: {rolling_correlations.shape}\")\n",
    "\n",
    "# Plot rolling correlation\n",
    "fig_rolling = go.Figure()\n",
    "\n",
    "fig_rolling.add_trace(go.Scatter(\n",
    "    x=rolling_correlations.index,\n",
    "    y=rolling_correlations.iloc[:, 0],\n",
    "    mode='lines',\n",
    "    name='Rolling Correlation',\n",
    "    line=dict(width=2)\n",
    "))\n",
    "\n",
    "fig_rolling.add_hline(y=0, line_dash=\"dash\", line_color=\"gray\", opacity=0.5)\n",
    "\n",
    "fig_rolling.update_layout(\n",
    "    title=\"Rolling Correlation: Casting Speed ↔ Mold Temperature\",\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Correlation Coefficient\",\n",
    "    height=400,\n",
    "    width=800\n",
    ")\n",
    "\n",
    "fig_rolling.show()\n",
    "\n",
    "# Analyze correlation stability\n",
    "corr_values = rolling_correlations.iloc[:, 0].dropna()\n",
    "print(f\"\\nRolling correlation statistics:\")\n",
    "print(f\"Mean: {corr_values.mean():.3f}\")\n",
    "print(f\"Std: {corr_values.std():.3f}\")\n",
    "print(f\"Min: {corr_values.min():.3f}\")\n",
    "print(f\"Max: {corr_values.max():.3f}\")\n",
    "print(f\"Range: {corr_values.max() - corr_values.min():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comprehensive Analysis Export\n",
    "\n",
    "Finally, let's export a comprehensive correlation analysis for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path('../data/correlation_analysis')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Export comprehensive analysis\n",
    "analysis_file = output_dir / 'comprehensive_correlation_analysis.json'\n",
    "analyzer.export_correlation_analysis(cast_data_list, str(analysis_file))\n",
    "\n",
    "# Save key visualizations\n",
    "print(\"\\nSaving visualizations...\")\n",
    "\n",
    "# Save correlation heatmap\n",
    "plotter.save_plot(\n",
    "    fig_heatmap, \n",
    "    str(output_dir / 'correlation_heatmap.html'), \n",
    "    format='html'\n",
    ")\n",
    "\n",
    "# Save defect comparison\n",
    "plotter.save_plot(\n",
    "    fig_comparison, \n",
    "    str(output_dir / 'defect_correlation_comparison.html'), \n",
    "    format='html'\n",
    ")\n",
    "\n",
    "# Save time-lagged analysis\n",
    "plotter.save_plot(\n",
    "    fig_lagged, \n",
    "    str(output_dir / 'time_lagged_correlations.html'), \n",
    "    format='html'\n",
    ")\n",
    "\n",
    "# Save feature importance\n",
    "plotter.save_plot(\n",
    "    fig_importance, \n",
    "    str(output_dir / 'feature_importance_ranking.html'), \n",
    "    format='html'\n",
    ")\n",
    "\n",
    "print(f\"Analysis complete! Results saved to {output_dir}\")\n",
    "print(f\"Files created:\")\n",
    "for file in output_dir.glob('*'):\n",
    "    print(f\"  - {file.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has demonstrated the comprehensive correlation analysis capabilities for steel casting sensor data:\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Cross-Sensor Correlations**: We identified the strongest positive and negative correlations between sensor pairs\n",
    "2. **Defect-Specific Patterns**: We compared correlation patterns between good and defective casts to identify differences\n",
    "3. **Time-Lagged Relationships**: We analyzed delayed relationships to identify leading indicators\n",
    "4. **Predictive Features**: We ranked sensor combinations by their predictive power for defect detection\n",
    "5. **Temporal Dynamics**: We analyzed how correlations change over time during casting\n",
    "\n",
    "### Applications:\n",
    "\n",
    "- **Process Monitoring**: Use correlation changes as early warning indicators\n",
    "- **Sensor Validation**: Identify when sensor relationships deviate from normal patterns\n",
    "- **Defect Prevention**: Monitor critical sensor combinations with high predictive power\n",
    "- **Process Optimization**: Understand sensor interdependencies for better control strategies\n",
    "\n",
    "The analysis results have been exported for further use in production monitoring systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}